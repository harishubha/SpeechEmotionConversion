{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-02T10:56:53.092553Z",
     "iopub.status.busy": "2025-12-02T10:56:53.091834Z",
     "iopub.status.idle": "2025-12-02T10:57:06.759897Z",
     "shell.execute_reply": "2025-12-02T10:57:06.759011Z",
     "shell.execute_reply.started": "2025-12-02T10:56:53.092503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T10:57:06.761702Z",
     "iopub.status.busy": "2025-12-02T10:57:06.761302Z",
     "iopub.status.idle": "2025-12-02T10:57:07.173978Z",
     "shell.execute_reply": "2025-12-02T10:57:07.173292Z",
     "shell.execute_reply.started": "2025-12-02T10:57:06.761680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: /data/b22_shruti_chaudhary/.cache/kagglehub/datasets/phantasm34/emovdb-sorted/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"phantasm34/emovdb-sorted\")\n",
    "print(\"Downloaded to:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:02:18.355538Z",
     "iopub.status.busy": "2025-12-02T11:02:18.355195Z",
     "iopub.status.idle": "2025-12-02T11:02:39.004745Z",
     "shell.execute_reply": "2025-12-02T11:02:39.003905Z",
     "shell.execute_reply.started": "2025-12-02T11:02:18.355514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  speaker  emotion                                           filepath  \\\n",
       " 0     bea  Neutral  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       " 1     bea  Neutral  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       " 2     bea  Neutral  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       " 3     bea  Neutral  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       " 4     bea  Neutral  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       " \n",
       "    sample_rate  duration_s  channels  \n",
       " 0        44100    3.322630         1  \n",
       " 1        44100    3.878390         1  \n",
       " 2        44100    5.015170         1  \n",
       " 3        44100    4.597846         1  \n",
       " 4        44100    3.477188         1  ,\n",
       " (6893, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = path  # path returned by kagglehub\n",
    "\n",
    "rows = []\n",
    "\n",
    "for speaker in sorted(os.listdir(DATA_DIR)):\n",
    "    spk_path = os.path.join(DATA_DIR, speaker)\n",
    "    if not os.path.isdir(spk_path):\n",
    "        continue\n",
    "    \n",
    "    for root, dirs, files in os.walk(spk_path):\n",
    "        for f in files:\n",
    "            if not f.lower().endswith((\".wav\", \".flac\", \".mp3\")):\n",
    "                continue\n",
    "            \n",
    "            filepath = os.path.join(root, f)\n",
    "            emotion = os.path.basename(os.path.dirname(filepath))\n",
    "            \n",
    "            try:\n",
    "                info = sf.info(filepath)\n",
    "                sr = info.samplerate\n",
    "                duration = info.frames / info.samplerate\n",
    "                channels = info.channels\n",
    "            except:\n",
    "                sr = None\n",
    "                duration = None\n",
    "                channels = None\n",
    "            \n",
    "            rows.append({\n",
    "                \"speaker\": speaker,\n",
    "                \"emotion\": emotion,\n",
    "                \"filepath\": filepath,\n",
    "                \"sample_rate\": sr,\n",
    "                \"duration_s\": duration,\n",
    "                \"channels\": channels,\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"emovdb_manifest.csv\", index=False)\n",
    "\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:02:39.006230Z",
     "iopub.status.busy": "2025-12-02T11:02:39.005996Z",
     "iopub.status.idle": "2025-12-02T11:02:39.025600Z",
     "shell.execute_reply": "2025-12-02T11:02:39.024690Z",
     "shell.execute_reply.started": "2025-12-02T11:02:39.006213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>emotion</th>\n",
       "      <th>filepath</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>sam</td>\n",
       "      <td>Angry</td>\n",
       "      <td>/data/b22_shruti_chaudhary/.cache/kagglehub/da...</td>\n",
       "      <td>16000</td>\n",
       "      <td>5.564938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>sam</td>\n",
       "      <td>Angry</td>\n",
       "      <td>/data/b22_shruti_chaudhary/.cache/kagglehub/da...</td>\n",
       "      <td>16000</td>\n",
       "      <td>4.385187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>sam</td>\n",
       "      <td>Angry</td>\n",
       "      <td>/data/b22_shruti_chaudhary/.cache/kagglehub/da...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.667500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>sam</td>\n",
       "      <td>Angry</td>\n",
       "      <td>/data/b22_shruti_chaudhary/.cache/kagglehub/da...</td>\n",
       "      <td>16000</td>\n",
       "      <td>4.655062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>sam</td>\n",
       "      <td>Angry</td>\n",
       "      <td>/data/b22_shruti_chaudhary/.cache/kagglehub/da...</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.833500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker emotion                                           filepath  \\\n",
       "6888     sam   Angry  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       "6889     sam   Angry  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       "6890     sam   Angry  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       "6891     sam   Angry  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       "6892     sam   Angry  /data/b22_shruti_chaudhary/.cache/kagglehub/da...   \n",
       "\n",
       "      sample_rate  duration_s  channels  \n",
       "6888        16000    5.564938         1  \n",
       "6889        16000    4.385187         1  \n",
       "6890        16000    3.667500         1  \n",
       "6891        16000    4.655062         1  \n",
       "6892        16000    2.833500         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 5.0.0.dev0\n",
      "Uninstalling transformers-5.0.0.dev0:\n",
      "  Successfully uninstalled transformers-5.0.0.dev0\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:02:39.026656Z",
     "iopub.status.busy": "2025-12-02T11:02:39.026417Z",
     "iopub.status.idle": "2025-12-02T11:03:57.123167Z",
     "shell.execute_reply": "2025-12-02T11:03:57.122091Z",
     "shell.execute_reply.started": "2025-12-02T11:02:39.026636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torchaudio in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: soundfile in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: tqdm in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: torch==2.9.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torchaudio) (2.9.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from torch==2.9.1->torchaudio) (3.5.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: pycparser in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.9.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.9.1->torchaudio) (2.0.1)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.1.7\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.1.7:\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.1.7\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed huggingface-hub-0.36.0 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torchaudio soundfile librosa tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-02T11:10:46.614603Z",
     "iopub.status.idle": "2025-12-02T11:10:46.614922Z",
     "shell.execute_reply": "2025-12-02T11:10:46.614775Z",
     "shell.execute_reply.started": "2025-12-02T11:10:46.614762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:04:00.414372Z",
     "iopub.status.busy": "2025-12-02T11:04:00.413926Z",
     "iopub.status.idle": "2025-12-02T11:04:31.378682Z",
     "shell.execute_reply": "2025-12-02T11:04:31.377793Z",
     "shell.execute_reply.started": "2025-12-02T11:04:00.414350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HubertModel' from 'transformers' (/data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HubertModel, Wav2Vec2FeatureExtractor\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HubertModel' from 'transformers' (/data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import HubertModel, Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# path to manifest file from previous step\n",
    "manifest_path = \"emovdb_manifest.csv\"\n",
    "df = pd.read_csv(manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:04:31.404935Z",
     "iopub.status.busy": "2025-12-02T11:04:31.404594Z",
     "iopub.status.idle": "2025-12-02T11:10:01.342248Z",
     "shell.execute_reply": "2025-12-02T11:10:01.341257Z",
     "shell.execute_reply.started": "2025-12-02T11:04:31.404914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e118ba961b3149fdb15dae317906949f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec616b7f43eb4cbc8ee76789c8767d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec8ca57df7e4bf0a0eb8aa684a4280d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380918759cbd4e1599b2fd880b3991e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting HuBERT features:   0%|          | 0/6893 [00:00<?, ?it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 1/6893 [00:00<1:32:51,  1.24it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 2/6893 [00:00<48:18,  2.38it/s]  \u001b[A\n",
      "Extracting HuBERT features:   0%|          | 4/6893 [00:01<23:36,  4.86it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 6/6893 [00:01<16:54,  6.79it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 8/6893 [00:01<13:19,  8.61it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 10/6893 [00:01<10:40, 10.74it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 12/6893 [00:01<08:59, 12.76it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 15/6893 [00:01<07:12, 15.90it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 17/6893 [00:01<06:49, 16.78it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 19/6893 [00:01<06:41, 17.13it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 21/6893 [00:02<06:45, 16.97it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 23/6893 [00:02<06:34, 17.42it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 26/6893 [00:02<05:52, 19.48it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 28/6893 [00:02<05:54, 19.36it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 30/6893 [00:02<05:52, 19.47it/s]\u001b[A\n",
      "Extracting HuBERT features:   0%|          | 33/6893 [00:02<05:45, 19.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 36/6893 [00:02<05:44, 19.92it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 39/6893 [00:02<05:22, 21.29it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 42/6893 [00:03<05:20, 21.38it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 45/6893 [00:03<05:13, 21.82it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 48/6893 [00:03<05:24, 21.12it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 51/6893 [00:03<05:15, 21.65it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 54/6893 [00:03<05:21, 21.29it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 57/6893 [00:03<05:09, 22.11it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 60/6893 [00:03<05:44, 19.84it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 63/6893 [00:04<05:24, 21.03it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 66/6893 [00:04<05:21, 21.22it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 69/6893 [00:04<05:18, 21.44it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 72/6893 [00:04<05:27, 20.80it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 75/6893 [00:04<05:35, 20.31it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 78/6893 [00:04<05:23, 21.05it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 81/6893 [00:04<05:51, 19.38it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|          | 84/6893 [00:05<05:37, 20.20it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 87/6893 [00:05<05:48, 19.54it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 89/6893 [00:05<05:50, 19.41it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 92/6893 [00:05<05:41, 19.91it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 95/6893 [00:05<05:54, 19.15it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 97/6893 [00:05<06:01, 18.82it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 100/6893 [00:05<05:30, 20.56it/s]\u001b[A\n",
      "Extracting HuBERT features:   1%|▏         | 103/6893 [00:06<05:18, 21.29it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 106/6893 [00:06<05:27, 20.70it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 109/6893 [00:06<05:25, 20.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 112/6893 [00:06<05:22, 21.03it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 115/6893 [00:06<05:12, 21.68it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 118/6893 [00:06<05:01, 22.48it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 121/6893 [00:06<05:07, 22.00it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 124/6893 [00:07<04:59, 22.61it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 127/6893 [00:07<04:43, 23.84it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 130/6893 [00:07<04:48, 23.48it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 133/6893 [00:07<05:13, 21.54it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 136/6893 [00:07<05:37, 20.05it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 139/6893 [00:07<05:32, 20.30it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 142/6893 [00:07<05:37, 20.03it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 145/6893 [00:08<05:19, 21.15it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 148/6893 [00:08<05:12, 21.60it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 151/6893 [00:08<05:21, 20.98it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 154/6893 [00:08<05:31, 20.35it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 157/6893 [00:08<05:38, 19.91it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 160/6893 [00:08<05:42, 19.68it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 163/6893 [00:08<05:23, 20.80it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 166/6893 [00:09<05:33, 20.14it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 169/6893 [00:09<05:17, 21.15it/s]\u001b[A\n",
      "Extracting HuBERT features:   2%|▏         | 172/6893 [00:09<05:22, 20.82it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 175/6893 [00:09<05:30, 20.33it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 178/6893 [00:09<05:30, 20.33it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 181/6893 [00:09<05:23, 20.77it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 184/6893 [00:09<05:21, 20.87it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 187/6893 [00:10<05:09, 21.67it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 190/6893 [00:10<05:20, 20.93it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 193/6893 [00:10<05:13, 21.38it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 196/6893 [00:10<05:03, 22.10it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 199/6893 [00:10<05:05, 21.94it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 202/6893 [00:10<05:02, 22.12it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 205/6893 [00:10<05:19, 20.96it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 208/6893 [00:11<05:19, 20.95it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 211/6893 [00:11<05:48, 19.18it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 214/6893 [00:11<05:34, 20.00it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 217/6893 [00:11<05:20, 20.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 220/6893 [00:11<05:21, 20.77it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 223/6893 [00:11<05:33, 20.01it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 226/6893 [00:11<05:27, 20.38it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 229/6893 [00:12<05:11, 21.36it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 232/6893 [00:12<05:00, 22.17it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 235/6893 [00:12<05:01, 22.06it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 238/6893 [00:12<05:03, 21.95it/s]\u001b[A\n",
      "Extracting HuBERT features:   3%|▎         | 241/6893 [00:12<05:31, 20.05it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▎         | 244/6893 [00:12<05:31, 20.07it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▎         | 247/6893 [00:12<05:24, 20.46it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▎         | 250/6893 [00:13<05:34, 19.86it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▎         | 253/6893 [00:13<05:27, 20.30it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▎         | 256/6893 [00:13<05:35, 19.76it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 259/6893 [00:13<05:24, 20.41it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 262/6893 [00:13<05:30, 20.08it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 265/6893 [00:13<05:28, 20.18it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 268/6893 [00:13<05:25, 20.34it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 271/6893 [00:14<05:39, 19.53it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 274/6893 [00:14<05:33, 19.84it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 276/6893 [00:14<05:45, 19.18it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 278/6893 [00:14<05:50, 18.88it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 280/6893 [00:14<05:58, 18.44it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 283/6893 [00:14<05:47, 19.04it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 285/6893 [00:14<05:54, 18.67it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 288/6893 [00:15<05:33, 19.81it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 291/6893 [00:15<05:23, 20.42it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 294/6893 [00:15<05:54, 18.61it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 297/6893 [00:15<05:42, 19.25it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 300/6893 [00:15<05:27, 20.11it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 303/6893 [00:15<05:30, 19.92it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 306/6893 [00:15<05:30, 19.91it/s]\u001b[A\n",
      "Extracting HuBERT features:   4%|▍         | 309/6893 [00:16<05:26, 20.19it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 312/6893 [00:16<05:15, 20.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 315/6893 [00:16<05:21, 20.45it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 318/6893 [00:16<05:28, 20.01it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 321/6893 [00:16<05:41, 19.25it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 323/6893 [00:16<05:45, 19.02it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 325/6893 [00:16<06:29, 16.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 327/6893 [00:17<06:19, 17.30it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 329/6893 [00:17<06:36, 16.56it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 332/6893 [00:17<05:57, 18.36it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 335/6893 [00:17<05:38, 19.39it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 338/6893 [00:17<05:11, 21.06it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▍         | 342/6893 [00:17<04:39, 23.45it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 345/6893 [00:17<04:33, 23.95it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 348/6893 [00:17<04:30, 24.19it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 351/6893 [00:18<04:24, 24.77it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 354/6893 [00:18<04:24, 24.69it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 357/6893 [00:18<04:31, 24.05it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 360/6893 [00:18<04:38, 23.48it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 363/6893 [00:18<04:29, 24.23it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 366/6893 [00:18<04:35, 23.71it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 369/6893 [00:18<04:40, 23.25it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 372/6893 [00:18<04:27, 24.35it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 375/6893 [00:19<04:29, 24.15it/s]\u001b[A\n",
      "Extracting HuBERT features:   5%|▌         | 378/6893 [00:19<04:32, 23.92it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 381/6893 [00:19<04:20, 25.04it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 384/6893 [00:19<04:22, 24.77it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 387/6893 [00:19<04:16, 25.34it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 390/6893 [00:19<04:06, 26.41it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 393/6893 [00:19<04:07, 26.27it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 396/6893 [00:19<04:08, 26.15it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 399/6893 [00:20<04:13, 25.60it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 402/6893 [00:20<04:20, 24.90it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 405/6893 [00:20<04:25, 24.40it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 408/6893 [00:20<04:11, 25.78it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 411/6893 [00:20<04:09, 25.93it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 414/6893 [00:20<04:25, 24.44it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 417/6893 [00:20<04:26, 24.29it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 420/6893 [00:20<04:20, 24.84it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 423/6893 [00:20<04:14, 25.46it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 426/6893 [00:21<04:20, 24.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▌         | 429/6893 [00:21<04:12, 25.55it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▋         | 432/6893 [00:21<04:13, 25.51it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▋         | 435/6893 [00:21<04:10, 25.80it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▋         | 438/6893 [00:21<04:05, 26.26it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▋         | 441/6893 [00:21<04:20, 24.75it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▋         | 444/6893 [00:21<04:11, 25.59it/s]\u001b[A\n",
      "Extracting HuBERT features:   6%|▋         | 447/6893 [00:21<04:18, 24.90it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 450/6893 [00:22<04:11, 25.65it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 453/6893 [00:22<04:06, 26.15it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 456/6893 [00:22<04:00, 26.81it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 459/6893 [00:22<04:00, 26.79it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 462/6893 [00:22<03:54, 27.42it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 465/6893 [00:22<03:57, 27.11it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 468/6893 [00:22<04:08, 25.84it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 471/6893 [00:22<04:13, 25.34it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 474/6893 [00:22<04:04, 26.25it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 477/6893 [00:23<04:10, 25.60it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 480/6893 [00:23<04:16, 24.99it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 483/6893 [00:23<04:07, 25.90it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 486/6893 [00:23<04:13, 25.26it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 489/6893 [00:23<04:18, 24.81it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 493/6893 [00:23<04:07, 25.82it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 496/6893 [00:23<04:08, 25.72it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 499/6893 [00:23<04:02, 26.37it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 502/6893 [00:24<04:07, 25.86it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 505/6893 [00:24<03:59, 26.68it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 508/6893 [00:24<04:21, 24.46it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 511/6893 [00:24<04:11, 25.36it/s]\u001b[A\n",
      "Extracting HuBERT features:   7%|▋         | 514/6893 [00:24<04:26, 23.95it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 517/6893 [00:24<04:25, 24.04it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 520/6893 [00:24<04:20, 24.43it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 523/6893 [00:24<04:33, 23.28it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 526/6893 [00:25<04:16, 24.85it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 529/6893 [00:25<04:15, 24.91it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 532/6893 [00:25<04:08, 25.58it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 535/6893 [00:25<04:17, 24.73it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 538/6893 [00:25<04:04, 26.03it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 541/6893 [00:25<04:12, 25.14it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 544/6893 [00:25<04:07, 25.61it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 547/6893 [00:25<04:13, 25.00it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 550/6893 [00:25<04:23, 24.10it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 553/6893 [00:26<04:20, 24.29it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 556/6893 [00:26<04:12, 25.06it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 559/6893 [00:26<04:23, 24.06it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 563/6893 [00:26<04:05, 25.73it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 566/6893 [00:26<04:03, 26.00it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 569/6893 [00:26<03:56, 26.72it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 572/6893 [00:26<03:57, 26.66it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 575/6893 [00:26<03:58, 26.48it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 578/6893 [00:27<03:56, 26.67it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 581/6893 [00:27<04:00, 26.29it/s]\u001b[A\n",
      "Extracting HuBERT features:   8%|▊         | 584/6893 [00:27<04:12, 25.03it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▊         | 587/6893 [00:27<04:20, 24.21it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▊         | 590/6893 [00:27<04:07, 25.45it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▊         | 593/6893 [00:27<04:06, 25.59it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▊         | 596/6893 [00:27<04:05, 25.69it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▊         | 599/6893 [00:27<04:02, 26.00it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▊         | 602/6893 [00:27<03:53, 26.97it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 605/6893 [00:28<03:52, 27.06it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 608/6893 [00:28<04:10, 25.11it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 611/6893 [00:28<03:59, 26.19it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 614/6893 [00:28<03:54, 26.81it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 617/6893 [00:28<03:53, 26.93it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 620/6893 [00:28<03:54, 26.74it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 623/6893 [00:28<03:59, 26.14it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 626/6893 [00:28<03:51, 27.10it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 630/6893 [00:29<03:47, 27.47it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 633/6893 [00:29<03:45, 27.73it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 636/6893 [00:29<03:44, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 639/6893 [00:29<03:41, 28.27it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 642/6893 [00:29<03:55, 26.50it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 645/6893 [00:29<03:57, 26.28it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 648/6893 [00:29<04:05, 25.41it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 651/6893 [00:29<04:18, 24.19it/s]\u001b[A\n",
      "Extracting HuBERT features:   9%|▉         | 654/6893 [00:29<04:29, 23.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 657/6893 [00:30<04:26, 23.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 660/6893 [00:30<04:53, 21.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 663/6893 [00:30<05:05, 20.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 666/6893 [00:30<05:10, 20.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 669/6893 [00:30<05:24, 19.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 671/6893 [00:30<05:22, 19.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 673/6893 [00:30<05:26, 19.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 676/6893 [00:31<05:03, 20.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 679/6893 [00:31<04:47, 21.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 682/6893 [00:31<04:41, 22.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 685/6893 [00:31<04:30, 22.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|▉         | 688/6893 [00:31<04:35, 22.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 691/6893 [00:31<04:42, 21.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 694/6893 [00:31<04:26, 23.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 697/6893 [00:32<04:31, 22.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 700/6893 [00:32<04:40, 22.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 703/6893 [00:32<04:26, 23.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 706/6893 [00:32<04:19, 23.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 709/6893 [00:32<04:15, 24.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 712/6893 [00:32<04:13, 24.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 715/6893 [00:32<04:02, 25.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 718/6893 [00:32<04:04, 25.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  10%|█         | 721/6893 [00:32<04:08, 24.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 724/6893 [00:33<04:04, 25.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 727/6893 [00:33<04:16, 24.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 730/6893 [00:33<04:18, 23.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 733/6893 [00:33<04:19, 23.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 736/6893 [00:33<04:20, 23.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 739/6893 [00:33<04:21, 23.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 742/6893 [00:33<04:13, 24.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 745/6893 [00:33<04:12, 24.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 748/6893 [00:34<04:05, 25.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 751/6893 [00:34<04:09, 24.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 754/6893 [00:34<04:23, 23.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 757/6893 [00:34<04:31, 22.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 760/6893 [00:34<04:18, 23.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 763/6893 [00:34<04:12, 24.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 766/6893 [00:34<04:04, 25.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 769/6893 [00:35<04:28, 22.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 772/6893 [00:35<04:26, 22.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█         | 775/6893 [00:35<04:20, 23.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█▏        | 778/6893 [00:35<04:20, 23.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█▏        | 781/6893 [00:35<04:13, 24.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█▏        | 784/6893 [00:35<04:14, 23.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█▏        | 787/6893 [00:35<04:35, 22.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  11%|█▏        | 790/6893 [00:35<04:26, 22.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 793/6893 [00:36<04:17, 23.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 796/6893 [00:36<04:17, 23.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 800/6893 [00:36<04:04, 24.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 803/6893 [00:36<04:12, 24.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 806/6893 [00:36<04:19, 23.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 809/6893 [00:36<04:29, 22.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 812/6893 [00:36<04:20, 23.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 815/6893 [00:36<04:26, 22.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 818/6893 [00:37<04:16, 23.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 821/6893 [00:37<04:13, 23.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 824/6893 [00:37<04:17, 23.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 827/6893 [00:37<04:21, 23.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 830/6893 [00:37<04:19, 23.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 833/6893 [00:37<04:08, 24.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 836/6893 [00:37<03:56, 25.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 839/6893 [00:37<03:48, 26.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 842/6893 [00:38<03:53, 25.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 845/6893 [00:38<03:51, 26.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 848/6893 [00:38<04:15, 23.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 851/6893 [00:38<04:07, 24.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 854/6893 [00:38<04:01, 25.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 857/6893 [00:38<04:05, 24.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  12%|█▏        | 860/6893 [00:38<04:09, 24.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 863/6893 [00:38<04:00, 25.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 866/6893 [00:39<03:55, 25.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 869/6893 [00:39<03:51, 26.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 872/6893 [00:39<03:58, 25.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 875/6893 [00:39<04:12, 23.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 878/6893 [00:39<04:17, 23.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 881/6893 [00:39<04:18, 23.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 884/6893 [00:39<04:16, 23.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 887/6893 [00:39<04:18, 23.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 890/6893 [00:40<04:06, 24.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 894/6893 [00:40<03:56, 25.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 897/6893 [00:40<04:02, 24.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 900/6893 [00:40<03:59, 24.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 903/6893 [00:40<04:20, 22.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 906/6893 [00:40<04:44, 21.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 909/6893 [00:40<04:31, 22.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 912/6893 [00:41<04:32, 21.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 915/6893 [00:41<04:11, 23.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 918/6893 [00:41<04:19, 22.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 921/6893 [00:41<04:23, 22.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 924/6893 [00:41<04:11, 23.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 927/6893 [00:41<04:11, 23.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  13%|█▎        | 930/6893 [00:41<04:03, 24.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▎        | 933/6893 [00:41<04:01, 24.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▎        | 936/6893 [00:41<04:01, 24.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▎        | 939/6893 [00:42<03:56, 25.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▎        | 942/6893 [00:42<03:49, 25.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▎        | 945/6893 [00:42<03:46, 26.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 948/6893 [00:42<03:48, 26.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 951/6893 [00:42<03:54, 25.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 954/6893 [00:42<04:01, 24.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 957/6893 [00:42<04:07, 23.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 960/6893 [00:42<04:17, 23.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 963/6893 [00:43<04:06, 24.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 966/6893 [00:43<03:56, 25.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 969/6893 [00:43<04:04, 24.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 972/6893 [00:43<04:07, 23.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 975/6893 [00:43<04:14, 23.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 978/6893 [00:43<04:26, 22.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 981/6893 [00:43<04:15, 23.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 984/6893 [00:43<04:15, 23.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 987/6893 [00:44<04:32, 21.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 990/6893 [00:44<04:12, 23.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 993/6893 [00:44<04:09, 23.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 996/6893 [00:44<04:29, 21.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  14%|█▍        | 999/6893 [00:44<04:33, 21.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1002/6893 [00:44<04:47, 20.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1005/6893 [00:44<04:51, 20.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1008/6893 [00:45<04:56, 19.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1011/6893 [00:45<05:14, 18.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1013/6893 [00:45<05:28, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1015/6893 [00:45<05:30, 17.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1017/6893 [00:45<05:42, 17.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1019/6893 [00:45<05:49, 16.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1022/6893 [00:45<05:22, 18.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1024/6893 [00:46<05:38, 17.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1026/6893 [00:46<06:07, 15.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1028/6893 [00:46<06:04, 16.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1030/6893 [00:46<06:05, 16.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▍        | 1032/6893 [00:46<05:53, 16.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1034/6893 [00:46<05:44, 17.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1036/6893 [00:46<05:36, 17.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1038/6893 [00:46<05:57, 16.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1040/6893 [00:47<05:49, 16.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1042/6893 [00:47<05:39, 17.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1044/6893 [00:47<05:40, 17.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1046/6893 [00:47<05:46, 16.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1048/6893 [00:47<05:38, 17.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1050/6893 [00:47<05:40, 17.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1052/6893 [00:47<05:33, 17.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1054/6893 [00:47<05:34, 17.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1056/6893 [00:47<05:31, 17.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1058/6893 [00:48<05:50, 16.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1060/6893 [00:48<05:33, 17.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1062/6893 [00:48<05:34, 17.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1064/6893 [00:48<05:47, 16.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1066/6893 [00:48<05:38, 17.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  15%|█▌        | 1068/6893 [00:48<05:36, 17.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1071/6893 [00:48<05:09, 18.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1073/6893 [00:48<05:14, 18.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1075/6893 [00:49<05:38, 17.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1077/6893 [00:49<05:35, 17.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1079/6893 [00:49<06:26, 15.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1081/6893 [00:49<06:19, 15.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1083/6893 [00:49<06:01, 16.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1085/6893 [00:49<06:17, 15.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1087/6893 [00:49<05:56, 16.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1089/6893 [00:49<05:57, 16.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1091/6893 [00:50<05:47, 16.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1093/6893 [00:50<06:08, 15.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1095/6893 [00:50<05:55, 16.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1098/6893 [00:50<05:17, 18.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1100/6893 [00:50<05:25, 17.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1102/6893 [00:50<05:50, 16.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1104/6893 [00:50<05:51, 16.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1106/6893 [00:50<05:39, 17.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1108/6893 [00:51<05:48, 16.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1110/6893 [00:51<05:59, 16.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1112/6893 [00:51<05:52, 16.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1114/6893 [00:51<05:49, 16.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1116/6893 [00:51<05:42, 16.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1118/6893 [00:51<06:02, 15.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▌        | 1120/6893 [00:51<06:11, 15.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1122/6893 [00:51<06:10, 15.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1125/6893 [00:52<05:39, 16.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1128/6893 [00:52<05:19, 18.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1130/6893 [00:52<05:22, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1132/6893 [00:52<05:33, 17.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1134/6893 [00:52<05:58, 16.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  16%|█▋        | 1137/6893 [00:52<05:29, 17.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1139/6893 [00:52<05:39, 16.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1141/6893 [00:53<05:36, 17.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1144/6893 [00:53<05:19, 18.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1146/6893 [00:53<05:24, 17.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1148/6893 [00:53<05:46, 16.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1150/6893 [00:53<05:57, 16.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1152/6893 [00:53<06:06, 15.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1154/6893 [00:53<06:22, 15.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1157/6893 [00:54<05:59, 15.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1160/6893 [00:54<05:34, 17.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1162/6893 [00:54<05:28, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1164/6893 [00:54<05:23, 17.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1166/6893 [00:54<05:24, 17.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1168/6893 [00:54<05:36, 17.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1170/6893 [00:54<05:48, 16.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1172/6893 [00:54<05:54, 16.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1174/6893 [00:55<05:38, 16.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1176/6893 [00:55<06:03, 15.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1178/6893 [00:55<06:07, 15.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1180/6893 [00:55<05:51, 16.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1182/6893 [00:55<06:11, 15.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1184/6893 [00:55<06:01, 15.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1187/6893 [00:55<05:24, 17.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1189/6893 [00:55<05:27, 17.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1192/6893 [00:56<05:16, 18.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1195/6893 [00:56<05:14, 18.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1197/6893 [00:56<05:31, 17.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1199/6893 [00:56<05:31, 17.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1201/6893 [00:56<05:50, 16.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1203/6893 [00:56<05:54, 16.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  17%|█▋        | 1205/6893 [00:56<05:43, 16.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1207/6893 [00:57<05:51, 16.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1209/6893 [00:57<05:34, 17.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1211/6893 [00:57<05:53, 16.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1213/6893 [00:57<05:40, 16.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1215/6893 [00:57<05:39, 16.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1217/6893 [00:57<05:39, 16.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1220/6893 [00:57<05:33, 16.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1222/6893 [00:57<05:31, 17.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1224/6893 [00:58<05:30, 17.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1226/6893 [00:58<05:39, 16.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1228/6893 [00:58<05:29, 17.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1230/6893 [00:58<05:29, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1232/6893 [00:58<05:28, 17.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1234/6893 [00:58<05:52, 16.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1237/6893 [00:58<05:29, 17.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1239/6893 [00:58<05:17, 17.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1241/6893 [00:59<05:17, 17.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1244/6893 [00:59<04:58, 18.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1246/6893 [00:59<05:08, 18.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1248/6893 [00:59<05:09, 18.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1250/6893 [00:59<05:16, 17.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1253/6893 [00:59<05:05, 18.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1255/6893 [00:59<05:12, 18.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1257/6893 [00:59<05:10, 18.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1259/6893 [01:00<06:02, 15.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1261/6893 [01:00<05:39, 16.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1264/6893 [01:00<05:30, 17.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1266/6893 [01:00<05:33, 16.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1268/6893 [01:00<05:38, 16.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1270/6893 [01:00<05:46, 16.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1272/6893 [01:00<05:37, 16.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  18%|█▊        | 1275/6893 [01:00<05:26, 17.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1277/6893 [01:01<05:32, 16.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1279/6893 [01:01<05:39, 16.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1281/6893 [01:01<05:34, 16.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1283/6893 [01:01<05:45, 16.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1285/6893 [01:01<05:36, 16.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1287/6893 [01:01<05:22, 17.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1289/6893 [01:01<05:31, 16.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▊        | 1292/6893 [01:01<05:20, 17.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1294/6893 [01:02<05:56, 15.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1296/6893 [01:02<05:59, 15.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1298/6893 [01:02<05:43, 16.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1300/6893 [01:02<05:45, 16.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1302/6893 [01:02<05:34, 16.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1304/6893 [01:02<05:34, 16.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1306/6893 [01:02<05:31, 16.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1308/6893 [01:02<05:46, 16.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1310/6893 [01:03<05:50, 15.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1312/6893 [01:03<05:41, 16.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1314/6893 [01:03<05:51, 15.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1316/6893 [01:03<05:40, 16.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1318/6893 [01:03<06:04, 15.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1320/6893 [01:03<05:54, 15.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1323/6893 [01:03<05:14, 17.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1325/6893 [01:04<05:22, 17.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1327/6893 [01:04<05:32, 16.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1329/6893 [01:04<05:23, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1331/6893 [01:04<05:43, 16.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1333/6893 [01:04<05:43, 16.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1335/6893 [01:04<05:32, 16.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1337/6893 [01:04<05:37, 16.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1339/6893 [01:04<05:23, 17.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1341/6893 [01:04<05:22, 17.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  19%|█▉        | 1343/6893 [01:05<05:22, 17.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1345/6893 [01:05<05:40, 16.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1347/6893 [01:05<05:28, 16.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1349/6893 [01:05<05:58, 15.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1351/6893 [01:05<05:37, 16.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1353/6893 [01:05<05:26, 16.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1355/6893 [01:05<05:31, 16.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1357/6893 [01:05<05:29, 16.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1359/6893 [01:06<05:17, 17.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1361/6893 [01:06<05:16, 17.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1363/6893 [01:06<05:22, 17.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1365/6893 [01:06<05:31, 16.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1367/6893 [01:06<05:39, 16.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1369/6893 [01:06<06:19, 14.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1371/6893 [01:06<06:08, 14.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1373/6893 [01:06<06:25, 14.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1375/6893 [01:07<06:28, 14.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|█▉        | 1377/6893 [01:07<06:18, 14.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1379/6893 [01:07<06:05, 15.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1381/6893 [01:07<05:46, 15.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1383/6893 [01:07<05:31, 16.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1385/6893 [01:07<05:23, 17.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1387/6893 [01:07<05:37, 16.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1389/6893 [01:07<05:47, 15.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1391/6893 [01:08<05:30, 16.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1393/6893 [01:08<05:42, 16.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1395/6893 [01:08<05:58, 15.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1397/6893 [01:08<05:43, 16.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1399/6893 [01:08<05:48, 15.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1401/6893 [01:08<05:50, 15.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1404/6893 [01:08<05:30, 16.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1406/6893 [01:09<05:47, 15.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1408/6893 [01:09<05:33, 16.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1410/6893 [01:09<05:46, 15.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  20%|██        | 1412/6893 [01:09<06:17, 14.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1414/6893 [01:09<06:28, 14.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1416/6893 [01:09<06:02, 15.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1418/6893 [01:09<05:59, 15.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1420/6893 [01:10<06:21, 14.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1422/6893 [01:10<06:14, 14.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1424/6893 [01:10<06:09, 14.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1426/6893 [01:10<06:24, 14.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1428/6893 [01:10<06:43, 13.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1430/6893 [01:10<07:04, 12.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1432/6893 [01:10<06:27, 14.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1434/6893 [01:10<06:07, 14.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1436/6893 [01:11<06:08, 14.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1438/6893 [01:11<07:11, 12.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1441/6893 [01:11<06:20, 14.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1443/6893 [01:11<06:35, 13.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1445/6893 [01:11<06:22, 14.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1448/6893 [01:11<05:49, 15.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1450/6893 [01:12<05:31, 16.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1452/6893 [01:12<05:27, 16.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1454/6893 [01:12<05:30, 16.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1456/6893 [01:12<05:20, 16.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1458/6893 [01:12<05:09, 17.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1460/6893 [01:12<05:20, 16.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1462/6893 [01:12<05:13, 17.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██        | 1464/6893 [01:12<05:11, 17.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1466/6893 [01:12<05:04, 17.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1468/6893 [01:13<05:22, 16.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1470/6893 [01:13<05:32, 16.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1472/6893 [01:13<05:44, 15.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1474/6893 [01:13<06:05, 14.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1476/6893 [01:13<06:12, 14.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1478/6893 [01:13<05:59, 15.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  21%|██▏       | 1480/6893 [01:13<05:47, 15.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1482/6893 [01:14<05:51, 15.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1484/6893 [01:14<05:41, 15.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1486/6893 [01:14<05:47, 15.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1488/6893 [01:14<05:41, 15.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1490/6893 [01:14<05:55, 15.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1492/6893 [01:14<05:33, 16.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1494/6893 [01:14<05:15, 17.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1497/6893 [01:14<04:47, 18.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1499/6893 [01:15<04:48, 18.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1501/6893 [01:15<04:58, 18.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1503/6893 [01:15<05:04, 17.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1506/6893 [01:15<04:43, 18.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1509/6893 [01:15<04:29, 20.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1512/6893 [01:15<04:15, 21.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1515/6893 [01:15<04:16, 20.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1518/6893 [01:15<04:12, 21.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1521/6893 [01:16<04:14, 21.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1524/6893 [01:16<04:00, 22.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1527/6893 [01:16<03:58, 22.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1530/6893 [01:16<03:53, 23.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1533/6893 [01:16<03:55, 22.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1536/6893 [01:16<03:57, 22.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1539/6893 [01:16<04:04, 21.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1542/6893 [01:16<03:56, 22.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1545/6893 [01:17<04:00, 22.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  22%|██▏       | 1548/6893 [01:17<03:56, 22.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1551/6893 [01:17<04:06, 21.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1554/6893 [01:17<04:01, 22.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1557/6893 [01:17<04:17, 20.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1560/6893 [01:17<04:10, 21.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1563/6893 [01:17<04:11, 21.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1566/6893 [01:18<04:24, 20.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1569/6893 [01:18<04:17, 20.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1572/6893 [01:18<04:06, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1575/6893 [01:18<04:13, 20.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1578/6893 [01:18<04:03, 21.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1581/6893 [01:18<04:03, 21.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1584/6893 [01:18<03:57, 22.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1587/6893 [01:19<03:53, 22.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1590/6893 [01:19<03:54, 22.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1593/6893 [01:19<04:00, 22.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1596/6893 [01:19<03:58, 22.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1599/6893 [01:19<04:03, 21.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1602/6893 [01:19<04:09, 21.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1605/6893 [01:19<04:11, 21.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1608/6893 [01:20<03:59, 22.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1611/6893 [01:20<04:05, 21.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1614/6893 [01:20<03:56, 22.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  23%|██▎       | 1617/6893 [01:20<03:58, 22.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▎       | 1620/6893 [01:20<03:57, 22.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▎       | 1623/6893 [01:20<04:12, 20.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▎       | 1626/6893 [01:20<04:04, 21.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▎       | 1629/6893 [01:21<04:03, 21.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▎       | 1632/6893 [01:21<04:15, 20.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▎       | 1635/6893 [01:21<04:13, 20.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1638/6893 [01:21<04:05, 21.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1641/6893 [01:21<04:05, 21.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1644/6893 [01:21<04:09, 21.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1647/6893 [01:21<04:01, 21.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1650/6893 [01:21<03:55, 22.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1653/6893 [01:22<03:59, 21.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1656/6893 [01:22<04:20, 20.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1659/6893 [01:22<04:05, 21.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1662/6893 [01:22<04:02, 21.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1665/6893 [01:22<04:09, 20.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1668/6893 [01:22<04:04, 21.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1671/6893 [01:22<03:54, 22.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1674/6893 [01:23<03:54, 22.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1677/6893 [01:23<03:43, 23.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1680/6893 [01:23<03:48, 22.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1683/6893 [01:23<03:51, 22.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  24%|██▍       | 1686/6893 [01:23<03:59, 21.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1689/6893 [01:23<03:59, 21.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1692/6893 [01:23<04:09, 20.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1695/6893 [01:24<04:18, 20.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1698/6893 [01:24<04:24, 19.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1700/6893 [01:24<04:25, 19.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1703/6893 [01:24<04:10, 20.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1706/6893 [01:24<04:05, 21.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1709/6893 [01:24<03:53, 22.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1712/6893 [01:24<03:55, 22.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1715/6893 [01:25<03:46, 22.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1718/6893 [01:25<03:46, 22.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▍       | 1721/6893 [01:25<03:35, 23.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1724/6893 [01:25<03:58, 21.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1727/6893 [01:25<04:08, 20.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1730/6893 [01:25<03:48, 22.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1733/6893 [01:25<03:53, 22.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1736/6893 [01:25<03:50, 22.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1739/6893 [01:26<03:53, 22.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1742/6893 [01:26<03:59, 21.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1745/6893 [01:26<03:51, 22.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1748/6893 [01:26<03:55, 21.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1751/6893 [01:26<03:53, 22.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1754/6893 [01:26<03:58, 21.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  25%|██▌       | 1757/6893 [01:26<04:04, 21.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1760/6893 [01:27<04:06, 20.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1763/6893 [01:27<03:58, 21.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1766/6893 [01:27<04:04, 20.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1769/6893 [01:27<03:57, 21.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1772/6893 [01:27<04:00, 21.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1775/6893 [01:27<04:09, 20.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1778/6893 [01:27<04:13, 20.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1781/6893 [01:28<04:05, 20.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1784/6893 [01:28<04:14, 20.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1787/6893 [01:28<04:09, 20.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1790/6893 [01:28<03:58, 21.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1793/6893 [01:28<03:49, 22.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1796/6893 [01:28<03:46, 22.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1799/6893 [01:28<03:43, 22.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1802/6893 [01:29<03:35, 23.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1805/6893 [01:29<03:36, 23.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▌       | 1808/6893 [01:29<03:35, 23.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▋       | 1811/6893 [01:29<03:39, 23.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▋       | 1814/6893 [01:29<03:34, 23.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▋       | 1817/6893 [01:29<03:34, 23.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▋       | 1820/6893 [01:29<03:26, 24.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▋       | 1823/6893 [01:29<03:22, 24.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  26%|██▋       | 1826/6893 [01:30<03:24, 24.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1829/6893 [01:30<03:34, 23.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1832/6893 [01:30<03:33, 23.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1835/6893 [01:30<03:39, 23.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1838/6893 [01:30<03:42, 22.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1841/6893 [01:30<03:43, 22.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1844/6893 [01:30<03:54, 21.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1847/6893 [01:30<03:56, 21.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1850/6893 [01:31<03:44, 22.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1853/6893 [01:31<03:39, 23.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1856/6893 [01:31<03:33, 23.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1859/6893 [01:31<03:30, 23.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1862/6893 [01:31<03:25, 24.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1865/6893 [01:31<03:23, 24.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1868/6893 [01:31<03:35, 23.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1871/6893 [01:31<03:39, 22.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1874/6893 [01:32<03:41, 22.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1877/6893 [01:32<03:42, 22.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1880/6893 [01:32<03:37, 23.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1883/6893 [01:32<03:26, 24.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1886/6893 [01:32<03:22, 24.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1889/6893 [01:32<03:25, 24.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1892/6893 [01:32<03:26, 24.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  27%|██▋       | 1895/6893 [01:32<03:35, 23.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1898/6893 [01:33<03:36, 23.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1901/6893 [01:33<03:43, 22.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1904/6893 [01:33<03:37, 22.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1907/6893 [01:33<03:22, 24.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1910/6893 [01:33<03:28, 23.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1913/6893 [01:33<03:25, 24.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1916/6893 [01:33<03:24, 24.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1919/6893 [01:34<03:32, 23.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1922/6893 [01:34<03:37, 22.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1925/6893 [01:34<03:41, 22.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1928/6893 [01:34<03:42, 22.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1931/6893 [01:34<03:34, 23.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1934/6893 [01:34<03:45, 21.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1937/6893 [01:34<03:54, 21.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1940/6893 [01:34<03:53, 21.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1943/6893 [01:35<03:43, 22.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1946/6893 [01:35<03:42, 22.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1949/6893 [01:35<03:50, 21.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1952/6893 [01:35<03:40, 22.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1955/6893 [01:35<03:33, 23.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1958/6893 [01:35<03:25, 23.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1961/6893 [01:35<03:43, 22.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  28%|██▊       | 1964/6893 [01:36<03:38, 22.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▊       | 1967/6893 [01:36<03:44, 21.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▊       | 1970/6893 [01:36<03:33, 23.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▊       | 1973/6893 [01:36<03:50, 21.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▊       | 1976/6893 [01:36<03:35, 22.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▊       | 1979/6893 [01:36<03:40, 22.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 1982/6893 [01:36<03:45, 21.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 1985/6893 [01:36<03:40, 22.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 1988/6893 [01:37<03:55, 20.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 1991/6893 [01:37<04:00, 20.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 1994/6893 [01:37<04:00, 20.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 1997/6893 [01:37<03:42, 21.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2000/6893 [01:37<03:39, 22.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2003/6893 [01:37<03:41, 22.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2006/6893 [01:38<03:53, 20.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2009/6893 [01:38<04:00, 20.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2012/6893 [01:38<03:52, 21.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2015/6893 [01:38<04:01, 20.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2018/6893 [01:38<04:01, 20.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2021/6893 [01:38<04:05, 19.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2024/6893 [01:38<04:05, 19.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2027/6893 [01:39<03:54, 20.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2030/6893 [01:39<03:43, 21.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  29%|██▉       | 2033/6893 [01:39<03:45, 21.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2036/6893 [01:39<03:31, 22.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2039/6893 [01:39<03:59, 20.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2042/6893 [01:39<03:52, 20.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2045/6893 [01:39<03:48, 21.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2048/6893 [01:40<03:43, 21.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2051/6893 [01:40<03:46, 21.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2054/6893 [01:40<03:33, 22.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2057/6893 [01:40<03:44, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2060/6893 [01:40<03:39, 22.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2063/6893 [01:40<03:44, 21.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|██▉       | 2066/6893 [01:40<03:38, 22.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2069/6893 [01:40<03:36, 22.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2072/6893 [01:41<03:49, 21.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2075/6893 [01:41<03:35, 22.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2078/6893 [01:41<03:43, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2081/6893 [01:41<03:39, 21.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2084/6893 [01:41<03:42, 21.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2087/6893 [01:41<03:47, 21.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2090/6893 [01:41<03:36, 22.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2093/6893 [01:42<03:37, 22.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2096/6893 [01:42<03:27, 23.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2099/6893 [01:42<03:43, 21.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  30%|███       | 2102/6893 [01:42<03:43, 21.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2105/6893 [01:42<03:39, 21.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2108/6893 [01:42<03:38, 21.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2111/6893 [01:42<03:40, 21.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2114/6893 [01:43<03:39, 21.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2117/6893 [01:43<03:39, 21.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2120/6893 [01:43<03:36, 22.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2123/6893 [01:43<03:33, 22.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2126/6893 [01:43<03:37, 21.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2129/6893 [01:43<03:52, 20.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2132/6893 [01:43<03:42, 21.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2135/6893 [01:44<03:44, 21.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2138/6893 [01:44<03:26, 23.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2141/6893 [01:44<03:29, 22.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2144/6893 [01:44<03:38, 21.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2147/6893 [01:44<03:40, 21.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2150/6893 [01:44<03:36, 21.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███       | 2153/6893 [01:44<03:29, 22.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███▏      | 2156/6893 [01:44<03:27, 22.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███▏      | 2159/6893 [01:45<03:27, 22.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███▏      | 2162/6893 [01:45<03:24, 23.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███▏      | 2165/6893 [01:45<03:28, 22.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███▏      | 2168/6893 [01:45<03:36, 21.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  31%|███▏      | 2171/6893 [01:45<03:40, 21.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2174/6893 [01:45<03:38, 21.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2177/6893 [01:45<03:36, 21.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2180/6893 [01:46<03:26, 22.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2183/6893 [01:46<03:24, 23.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2186/6893 [01:46<03:26, 22.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2189/6893 [01:46<03:24, 23.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2192/6893 [01:46<03:37, 21.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2195/6893 [01:46<03:27, 22.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2198/6893 [01:46<03:29, 22.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2201/6893 [01:46<03:34, 21.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2204/6893 [01:47<03:33, 21.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2207/6893 [01:47<03:40, 21.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2210/6893 [01:47<03:33, 21.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2213/6893 [01:47<03:38, 21.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2216/6893 [01:47<03:40, 21.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2219/6893 [01:47<03:42, 21.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2222/6893 [01:47<03:36, 21.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2225/6893 [01:48<03:48, 20.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2228/6893 [01:48<03:53, 20.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2231/6893 [01:48<03:51, 20.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2234/6893 [01:48<03:45, 20.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2237/6893 [01:48<03:38, 21.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  32%|███▏      | 2240/6893 [01:48<03:36, 21.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2243/6893 [01:48<03:34, 21.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2246/6893 [01:49<03:30, 22.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2249/6893 [01:49<03:23, 22.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2252/6893 [01:49<03:32, 21.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2255/6893 [01:49<03:36, 21.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2258/6893 [01:49<03:37, 21.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2261/6893 [01:49<03:55, 19.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2264/6893 [01:49<03:40, 20.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2267/6893 [01:50<03:47, 20.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2270/6893 [01:50<03:44, 20.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2273/6893 [01:50<03:41, 20.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2276/6893 [01:50<03:40, 20.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2279/6893 [01:50<03:42, 20.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2282/6893 [01:50<03:47, 20.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2285/6893 [01:50<03:39, 20.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2288/6893 [01:51<03:37, 21.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2291/6893 [01:51<03:43, 20.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2294/6893 [01:51<03:50, 19.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2297/6893 [01:51<03:34, 21.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2300/6893 [01:51<03:39, 20.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2303/6893 [01:51<03:44, 20.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2306/6893 [01:51<03:32, 21.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  33%|███▎      | 2309/6893 [01:52<03:23, 22.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▎      | 2312/6893 [01:52<03:27, 22.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▎      | 2315/6893 [01:52<03:33, 21.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▎      | 2318/6893 [01:52<03:31, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▎      | 2321/6893 [01:52<03:28, 21.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▎      | 2324/6893 [01:52<03:38, 20.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2327/6893 [01:52<03:35, 21.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2330/6893 [01:53<03:38, 20.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2333/6893 [01:53<03:40, 20.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2336/6893 [01:53<03:51, 19.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2339/6893 [01:53<03:30, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2342/6893 [01:53<03:27, 21.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2345/6893 [01:53<03:36, 20.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2348/6893 [01:53<03:38, 20.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2351/6893 [01:54<03:43, 20.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2354/6893 [01:54<03:47, 19.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2357/6893 [01:54<03:54, 19.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2360/6893 [01:54<03:44, 20.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2363/6893 [01:54<03:41, 20.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2366/6893 [01:54<03:33, 21.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2369/6893 [01:54<03:31, 21.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2372/6893 [01:55<03:19, 22.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2375/6893 [01:55<03:24, 22.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  34%|███▍      | 2378/6893 [01:55<03:20, 22.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2381/6893 [01:55<03:24, 22.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2384/6893 [01:55<03:18, 22.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2387/6893 [01:55<03:21, 22.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2390/6893 [01:55<03:26, 21.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2393/6893 [01:56<03:28, 21.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2396/6893 [01:56<03:34, 20.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2399/6893 [01:56<03:28, 21.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2402/6893 [01:56<03:29, 21.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2405/6893 [01:56<03:34, 20.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2408/6893 [01:56<03:28, 21.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▍      | 2411/6893 [01:56<03:30, 21.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2414/6893 [01:57<03:26, 21.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2417/6893 [01:57<03:20, 22.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2420/6893 [01:57<03:14, 23.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2423/6893 [01:57<03:21, 22.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2426/6893 [01:57<03:24, 21.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2429/6893 [01:57<03:20, 22.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2432/6893 [01:57<03:27, 21.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2435/6893 [01:57<03:22, 21.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2438/6893 [01:58<03:22, 21.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2441/6893 [01:58<03:26, 21.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2444/6893 [01:58<03:30, 21.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  35%|███▌      | 2447/6893 [01:58<03:32, 20.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2450/6893 [01:58<03:23, 21.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2453/6893 [01:58<03:25, 21.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2456/6893 [01:58<03:33, 20.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2459/6893 [01:59<03:25, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2462/6893 [01:59<03:22, 21.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2465/6893 [01:59<03:28, 21.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2468/6893 [01:59<03:26, 21.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2471/6893 [01:59<03:27, 21.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2474/6893 [01:59<03:17, 22.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2477/6893 [01:59<03:04, 23.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2480/6893 [01:59<03:02, 24.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2483/6893 [02:00<03:03, 24.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2486/6893 [02:00<03:02, 24.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2489/6893 [02:00<03:12, 22.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2492/6893 [02:00<03:13, 22.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2495/6893 [02:00<03:08, 23.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▌      | 2498/6893 [02:00<02:58, 24.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▋      | 2501/6893 [02:00<02:59, 24.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▋      | 2504/6893 [02:01<03:00, 24.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▋      | 2507/6893 [02:01<03:07, 23.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▋      | 2510/6893 [02:01<03:07, 23.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  36%|███▋      | 2513/6893 [02:01<03:14, 22.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2516/6893 [02:01<03:03, 23.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2519/6893 [02:01<03:07, 23.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2522/6893 [02:01<03:10, 23.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2525/6893 [02:01<03:08, 23.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2528/6893 [02:02<03:14, 22.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2531/6893 [02:02<03:09, 22.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2534/6893 [02:02<03:08, 23.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2537/6893 [02:02<03:05, 23.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2540/6893 [02:02<03:15, 22.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2543/6893 [02:02<03:13, 22.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2546/6893 [02:02<03:17, 22.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2549/6893 [02:03<03:21, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2552/6893 [02:03<03:14, 22.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2555/6893 [02:03<03:01, 23.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2558/6893 [02:03<03:04, 23.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2561/6893 [02:03<03:06, 23.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2564/6893 [02:03<03:02, 23.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2567/6893 [02:03<02:56, 24.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2570/6893 [02:03<03:04, 23.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2573/6893 [02:04<03:09, 22.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2576/6893 [02:04<03:09, 22.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2579/6893 [02:04<03:01, 23.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  37%|███▋      | 2582/6893 [02:04<02:55, 24.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2585/6893 [02:04<02:59, 23.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2588/6893 [02:04<03:01, 23.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2591/6893 [02:04<03:07, 22.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2594/6893 [02:04<03:11, 22.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2597/6893 [02:05<03:11, 22.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2600/6893 [02:05<03:06, 23.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2603/6893 [02:05<03:00, 23.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2606/6893 [02:05<02:55, 24.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2609/6893 [02:05<02:56, 24.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2612/6893 [02:05<02:58, 24.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2615/6893 [02:05<03:01, 23.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2618/6893 [02:05<03:00, 23.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2621/6893 [02:06<03:07, 22.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2624/6893 [02:06<03:08, 22.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2627/6893 [02:06<03:08, 22.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2630/6893 [02:06<03:02, 23.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2633/6893 [02:06<03:01, 23.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2636/6893 [02:06<03:13, 22.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2639/6893 [02:06<03:07, 22.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2642/6893 [02:06<03:02, 23.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2645/6893 [02:07<03:01, 23.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2648/6893 [02:07<02:57, 23.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  38%|███▊      | 2651/6893 [02:07<02:54, 24.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▊      | 2654/6893 [02:07<02:52, 24.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▊      | 2657/6893 [02:07<02:53, 24.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▊      | 2660/6893 [02:07<02:54, 24.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▊      | 2663/6893 [02:07<03:01, 23.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▊      | 2666/6893 [02:07<03:02, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▊      | 2669/6893 [02:08<03:12, 21.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2672/6893 [02:08<03:05, 22.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2675/6893 [02:08<03:08, 22.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2678/6893 [02:08<02:57, 23.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2681/6893 [02:08<03:00, 23.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2684/6893 [02:08<02:53, 24.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2687/6893 [02:08<02:48, 24.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2690/6893 [02:08<02:50, 24.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2693/6893 [02:09<02:57, 23.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2697/6893 [02:09<02:47, 25.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2700/6893 [02:09<02:45, 25.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2703/6893 [02:09<02:46, 25.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2706/6893 [02:09<02:39, 26.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2709/6893 [02:09<02:43, 25.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2712/6893 [02:09<02:42, 25.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2715/6893 [02:09<02:43, 25.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2718/6893 [02:10<02:54, 23.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  39%|███▉      | 2721/6893 [02:10<02:49, 24.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2724/6893 [02:10<02:42, 25.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2727/6893 [02:10<02:45, 25.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2730/6893 [02:10<02:45, 25.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2733/6893 [02:10<02:41, 25.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2736/6893 [02:10<02:44, 25.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2739/6893 [02:10<02:39, 26.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2742/6893 [02:11<02:41, 25.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2745/6893 [02:11<02:42, 25.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2748/6893 [02:11<02:47, 24.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2751/6893 [02:11<02:48, 24.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2754/6893 [02:11<02:58, 23.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|███▉      | 2757/6893 [02:11<03:04, 22.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2760/6893 [02:11<02:58, 23.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2763/6893 [02:11<03:02, 22.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2766/6893 [02:12<02:59, 22.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2769/6893 [02:12<02:58, 23.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2773/6893 [02:12<02:41, 25.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2776/6893 [02:12<02:45, 24.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2779/6893 [02:12<02:46, 24.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2782/6893 [02:12<02:50, 24.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2785/6893 [02:12<02:47, 24.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2788/6893 [02:12<02:45, 24.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  40%|████      | 2791/6893 [02:13<02:46, 24.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2794/6893 [02:13<02:38, 25.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2797/6893 [02:13<02:44, 24.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2800/6893 [02:13<02:40, 25.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2803/6893 [02:13<02:40, 25.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2807/6893 [02:13<02:33, 26.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2810/6893 [02:13<02:40, 25.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2813/6893 [02:13<02:40, 25.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2816/6893 [02:14<02:37, 25.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2819/6893 [02:14<02:43, 24.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2822/6893 [02:14<02:41, 25.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2825/6893 [02:14<02:43, 24.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2828/6893 [02:14<02:42, 25.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2832/6893 [02:14<02:31, 26.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2835/6893 [02:14<02:35, 26.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2838/6893 [02:14<02:42, 24.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████      | 2841/6893 [02:15<02:48, 24.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████▏     | 2844/6893 [02:15<02:47, 24.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████▏     | 2847/6893 [02:15<02:48, 24.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████▏     | 2850/6893 [02:15<02:47, 24.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████▏     | 2853/6893 [02:15<02:51, 23.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████▏     | 2856/6893 [02:15<02:51, 23.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  41%|████▏     | 2859/6893 [02:15<02:41, 24.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2862/6893 [02:15<02:44, 24.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2865/6893 [02:16<02:43, 24.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2868/6893 [02:16<02:44, 24.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2871/6893 [02:16<02:42, 24.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2874/6893 [02:16<02:40, 24.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2877/6893 [02:16<02:50, 23.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2880/6893 [02:16<02:43, 24.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2883/6893 [02:16<02:44, 24.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2886/6893 [02:16<02:48, 23.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2889/6893 [02:17<02:45, 24.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2892/6893 [02:17<02:47, 23.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2895/6893 [02:17<02:52, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2898/6893 [02:17<02:44, 24.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2901/6893 [02:17<02:45, 24.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2904/6893 [02:17<02:42, 24.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2907/6893 [02:17<02:38, 25.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2910/6893 [02:17<02:47, 23.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2913/6893 [02:18<02:41, 24.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2916/6893 [02:18<02:52, 23.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2919/6893 [02:18<02:51, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2922/6893 [02:18<02:51, 23.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2925/6893 [02:18<02:40, 24.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  42%|████▏     | 2928/6893 [02:18<02:47, 23.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2931/6893 [02:18<02:51, 23.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2934/6893 [02:18<02:54, 22.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2937/6893 [02:19<02:57, 22.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2940/6893 [02:19<03:02, 21.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2943/6893 [02:19<02:56, 22.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2946/6893 [02:19<02:57, 22.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2949/6893 [02:19<02:49, 23.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2952/6893 [02:19<02:43, 24.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2955/6893 [02:19<02:41, 24.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2958/6893 [02:19<02:39, 24.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2961/6893 [02:20<02:41, 24.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2964/6893 [02:20<02:39, 24.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2967/6893 [02:20<02:37, 24.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2970/6893 [02:20<02:46, 23.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2973/6893 [02:20<02:48, 23.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2976/6893 [02:20<03:19, 19.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2979/6893 [02:20<03:15, 20.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2982/6893 [02:21<03:07, 20.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2985/6893 [02:21<03:00, 21.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2988/6893 [02:21<03:07, 20.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2991/6893 [02:21<03:00, 21.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2994/6893 [02:21<02:48, 23.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  43%|████▎     | 2997/6893 [02:21<02:44, 23.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▎     | 3000/6893 [02:21<02:47, 23.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▎     | 3003/6893 [02:21<02:44, 23.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▎     | 3006/6893 [02:22<02:45, 23.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▎     | 3009/6893 [02:22<02:38, 24.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▎     | 3012/6893 [02:22<02:38, 24.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▎     | 3015/6893 [02:22<02:40, 24.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3018/6893 [02:22<02:44, 23.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3021/6893 [02:22<02:46, 23.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3024/6893 [02:22<02:41, 23.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3027/6893 [02:22<02:31, 25.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3030/6893 [02:23<02:38, 24.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3033/6893 [02:23<02:44, 23.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3036/6893 [02:23<02:58, 21.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3039/6893 [02:23<02:51, 22.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3042/6893 [02:23<02:48, 22.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3045/6893 [02:23<02:43, 23.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3048/6893 [02:23<02:38, 24.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3051/6893 [02:24<02:49, 22.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3054/6893 [02:24<02:55, 21.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3057/6893 [02:24<02:48, 22.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3060/6893 [02:24<02:41, 23.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3063/6893 [02:24<02:38, 24.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  44%|████▍     | 3066/6893 [02:24<02:39, 24.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3069/6893 [02:24<02:38, 24.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3072/6893 [02:24<02:41, 23.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3075/6893 [02:25<02:52, 22.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3078/6893 [02:25<02:47, 22.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3081/6893 [02:25<02:50, 22.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3084/6893 [02:25<02:48, 22.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3087/6893 [02:25<02:40, 23.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3090/6893 [02:25<02:40, 23.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3093/6893 [02:25<02:38, 24.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3096/6893 [02:25<02:35, 24.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▍     | 3099/6893 [02:26<02:41, 23.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3102/6893 [02:26<02:40, 23.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3105/6893 [02:26<02:35, 24.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3108/6893 [02:26<02:33, 24.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3111/6893 [02:26<02:33, 24.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3114/6893 [02:26<02:38, 23.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3117/6893 [02:26<02:42, 23.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3120/6893 [02:26<02:39, 23.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3123/6893 [02:27<02:38, 23.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3126/6893 [02:27<02:38, 23.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3129/6893 [02:27<02:47, 22.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3132/6893 [02:27<02:42, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  45%|████▌     | 3135/6893 [02:27<02:38, 23.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3138/6893 [02:27<02:32, 24.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3141/6893 [02:27<02:34, 24.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3144/6893 [02:27<02:37, 23.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3147/6893 [02:28<02:39, 23.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3150/6893 [02:28<02:58, 21.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3154/6893 [02:28<02:37, 23.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3157/6893 [02:28<02:40, 23.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3160/6893 [02:28<02:44, 22.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3163/6893 [02:28<02:35, 23.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3166/6893 [02:28<02:32, 24.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3169/6893 [02:29<02:34, 24.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3172/6893 [02:29<02:32, 24.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3175/6893 [02:29<02:34, 24.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3178/6893 [02:29<02:34, 23.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3181/6893 [02:29<02:32, 24.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3184/6893 [02:29<02:44, 22.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▌     | 3187/6893 [02:29<02:43, 22.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▋     | 3190/6893 [02:29<02:42, 22.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▋     | 3193/6893 [02:30<02:38, 23.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▋     | 3196/6893 [02:30<02:35, 23.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▋     | 3199/6893 [02:30<02:44, 22.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▋     | 3202/6893 [02:30<02:50, 21.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  46%|████▋     | 3205/6893 [02:30<02:43, 22.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3208/6893 [02:30<02:33, 24.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3211/6893 [02:30<02:41, 22.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3214/6893 [02:30<02:46, 22.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3217/6893 [02:31<02:38, 23.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3220/6893 [02:31<02:39, 22.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3223/6893 [02:31<02:46, 22.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3226/6893 [02:31<02:45, 22.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3229/6893 [02:31<02:41, 22.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3232/6893 [02:31<02:39, 22.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3235/6893 [02:31<02:39, 22.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3238/6893 [02:32<02:36, 23.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3241/6893 [02:32<02:39, 22.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3244/6893 [02:32<02:45, 22.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3247/6893 [02:32<02:45, 22.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3250/6893 [02:32<02:39, 22.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3253/6893 [02:32<02:32, 23.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3256/6893 [02:32<02:35, 23.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3259/6893 [02:32<02:36, 23.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3262/6893 [02:33<02:41, 22.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3265/6893 [02:33<02:49, 21.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3268/6893 [02:33<02:43, 22.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3271/6893 [02:33<02:42, 22.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  47%|████▋     | 3274/6893 [02:33<02:44, 22.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3277/6893 [02:33<02:35, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3280/6893 [02:33<02:38, 22.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3283/6893 [02:34<02:43, 22.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3286/6893 [02:34<02:37, 22.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3289/6893 [02:34<02:41, 22.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3292/6893 [02:34<02:59, 20.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3295/6893 [02:34<02:59, 20.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3298/6893 [02:34<03:01, 19.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3301/6893 [02:34<02:48, 21.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3304/6893 [02:35<02:50, 21.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3307/6893 [02:35<02:41, 22.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3310/6893 [02:35<02:37, 22.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3313/6893 [02:35<02:37, 22.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3316/6893 [02:35<02:33, 23.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3319/6893 [02:35<02:36, 22.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3322/6893 [02:35<02:39, 22.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3325/6893 [02:35<02:39, 22.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3328/6893 [02:36<02:33, 23.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3331/6893 [02:36<02:40, 22.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3334/6893 [02:36<02:37, 22.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3337/6893 [02:36<02:49, 21.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3340/6893 [02:36<02:54, 20.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  48%|████▊     | 3343/6893 [02:36<02:50, 20.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▊     | 3346/6893 [02:36<02:47, 21.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▊     | 3349/6893 [02:37<02:42, 21.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▊     | 3352/6893 [02:37<02:38, 22.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▊     | 3355/6893 [02:37<02:33, 23.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▊     | 3358/6893 [02:37<02:29, 23.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3361/6893 [02:37<02:29, 23.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3364/6893 [02:37<02:28, 23.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3367/6893 [02:37<02:23, 24.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3370/6893 [02:37<02:23, 24.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3373/6893 [02:38<02:31, 23.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3376/6893 [02:38<02:32, 23.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3379/6893 [02:38<02:33, 22.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3382/6893 [02:38<02:38, 22.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3385/6893 [02:38<02:33, 22.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3388/6893 [02:38<02:37, 22.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3391/6893 [02:38<02:38, 22.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3394/6893 [02:39<02:43, 21.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3397/6893 [02:39<02:46, 21.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3400/6893 [02:39<02:35, 22.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3403/6893 [02:39<02:30, 23.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3406/6893 [02:39<02:27, 23.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3409/6893 [02:39<02:41, 21.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  49%|████▉     | 3412/6893 [02:39<02:38, 21.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3415/6893 [02:39<02:41, 21.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3418/6893 [02:40<02:46, 20.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3421/6893 [02:40<02:43, 21.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3424/6893 [02:40<02:33, 22.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3427/6893 [02:40<02:37, 21.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3430/6893 [02:40<02:36, 22.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3433/6893 [02:40<02:29, 23.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3436/6893 [02:40<02:26, 23.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3439/6893 [02:41<02:26, 23.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3442/6893 [02:41<02:32, 22.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|████▉     | 3445/6893 [02:41<02:23, 24.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3449/6893 [02:41<02:24, 23.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3452/6893 [02:41<02:25, 23.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3455/6893 [02:41<02:26, 23.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3458/6893 [02:41<02:26, 23.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3461/6893 [02:42<02:36, 21.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3464/6893 [02:42<02:39, 21.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3467/6893 [02:42<02:49, 20.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3470/6893 [02:42<02:34, 22.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3473/6893 [02:42<02:37, 21.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3476/6893 [02:42<02:31, 22.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  50%|█████     | 3479/6893 [02:42<02:32, 22.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3482/6893 [02:42<02:35, 22.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3485/6893 [02:43<02:24, 23.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3488/6893 [02:43<02:17, 24.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3491/6893 [02:43<02:17, 24.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3494/6893 [02:43<02:21, 23.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3497/6893 [02:43<02:22, 23.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3500/6893 [02:43<03:27, 16.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3502/6893 [02:43<03:21, 16.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3504/6893 [02:44<03:15, 17.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3507/6893 [02:44<03:09, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3509/6893 [02:44<03:29, 16.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3512/6893 [02:44<03:13, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3515/6893 [02:44<02:53, 19.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3518/6893 [02:44<02:46, 20.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3521/6893 [02:44<02:35, 21.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3524/6893 [02:45<02:27, 22.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3527/6893 [02:45<02:25, 23.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████     | 3530/6893 [02:45<02:24, 23.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████▏    | 3533/6893 [02:45<02:23, 23.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████▏    | 3536/6893 [02:45<02:31, 22.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████▏    | 3539/6893 [02:45<02:32, 21.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████▏    | 3542/6893 [02:45<02:30, 22.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████▏    | 3545/6893 [02:45<02:24, 23.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  51%|█████▏    | 3548/6893 [02:46<02:16, 24.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3551/6893 [02:46<02:20, 23.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3554/6893 [02:46<02:28, 22.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3557/6893 [02:46<02:26, 22.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3560/6893 [02:46<02:31, 21.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3563/6893 [02:46<02:32, 21.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3566/6893 [02:46<02:24, 23.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3569/6893 [02:46<02:17, 24.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3572/6893 [02:47<02:18, 23.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3575/6893 [02:47<02:18, 23.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3578/6893 [02:47<02:24, 22.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3581/6893 [02:47<02:16, 24.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3584/6893 [02:47<02:09, 25.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3587/6893 [02:47<02:05, 26.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3590/6893 [02:47<02:01, 27.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3594/6893 [02:47<01:54, 28.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3598/6893 [02:48<01:53, 29.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3601/6893 [02:48<01:54, 28.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3604/6893 [02:48<01:53, 29.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3607/6893 [02:48<01:56, 28.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3610/6893 [02:48<01:55, 28.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3614/6893 [02:48<01:51, 29.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  52%|█████▏    | 3617/6893 [02:48<01:57, 27.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3620/6893 [02:48<01:54, 28.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3623/6893 [02:48<01:53, 28.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3626/6893 [02:49<01:54, 28.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3630/6893 [02:49<01:54, 28.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3633/6893 [02:49<01:53, 28.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3636/6893 [02:49<01:56, 27.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3640/6893 [02:49<01:53, 28.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3643/6893 [02:49<01:52, 28.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3646/6893 [02:49<01:53, 28.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3649/6893 [02:49<01:52, 28.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3652/6893 [02:49<01:53, 28.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3655/6893 [02:50<01:53, 28.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3659/6893 [02:50<01:49, 29.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3663/6893 [02:50<01:48, 29.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3667/6893 [02:50<01:47, 29.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3671/6893 [02:50<01:44, 30.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3675/6893 [02:50<01:42, 31.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3679/6893 [02:50<01:45, 30.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3683/6893 [02:50<01:46, 30.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  53%|█████▎    | 3687/6893 [02:51<01:44, 30.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▎    | 3691/6893 [02:51<01:44, 30.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▎    | 3695/6893 [02:51<01:50, 28.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▎    | 3699/6893 [02:51<01:45, 30.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▎    | 3703/6893 [02:51<01:46, 29.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3707/6893 [02:51<01:45, 30.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3711/6893 [02:51<01:44, 30.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3715/6893 [02:52<01:45, 30.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3719/6893 [02:52<01:45, 30.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3723/6893 [02:52<01:44, 30.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3727/6893 [02:52<01:44, 30.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3731/6893 [02:52<01:45, 30.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3735/6893 [02:52<01:47, 29.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3738/6893 [02:52<01:52, 28.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3742/6893 [02:52<01:48, 29.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3745/6893 [02:53<01:55, 27.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3749/6893 [02:53<01:50, 28.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3753/6893 [02:53<01:48, 28.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  54%|█████▍    | 3756/6893 [02:53<01:47, 29.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3760/6893 [02:53<01:45, 29.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3763/6893 [02:53<01:45, 29.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3766/6893 [02:53<01:47, 29.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3770/6893 [02:53<01:45, 29.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3773/6893 [02:54<01:48, 28.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3776/6893 [02:54<01:50, 28.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3779/6893 [02:54<01:49, 28.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3782/6893 [02:54<01:54, 27.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3786/6893 [02:54<01:51, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▍    | 3790/6893 [02:54<01:43, 30.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3794/6893 [02:54<01:45, 29.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3798/6893 [02:54<01:43, 29.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3801/6893 [02:55<01:47, 28.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3805/6893 [02:55<01:46, 28.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3808/6893 [02:55<01:47, 28.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3811/6893 [02:55<01:47, 28.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3814/6893 [02:55<01:50, 27.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3817/6893 [02:55<01:54, 26.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3821/6893 [02:55<01:45, 29.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  55%|█████▌    | 3824/6893 [02:55<01:49, 28.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3828/6893 [02:55<01:45, 29.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3832/6893 [02:56<01:43, 29.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3835/6893 [02:56<01:44, 29.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3839/6893 [02:56<01:53, 26.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3842/6893 [02:56<01:50, 27.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3845/6893 [02:56<01:50, 27.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3848/6893 [02:56<01:49, 27.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3852/6893 [02:56<01:44, 28.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3856/6893 [02:56<01:39, 30.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3860/6893 [02:57<01:41, 29.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3863/6893 [02:57<01:43, 29.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3866/6893 [02:57<01:43, 29.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3870/6893 [02:57<01:40, 30.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▌    | 3874/6893 [02:57<01:43, 29.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▋    | 3878/6893 [02:57<01:42, 29.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▋    | 3881/6893 [02:57<01:43, 29.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▋    | 3884/6893 [02:57<01:47, 27.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▋    | 3887/6893 [02:58<01:56, 25.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▋    | 3890/6893 [02:58<01:58, 25.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  56%|█████▋    | 3893/6893 [02:58<02:03, 24.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3896/6893 [02:58<02:03, 24.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3899/6893 [02:58<02:09, 23.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3902/6893 [02:58<02:12, 22.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3905/6893 [02:58<02:10, 22.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3908/6893 [02:58<02:06, 23.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3911/6893 [02:59<02:09, 23.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3914/6893 [02:59<02:11, 22.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3917/6893 [02:59<02:02, 24.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3920/6893 [02:59<02:03, 24.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3923/6893 [02:59<02:04, 23.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3926/6893 [02:59<02:08, 23.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3929/6893 [02:59<02:05, 23.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3932/6893 [02:59<02:02, 24.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3935/6893 [03:00<02:06, 23.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3938/6893 [03:00<02:04, 23.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3941/6893 [03:00<02:16, 21.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3944/6893 [03:00<02:18, 21.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3948/6893 [03:00<02:06, 23.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3951/6893 [03:00<02:04, 23.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3954/6893 [03:00<02:00, 24.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3957/6893 [03:01<02:01, 24.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3960/6893 [03:01<02:10, 22.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  57%|█████▋    | 3963/6893 [03:01<02:07, 22.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3966/6893 [03:01<02:04, 23.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3969/6893 [03:01<02:02, 23.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3972/6893 [03:01<02:00, 24.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3975/6893 [03:01<02:01, 24.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3978/6893 [03:01<01:59, 24.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3981/6893 [03:02<02:00, 24.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3984/6893 [03:02<02:01, 23.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3987/6893 [03:02<02:05, 23.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3990/6893 [03:02<02:02, 23.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3994/6893 [03:02<01:54, 25.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 3997/6893 [03:02<01:55, 25.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4000/6893 [03:02<01:56, 24.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4003/6893 [03:02<01:57, 24.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4006/6893 [03:03<01:59, 24.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4009/6893 [03:03<01:56, 24.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4012/6893 [03:03<02:02, 23.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4015/6893 [03:03<02:02, 23.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4018/6893 [03:03<02:03, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4021/6893 [03:03<02:07, 22.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4024/6893 [03:03<02:00, 23.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4027/6893 [03:03<02:00, 23.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  58%|█████▊    | 4030/6893 [03:04<01:57, 24.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▊    | 4033/6893 [03:04<02:03, 23.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▊    | 4036/6893 [03:04<02:04, 22.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▊    | 4039/6893 [03:04<02:08, 22.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▊    | 4042/6893 [03:04<02:01, 23.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▊    | 4045/6893 [03:04<01:58, 24.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▊    | 4048/6893 [03:04<02:04, 22.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4051/6893 [03:05<02:03, 22.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4054/6893 [03:05<02:02, 23.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4057/6893 [03:05<02:04, 22.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4060/6893 [03:05<02:03, 22.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4063/6893 [03:05<02:02, 23.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4066/6893 [03:05<02:10, 21.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4069/6893 [03:05<02:11, 21.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4072/6893 [03:05<02:07, 22.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4075/6893 [03:06<02:03, 22.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4078/6893 [03:06<01:58, 23.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4081/6893 [03:06<01:58, 23.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4084/6893 [03:06<02:05, 22.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4087/6893 [03:06<02:05, 22.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4090/6893 [03:06<02:00, 23.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4093/6893 [03:06<02:06, 22.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4096/6893 [03:06<01:59, 23.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  59%|█████▉    | 4099/6893 [03:07<01:59, 23.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4102/6893 [03:07<02:04, 22.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4105/6893 [03:07<02:01, 22.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4108/6893 [03:07<01:53, 24.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4111/6893 [03:07<02:05, 22.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4114/6893 [03:07<02:00, 23.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4117/6893 [03:07<02:01, 22.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4120/6893 [03:08<01:54, 24.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4123/6893 [03:08<01:51, 24.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4126/6893 [03:08<01:52, 24.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4129/6893 [03:08<01:53, 24.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4132/6893 [03:08<01:51, 24.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|█████▉    | 4135/6893 [03:08<01:58, 23.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4138/6893 [03:08<02:00, 22.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4141/6893 [03:08<01:57, 23.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4144/6893 [03:09<01:51, 24.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4147/6893 [03:09<01:47, 25.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4150/6893 [03:09<01:53, 24.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4153/6893 [03:09<01:54, 24.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4156/6893 [03:09<01:53, 24.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4159/6893 [03:09<01:47, 25.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4162/6893 [03:09<01:44, 26.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4165/6893 [03:09<01:45, 25.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  60%|██████    | 4168/6893 [03:09<01:48, 25.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4171/6893 [03:10<01:46, 25.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4174/6893 [03:10<01:48, 25.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4178/6893 [03:10<01:42, 26.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4181/6893 [03:10<01:41, 26.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4184/6893 [03:10<01:42, 26.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4188/6893 [03:10<01:35, 28.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4191/6893 [03:10<01:37, 27.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4194/6893 [03:10<01:44, 25.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4197/6893 [03:11<01:44, 25.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4200/6893 [03:11<01:42, 26.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4203/6893 [03:11<01:41, 26.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4206/6893 [03:11<01:42, 26.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4209/6893 [03:11<01:42, 26.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4212/6893 [03:11<01:41, 26.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4215/6893 [03:11<01:41, 26.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████    | 4219/6893 [03:11<01:40, 26.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████▏   | 4222/6893 [03:11<01:38, 27.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████▏   | 4225/6893 [03:12<01:40, 26.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████▏   | 4228/6893 [03:12<01:43, 25.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████▏   | 4231/6893 [03:12<01:40, 26.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████▏   | 4234/6893 [03:12<01:41, 26.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  61%|██████▏   | 4237/6893 [03:12<01:42, 25.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4240/6893 [03:12<01:42, 25.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4243/6893 [03:12<01:40, 26.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4246/6893 [03:12<01:43, 25.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4249/6893 [03:13<01:42, 25.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4252/6893 [03:13<01:44, 25.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4255/6893 [03:13<01:44, 25.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4258/6893 [03:13<01:40, 26.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4261/6893 [03:13<01:43, 25.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4264/6893 [03:13<01:45, 24.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4267/6893 [03:13<01:52, 23.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4270/6893 [03:13<01:48, 24.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4273/6893 [03:14<01:46, 24.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4276/6893 [03:14<01:48, 24.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4279/6893 [03:14<01:49, 23.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4282/6893 [03:14<01:48, 24.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4285/6893 [03:14<01:48, 24.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4288/6893 [03:14<01:50, 23.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4291/6893 [03:14<01:47, 24.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4294/6893 [03:14<01:47, 24.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4297/6893 [03:15<01:43, 24.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4300/6893 [03:15<01:47, 24.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4303/6893 [03:15<01:42, 25.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  62%|██████▏   | 4306/6893 [03:15<01:39, 26.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4309/6893 [03:15<01:36, 26.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4312/6893 [03:15<01:37, 26.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4316/6893 [03:15<01:35, 27.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4319/6893 [03:15<01:33, 27.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4322/6893 [03:15<01:31, 28.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4325/6893 [03:16<01:31, 28.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4328/6893 [03:16<01:34, 27.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4331/6893 [03:16<01:36, 26.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4334/6893 [03:16<01:37, 26.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4337/6893 [03:16<01:41, 25.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4340/6893 [03:16<01:46, 24.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4344/6893 [03:16<01:37, 26.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4347/6893 [03:16<01:36, 26.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4350/6893 [03:17<01:35, 26.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4353/6893 [03:17<01:38, 25.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4356/6893 [03:17<01:36, 26.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4359/6893 [03:17<01:37, 26.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4362/6893 [03:17<01:36, 26.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4365/6893 [03:17<01:37, 26.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4369/6893 [03:17<01:33, 26.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4372/6893 [03:17<01:36, 26.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  63%|██████▎   | 4375/6893 [03:17<01:33, 26.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▎   | 4378/6893 [03:18<01:31, 27.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▎   | 4381/6893 [03:18<01:33, 26.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▎   | 4384/6893 [03:18<01:32, 27.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▎   | 4387/6893 [03:18<01:33, 26.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▎   | 4390/6893 [03:18<01:34, 26.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▎   | 4393/6893 [03:18<01:33, 26.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4396/6893 [03:18<01:36, 25.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4399/6893 [03:18<01:36, 25.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4402/6893 [03:18<01:34, 26.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4405/6893 [03:19<01:34, 26.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4408/6893 [03:19<01:35, 25.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4411/6893 [03:19<01:37, 25.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4414/6893 [03:19<01:37, 25.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4417/6893 [03:19<01:40, 24.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4420/6893 [03:19<01:41, 24.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4423/6893 [03:19<01:37, 25.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4426/6893 [03:19<01:37, 25.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4429/6893 [03:20<01:40, 24.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4432/6893 [03:20<01:36, 25.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4435/6893 [03:20<01:34, 25.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4438/6893 [03:20<01:32, 26.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4441/6893 [03:20<01:38, 24.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  64%|██████▍   | 4444/6893 [03:20<01:48, 22.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4447/6893 [03:20<01:59, 20.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4450/6893 [03:21<02:03, 19.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4453/6893 [03:21<02:03, 19.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4456/6893 [03:21<02:16, 17.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4459/6893 [03:21<02:13, 18.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4462/6893 [03:21<02:08, 18.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4464/6893 [03:21<02:09, 18.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4466/6893 [03:21<02:21, 17.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4468/6893 [03:22<02:20, 17.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4470/6893 [03:22<02:23, 16.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4472/6893 [03:22<02:23, 16.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4474/6893 [03:22<02:25, 16.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4477/6893 [03:22<02:11, 18.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▍   | 4479/6893 [03:22<02:09, 18.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4481/6893 [03:22<02:09, 18.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4483/6893 [03:22<02:08, 18.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4485/6893 [03:22<02:07, 18.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4487/6893 [03:23<02:08, 18.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4490/6893 [03:23<01:57, 20.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4493/6893 [03:23<02:06, 19.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4495/6893 [03:23<02:05, 19.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4498/6893 [03:23<02:00, 19.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4501/6893 [03:23<02:01, 19.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4503/6893 [03:23<02:02, 19.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4505/6893 [03:24<02:02, 19.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4508/6893 [03:24<02:01, 19.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4510/6893 [03:24<02:05, 18.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  65%|██████▌   | 4513/6893 [03:24<02:00, 19.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4515/6893 [03:24<02:01, 19.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4517/6893 [03:24<02:01, 19.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4519/6893 [03:24<02:05, 18.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4521/6893 [03:24<02:08, 18.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4524/6893 [03:24<01:58, 20.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4526/6893 [03:25<01:59, 19.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4528/6893 [03:25<01:59, 19.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4530/6893 [03:25<02:00, 19.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4532/6893 [03:25<02:07, 18.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4535/6893 [03:25<02:05, 18.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4537/6893 [03:25<02:06, 18.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4539/6893 [03:25<02:07, 18.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4541/6893 [03:25<02:10, 18.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4543/6893 [03:26<02:07, 18.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4545/6893 [03:26<02:10, 18.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4547/6893 [03:26<02:15, 17.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4549/6893 [03:26<02:19, 16.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4551/6893 [03:26<02:15, 17.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4554/6893 [03:26<02:09, 18.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4556/6893 [03:26<02:07, 18.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4558/6893 [03:26<02:06, 18.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4560/6893 [03:26<02:09, 18.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4562/6893 [03:27<02:14, 17.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4564/6893 [03:27<02:31, 15.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▌   | 4566/6893 [03:27<02:21, 16.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4568/6893 [03:27<02:15, 17.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4571/6893 [03:27<02:09, 17.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4574/6893 [03:27<01:59, 19.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4576/6893 [03:27<02:04, 18.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4578/6893 [03:27<02:09, 17.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4580/6893 [03:28<02:11, 17.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  66%|██████▋   | 4583/6893 [03:28<02:07, 18.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4585/6893 [03:28<02:07, 18.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4587/6893 [03:28<02:13, 17.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4589/6893 [03:28<02:22, 16.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4591/6893 [03:28<02:30, 15.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4593/6893 [03:28<02:24, 15.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4596/6893 [03:29<02:12, 17.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4599/6893 [03:29<01:58, 19.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4601/6893 [03:29<02:07, 18.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4603/6893 [03:29<02:12, 17.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4605/6893 [03:29<02:12, 17.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4607/6893 [03:29<02:13, 17.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4609/6893 [03:29<02:16, 16.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4611/6893 [03:29<02:15, 16.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4613/6893 [03:30<02:17, 16.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4615/6893 [03:30<02:14, 16.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4617/6893 [03:30<02:12, 17.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4620/6893 [03:30<02:08, 17.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4622/6893 [03:30<02:08, 17.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4624/6893 [03:30<02:07, 17.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4626/6893 [03:30<02:05, 18.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4629/6893 [03:30<01:53, 19.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4631/6893 [03:31<01:56, 19.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4633/6893 [03:31<01:57, 19.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4635/6893 [03:31<02:06, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4638/6893 [03:31<02:01, 18.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4640/6893 [03:31<02:08, 17.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4643/6893 [03:31<02:01, 18.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4645/6893 [03:31<02:00, 18.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4647/6893 [03:31<02:00, 18.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4649/6893 [03:31<02:00, 18.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  67%|██████▋   | 4652/6893 [03:32<01:53, 19.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4655/6893 [03:32<01:55, 19.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4657/6893 [03:32<02:03, 18.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4660/6893 [03:32<02:03, 18.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4662/6893 [03:32<02:00, 18.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4664/6893 [03:32<02:01, 18.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4666/6893 [03:32<01:59, 18.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4668/6893 [03:33<02:03, 18.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4670/6893 [03:33<02:01, 18.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4673/6893 [03:33<01:59, 18.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4676/6893 [03:33<01:55, 19.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4678/6893 [03:33<01:55, 19.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4681/6893 [03:33<01:55, 19.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4683/6893 [03:33<01:56, 18.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4685/6893 [03:33<02:07, 17.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4688/6893 [03:34<01:58, 18.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4690/6893 [03:34<02:00, 18.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4692/6893 [03:34<01:59, 18.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4694/6893 [03:34<02:05, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4696/6893 [03:34<02:05, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4699/6893 [03:34<01:55, 19.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4702/6893 [03:34<01:49, 19.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4704/6893 [03:34<02:01, 18.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4707/6893 [03:35<01:55, 18.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4709/6893 [03:35<01:59, 18.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4711/6893 [03:35<01:56, 18.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4714/6893 [03:35<01:48, 20.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4717/6893 [03:35<01:53, 19.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  68%|██████▊   | 4720/6893 [03:35<01:48, 19.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▊   | 4723/6893 [03:35<01:46, 20.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▊   | 4726/6893 [03:36<01:47, 20.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▊   | 4729/6893 [03:36<01:48, 20.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▊   | 4732/6893 [03:36<01:53, 18.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▊   | 4734/6893 [03:36<01:54, 18.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▊   | 4736/6893 [03:36<02:00, 17.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4739/6893 [03:36<01:53, 18.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4742/6893 [03:36<01:50, 19.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4744/6893 [03:37<02:03, 17.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4747/6893 [03:37<01:56, 18.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4750/6893 [03:37<01:53, 18.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4752/6893 [03:37<01:56, 18.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4755/6893 [03:37<01:47, 19.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4758/6893 [03:37<02:05, 16.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4760/6893 [03:37<02:01, 17.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4762/6893 [03:38<02:07, 16.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4764/6893 [03:38<02:11, 16.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4766/6893 [03:38<02:09, 16.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4769/6893 [03:38<02:00, 17.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4772/6893 [03:38<01:51, 18.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4774/6893 [03:38<01:54, 18.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4777/6893 [03:38<01:56, 18.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4779/6893 [03:38<01:54, 18.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4781/6893 [03:39<01:55, 18.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4784/6893 [03:39<01:53, 18.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4786/6893 [03:39<01:51, 18.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  69%|██████▉   | 4789/6893 [03:39<01:45, 20.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4792/6893 [03:39<01:57, 17.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4794/6893 [03:39<01:58, 17.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4796/6893 [03:39<02:05, 16.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4798/6893 [03:40<02:07, 16.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4800/6893 [03:40<02:07, 16.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4802/6893 [03:40<02:01, 17.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4804/6893 [03:40<01:56, 17.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4806/6893 [03:40<01:57, 17.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4809/6893 [03:40<01:44, 19.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4812/6893 [03:40<01:57, 17.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4815/6893 [03:41<01:53, 18.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4817/6893 [03:41<01:55, 17.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4819/6893 [03:41<01:57, 17.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4821/6893 [03:41<01:57, 17.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4823/6893 [03:41<01:53, 18.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|██████▉   | 4825/6893 [03:41<01:55, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4827/6893 [03:41<01:53, 18.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4829/6893 [03:41<02:00, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4831/6893 [03:41<01:56, 17.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4833/6893 [03:42<02:09, 15.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4836/6893 [03:42<02:00, 17.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4838/6893 [03:42<01:58, 17.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4840/6893 [03:42<01:55, 17.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4843/6893 [03:42<01:48, 18.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4845/6893 [03:42<01:47, 19.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4847/6893 [03:42<01:54, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4849/6893 [03:42<02:04, 16.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4851/6893 [03:43<02:03, 16.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4854/6893 [03:43<01:54, 17.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4856/6893 [03:43<01:55, 17.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  70%|███████   | 4859/6893 [03:43<01:48, 18.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4862/6893 [03:43<01:40, 20.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4865/6893 [03:43<01:43, 19.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4868/6893 [03:43<01:39, 20.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4871/6893 [03:44<01:42, 19.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4873/6893 [03:44<01:46, 19.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4875/6893 [03:44<01:47, 18.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4877/6893 [03:44<01:45, 19.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4880/6893 [03:44<01:38, 20.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4883/6893 [03:44<01:38, 20.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4886/6893 [03:44<01:42, 19.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4889/6893 [03:44<01:40, 19.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4892/6893 [03:45<01:45, 18.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4894/6893 [03:45<01:51, 17.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4896/6893 [03:45<01:50, 18.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4898/6893 [03:45<02:00, 16.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4900/6893 [03:45<01:59, 16.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4903/6893 [03:45<01:47, 18.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4905/6893 [03:45<01:47, 18.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4907/6893 [03:46<01:51, 17.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4909/6893 [03:46<01:50, 17.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████   | 4911/6893 [03:46<01:50, 17.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4913/6893 [03:46<01:54, 17.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4916/6893 [03:46<01:50, 17.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4918/6893 [03:46<01:55, 17.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4920/6893 [03:46<01:51, 17.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4923/6893 [03:46<01:48, 18.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4925/6893 [03:47<01:46, 18.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  71%|███████▏  | 4927/6893 [03:47<01:47, 18.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4930/6893 [03:47<01:44, 18.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4933/6893 [03:47<01:45, 18.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4935/6893 [03:47<01:44, 18.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4938/6893 [03:47<01:39, 19.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4941/6893 [03:47<01:32, 21.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4944/6893 [03:47<01:27, 22.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4947/6893 [03:48<01:24, 23.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4950/6893 [03:48<01:19, 24.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4953/6893 [03:48<01:16, 25.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4956/6893 [03:48<01:12, 26.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4959/6893 [03:48<01:11, 27.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4962/6893 [03:48<01:10, 27.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4965/6893 [03:48<01:12, 26.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4968/6893 [03:48<01:12, 26.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4971/6893 [03:48<01:12, 26.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4974/6893 [03:49<01:11, 26.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4977/6893 [03:49<01:11, 26.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4980/6893 [03:49<01:13, 25.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4983/6893 [03:49<01:16, 24.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4986/6893 [03:49<01:18, 24.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4989/6893 [03:49<01:15, 25.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4993/6893 [03:49<01:09, 27.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  72%|███████▏  | 4996/6893 [03:49<01:09, 27.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 4999/6893 [03:50<01:09, 27.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5003/6893 [03:50<01:06, 28.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5006/6893 [03:50<01:06, 28.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5009/6893 [03:50<01:07, 27.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5012/6893 [03:50<01:08, 27.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5015/6893 [03:50<01:09, 26.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5018/6893 [03:50<01:10, 26.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5021/6893 [03:50<01:10, 26.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5024/6893 [03:50<01:12, 25.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5027/6893 [03:51<01:11, 26.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5030/6893 [03:51<01:09, 26.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5033/6893 [03:51<01:10, 26.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5036/6893 [03:51<01:11, 26.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5039/6893 [03:51<01:10, 26.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5042/6893 [03:51<01:12, 25.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5045/6893 [03:51<01:12, 25.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5048/6893 [03:51<01:12, 25.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5051/6893 [03:51<01:12, 25.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5055/6893 [03:52<01:07, 27.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5058/6893 [03:52<01:05, 27.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5061/6893 [03:52<01:10, 26.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  73%|███████▎  | 5064/6893 [03:52<01:12, 25.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▎  | 5067/6893 [03:52<01:13, 24.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▎  | 5070/6893 [03:52<01:12, 25.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▎  | 5073/6893 [03:52<01:11, 25.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▎  | 5076/6893 [03:52<01:08, 26.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▎  | 5079/6893 [03:53<01:06, 27.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▎  | 5082/6893 [03:53<01:07, 26.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5085/6893 [03:53<01:08, 26.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5088/6893 [03:53<01:06, 26.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5091/6893 [03:53<01:07, 26.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5094/6893 [03:53<01:05, 27.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5097/6893 [03:53<01:05, 27.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5100/6893 [03:53<01:09, 25.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5103/6893 [03:53<01:08, 26.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5106/6893 [03:54<01:08, 25.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5109/6893 [03:54<01:08, 26.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5112/6893 [03:54<01:09, 25.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5115/6893 [03:54<01:06, 26.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5118/6893 [03:54<01:08, 25.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5121/6893 [03:54<01:06, 26.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5124/6893 [03:54<01:08, 25.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5127/6893 [03:54<01:09, 25.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5130/6893 [03:54<01:08, 25.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  74%|███████▍  | 5134/6893 [03:55<01:02, 27.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5138/6893 [03:55<01:01, 28.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5141/6893 [03:55<01:03, 27.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5145/6893 [03:55<01:01, 28.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5148/6893 [03:55<01:03, 27.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5151/6893 [03:55<01:02, 27.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5154/6893 [03:55<01:03, 27.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5157/6893 [03:55<01:04, 26.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5160/6893 [03:56<01:08, 25.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5163/6893 [03:56<01:06, 25.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5166/6893 [03:56<01:06, 25.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▍  | 5169/6893 [03:56<01:05, 26.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5172/6893 [03:56<01:03, 26.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5175/6893 [03:56<01:02, 27.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5178/6893 [03:56<01:06, 25.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5181/6893 [03:56<01:06, 25.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5184/6893 [03:57<01:11, 23.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5187/6893 [03:57<01:11, 23.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5190/6893 [03:57<01:07, 25.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5193/6893 [03:57<01:04, 26.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5197/6893 [03:57<01:01, 27.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5200/6893 [03:57<01:00, 27.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  75%|███████▌  | 5203/6893 [03:57<01:03, 26.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5206/6893 [03:57<01:01, 27.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5209/6893 [03:57<01:03, 26.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5212/6893 [03:58<01:02, 26.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5215/6893 [03:58<01:04, 26.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5218/6893 [03:58<01:04, 25.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5221/6893 [03:58<01:04, 25.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5224/6893 [03:58<01:05, 25.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5228/6893 [03:58<01:02, 26.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5231/6893 [03:58<01:05, 25.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5234/6893 [03:58<01:05, 25.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5237/6893 [03:59<01:03, 25.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5241/6893 [03:59<01:00, 27.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5244/6893 [03:59<01:03, 26.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5247/6893 [03:59<01:05, 25.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5250/6893 [03:59<01:05, 25.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▌  | 5253/6893 [03:59<01:04, 25.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▋  | 5256/6893 [03:59<01:05, 25.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▋  | 5259/6893 [03:59<01:05, 24.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▋  | 5262/6893 [04:00<01:04, 25.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▋  | 5265/6893 [04:00<01:05, 24.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▋  | 5268/6893 [04:00<01:05, 24.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  76%|███████▋  | 5271/6893 [04:00<01:05, 24.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5274/6893 [04:00<01:03, 25.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5277/6893 [04:00<01:01, 26.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5281/6893 [04:00<00:57, 28.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5284/6893 [04:00<00:56, 28.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5287/6893 [04:00<01:00, 26.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5290/6893 [04:01<01:03, 25.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5293/6893 [04:01<01:03, 25.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5296/6893 [04:01<01:02, 25.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5299/6893 [04:01<01:01, 25.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5302/6893 [04:01<00:59, 26.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5305/6893 [04:01<00:58, 27.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5308/6893 [04:01<00:58, 27.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5311/6893 [04:01<00:59, 26.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5314/6893 [04:01<00:59, 26.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5317/6893 [04:02<00:57, 27.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5320/6893 [04:02<00:58, 26.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5323/6893 [04:02<00:57, 27.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5326/6893 [04:02<00:56, 27.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5330/6893 [04:02<00:54, 28.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5333/6893 [04:02<00:57, 27.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5336/6893 [04:02<00:59, 26.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5339/6893 [04:02<00:58, 26.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  77%|███████▋  | 5342/6893 [04:03<00:57, 27.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5345/6893 [04:03<00:56, 27.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5349/6893 [04:03<00:55, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5353/6893 [04:03<00:54, 28.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5357/6893 [04:03<00:52, 29.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5361/6893 [04:03<00:53, 28.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5364/6893 [04:03<00:53, 28.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5367/6893 [04:03<00:52, 28.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5370/6893 [04:03<00:54, 28.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5373/6893 [04:04<00:55, 27.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5376/6893 [04:04<00:57, 26.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5379/6893 [04:04<00:59, 25.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5382/6893 [04:04<00:57, 26.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5385/6893 [04:04<00:58, 25.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5388/6893 [04:04<00:57, 26.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5391/6893 [04:04<00:56, 26.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5395/6893 [04:04<00:51, 28.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5399/6893 [04:05<00:52, 28.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5402/6893 [04:05<00:54, 27.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5405/6893 [04:05<00:53, 27.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  78%|███████▊  | 5409/6893 [04:05<00:51, 28.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▊  | 5413/6893 [04:05<00:50, 29.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▊  | 5416/6893 [04:05<00:50, 29.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▊  | 5419/6893 [04:05<00:51, 28.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▊  | 5422/6893 [04:05<00:51, 28.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▊  | 5425/6893 [04:05<00:53, 27.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▊  | 5428/6893 [04:06<00:54, 26.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5432/6893 [04:06<00:52, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5435/6893 [04:06<00:52, 27.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5438/6893 [04:06<00:52, 27.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5441/6893 [04:06<00:51, 27.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5444/6893 [04:06<00:50, 28.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5447/6893 [04:06<00:51, 28.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5450/6893 [04:06<00:50, 28.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5453/6893 [04:06<00:52, 27.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5456/6893 [04:07<00:52, 27.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5459/6893 [04:07<00:54, 26.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5462/6893 [04:07<00:52, 27.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5465/6893 [04:07<00:52, 26.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5468/6893 [04:07<00:53, 26.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5471/6893 [04:07<00:52, 27.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5474/6893 [04:07<00:52, 27.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  79%|███████▉  | 5478/6893 [04:07<00:50, 28.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5481/6893 [04:08<00:49, 28.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5485/6893 [04:08<00:48, 28.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5488/6893 [04:08<00:48, 28.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5491/6893 [04:08<00:51, 27.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5494/6893 [04:08<00:51, 27.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5498/6893 [04:08<00:48, 28.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5501/6893 [04:08<00:51, 27.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5505/6893 [04:08<00:48, 28.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5508/6893 [04:08<00:48, 28.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|███████▉  | 5511/6893 [04:09<00:49, 27.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5515/6893 [04:09<00:47, 29.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5518/6893 [04:09<00:49, 27.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5521/6893 [04:09<00:50, 27.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5524/6893 [04:09<00:49, 27.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5527/6893 [04:09<00:49, 27.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5530/6893 [04:09<00:48, 27.94it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5534/6893 [04:09<00:47, 28.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5537/6893 [04:10<00:47, 28.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5541/6893 [04:10<00:45, 29.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5544/6893 [04:10<00:45, 29.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  80%|████████  | 5547/6893 [04:10<00:45, 29.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5550/6893 [04:10<00:46, 29.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5553/6893 [04:10<00:46, 28.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5556/6893 [04:10<00:46, 28.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5559/6893 [04:10<00:46, 28.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5562/6893 [04:10<00:47, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5566/6893 [04:11<00:45, 28.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5569/6893 [04:11<00:46, 28.37it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5573/6893 [04:11<00:45, 28.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5576/6893 [04:11<00:45, 29.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5579/6893 [04:11<00:45, 28.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5582/6893 [04:11<00:46, 28.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5586/6893 [04:11<00:44, 29.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5589/6893 [04:11<00:44, 29.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5592/6893 [04:11<00:45, 28.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5595/6893 [04:12<00:46, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████  | 5598/6893 [04:12<00:46, 27.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████▏ | 5601/6893 [04:12<00:48, 26.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████▏ | 5605/6893 [04:12<00:44, 29.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████▏ | 5609/6893 [04:12<00:42, 29.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████▏ | 5613/6893 [04:12<00:41, 30.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  81%|████████▏ | 5617/6893 [04:12<00:42, 30.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5621/6893 [04:12<00:42, 29.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5624/6893 [04:13<00:43, 29.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5628/6893 [04:13<00:42, 29.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5632/6893 [04:13<00:41, 30.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5636/6893 [04:13<00:43, 29.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5639/6893 [04:13<00:43, 28.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5642/6893 [04:13<00:45, 27.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5645/6893 [04:13<00:45, 27.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5649/6893 [04:13<00:43, 28.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5652/6893 [04:13<00:43, 28.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5655/6893 [04:14<00:43, 28.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5658/6893 [04:14<00:43, 28.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5662/6893 [04:14<00:41, 29.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5665/6893 [04:14<00:41, 29.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5669/6893 [04:14<00:40, 30.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5673/6893 [04:14<00:39, 30.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5677/6893 [04:14<00:39, 30.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5681/6893 [04:14<00:38, 31.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  82%|████████▏ | 5685/6893 [04:15<00:38, 31.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5689/6893 [04:15<00:39, 30.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5693/6893 [04:15<00:39, 30.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5697/6893 [04:15<00:39, 30.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5701/6893 [04:15<00:39, 30.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5705/6893 [04:15<00:39, 29.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5708/6893 [04:15<00:39, 29.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5711/6893 [04:15<00:41, 28.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5714/6893 [04:16<00:40, 28.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5717/6893 [04:16<00:40, 29.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5720/6893 [04:16<00:40, 29.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5724/6893 [04:16<00:38, 30.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5728/6893 [04:16<00:39, 29.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5731/6893 [04:16<00:40, 28.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5735/6893 [04:16<00:39, 29.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5739/6893 [04:16<00:37, 30.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5743/6893 [04:17<00:40, 28.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5746/6893 [04:17<00:41, 27.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5749/6893 [04:17<00:43, 26.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5752/6893 [04:17<00:42, 27.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  83%|████████▎ | 5755/6893 [04:17<00:42, 26.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▎ | 5758/6893 [04:17<00:41, 27.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▎ | 5761/6893 [04:17<00:41, 27.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▎ | 5765/6893 [04:17<00:39, 28.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▎ | 5768/6893 [04:17<00:40, 27.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▎ | 5771/6893 [04:18<00:39, 28.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5774/6893 [04:18<00:39, 28.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5777/6893 [04:18<00:41, 27.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5780/6893 [04:18<00:40, 27.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5783/6893 [04:18<00:40, 27.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5786/6893 [04:18<00:39, 27.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5789/6893 [04:18<00:39, 28.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5792/6893 [04:18<00:39, 27.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5795/6893 [04:18<00:39, 27.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5798/6893 [04:19<00:39, 27.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5801/6893 [04:19<00:38, 28.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5804/6893 [04:19<00:38, 28.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5807/6893 [04:19<00:39, 27.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5810/6893 [04:19<00:38, 28.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5813/6893 [04:19<00:37, 28.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5816/6893 [04:19<00:37, 28.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5820/6893 [04:19<00:36, 29.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  84%|████████▍ | 5823/6893 [04:19<00:36, 29.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5826/6893 [04:20<00:35, 29.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5829/6893 [04:20<00:36, 29.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5832/6893 [04:20<00:36, 28.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5835/6893 [04:20<00:36, 29.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5839/6893 [04:20<00:35, 29.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5842/6893 [04:20<00:36, 28.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5846/6893 [04:20<00:35, 29.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5850/6893 [04:20<00:34, 30.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5854/6893 [04:20<00:33, 30.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▍ | 5858/6893 [04:21<00:34, 29.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5861/6893 [04:21<00:35, 28.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5864/6893 [04:21<00:36, 28.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5867/6893 [04:21<00:36, 28.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5870/6893 [04:21<00:36, 28.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5873/6893 [04:21<00:36, 27.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5876/6893 [04:21<00:36, 27.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5879/6893 [04:21<00:36, 27.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5882/6893 [04:21<00:35, 28.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5885/6893 [04:22<00:36, 27.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5889/6893 [04:22<00:34, 29.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  85%|████████▌ | 5893/6893 [04:22<00:33, 30.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5897/6893 [04:22<00:32, 30.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5901/6893 [04:22<00:37, 26.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5904/6893 [04:22<00:41, 24.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5907/6893 [04:22<00:43, 22.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5910/6893 [04:23<00:47, 20.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5913/6893 [04:23<00:47, 20.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5916/6893 [04:23<00:46, 21.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5919/6893 [04:23<00:45, 21.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5922/6893 [04:23<00:50, 19.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5924/6893 [04:23<00:55, 17.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5926/6893 [04:23<00:53, 18.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5928/6893 [04:24<00:53, 18.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5930/6893 [04:24<00:52, 18.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5933/6893 [04:24<00:51, 18.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5935/6893 [04:24<00:51, 18.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5937/6893 [04:24<00:51, 18.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5940/6893 [04:24<00:48, 19.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5943/6893 [04:24<00:49, 19.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▌ | 5945/6893 [04:24<00:50, 18.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5947/6893 [04:25<00:50, 18.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5949/6893 [04:25<00:51, 18.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5951/6893 [04:25<00:50, 18.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5953/6893 [04:25<00:50, 18.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5955/6893 [04:25<00:52, 17.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5958/6893 [04:25<00:49, 18.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  86%|████████▋ | 5960/6893 [04:25<00:50, 18.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5963/6893 [04:25<00:47, 19.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5965/6893 [04:26<00:50, 18.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5967/6893 [04:26<00:50, 18.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5969/6893 [04:26<00:54, 17.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5971/6893 [04:26<00:52, 17.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5974/6893 [04:26<00:47, 19.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5976/6893 [04:26<00:48, 19.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5979/6893 [04:26<00:47, 19.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5981/6893 [04:26<00:49, 18.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5983/6893 [04:27<00:52, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5986/6893 [04:27<00:49, 18.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5988/6893 [04:27<00:50, 17.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5990/6893 [04:27<00:51, 17.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5993/6893 [04:27<00:49, 18.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5995/6893 [04:27<00:56, 15.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 5998/6893 [04:27<00:50, 17.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6001/6893 [04:28<00:46, 19.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6003/6893 [04:28<00:45, 19.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6005/6893 [04:28<00:47, 18.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6007/6893 [04:28<00:50, 17.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6009/6893 [04:28<00:50, 17.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6011/6893 [04:28<00:50, 17.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6013/6893 [04:28<00:52, 16.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6015/6893 [04:28<00:51, 16.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6017/6893 [04:28<00:50, 17.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6019/6893 [04:29<00:48, 18.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6021/6893 [04:29<00:48, 18.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6023/6893 [04:29<00:49, 17.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6025/6893 [04:29<00:49, 17.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6027/6893 [04:29<00:48, 17.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  87%|████████▋ | 6030/6893 [04:29<00:45, 19.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6032/6893 [04:29<00:46, 18.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6034/6893 [04:29<00:45, 18.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6036/6893 [04:30<00:47, 18.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6038/6893 [04:30<00:48, 17.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6041/6893 [04:30<00:46, 18.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6044/6893 [04:30<00:42, 19.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6047/6893 [04:30<00:40, 21.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6050/6893 [04:30<00:40, 20.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6053/6893 [04:30<00:44, 18.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6055/6893 [04:31<00:46, 18.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6057/6893 [04:31<00:46, 17.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6059/6893 [04:31<00:46, 17.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6062/6893 [04:31<00:43, 18.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6065/6893 [04:31<00:43, 19.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6068/6893 [04:31<00:40, 20.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6071/6893 [04:31<00:38, 21.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6074/6893 [04:31<00:41, 19.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6077/6893 [04:32<00:39, 20.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6080/6893 [04:32<00:40, 19.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6083/6893 [04:32<00:40, 19.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6086/6893 [04:32<00:40, 19.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6088/6893 [04:32<00:40, 19.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6090/6893 [04:32<00:42, 18.71it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6092/6893 [04:32<00:46, 17.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6094/6893 [04:33<00:44, 17.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6097/6893 [04:33<00:40, 19.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  88%|████████▊ | 6099/6893 [04:33<00:41, 19.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6101/6893 [04:33<00:42, 18.77it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6104/6893 [04:33<00:40, 19.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6106/6893 [04:33<00:40, 19.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6108/6893 [04:33<00:40, 19.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6110/6893 [04:33<00:40, 19.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6112/6893 [04:33<00:41, 18.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6114/6893 [04:34<00:42, 18.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▊ | 6117/6893 [04:34<00:39, 19.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6119/6893 [04:34<00:39, 19.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6122/6893 [04:34<00:36, 20.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6125/6893 [04:34<00:41, 18.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6127/6893 [04:34<00:42, 18.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6129/6893 [04:34<00:41, 18.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6131/6893 [04:34<00:44, 17.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6133/6893 [04:35<00:43, 17.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6135/6893 [04:35<00:42, 17.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6137/6893 [04:35<00:42, 17.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6139/6893 [04:35<00:42, 17.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6141/6893 [04:35<00:42, 17.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6143/6893 [04:35<00:42, 17.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6146/6893 [04:35<00:38, 19.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6149/6893 [04:35<00:38, 19.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6151/6893 [04:36<00:39, 18.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6154/6893 [04:36<00:38, 19.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6157/6893 [04:36<00:35, 20.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6160/6893 [04:36<00:37, 19.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6162/6893 [04:36<00:43, 16.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6164/6893 [04:36<00:44, 16.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6166/6893 [04:36<00:44, 16.25it/s]\u001b[A\n",
      "Extracting HuBERT features:  89%|████████▉ | 6169/6893 [04:37<00:42, 16.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6172/6893 [04:37<00:39, 18.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6174/6893 [04:37<00:41, 17.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6176/6893 [04:37<00:39, 18.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6178/6893 [04:37<00:38, 18.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6180/6893 [04:37<00:41, 17.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6182/6893 [04:37<00:40, 17.64it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6184/6893 [04:37<00:41, 17.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6187/6893 [04:38<00:37, 18.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6190/6893 [04:38<00:38, 18.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6192/6893 [04:38<00:39, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6194/6893 [04:38<00:39, 17.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6196/6893 [04:38<00:39, 17.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6199/6893 [04:38<00:36, 19.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6201/6893 [04:38<00:35, 19.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|████████▉ | 6203/6893 [04:38<00:38, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6205/6893 [04:39<00:39, 17.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6207/6893 [04:39<00:38, 18.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6210/6893 [04:39<00:35, 19.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6212/6893 [04:39<00:36, 18.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6215/6893 [04:39<00:35, 19.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6218/6893 [04:39<00:34, 19.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6220/6893 [04:39<00:36, 18.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6223/6893 [04:39<00:34, 19.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6225/6893 [04:40<00:34, 19.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6228/6893 [04:40<00:33, 19.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6230/6893 [04:40<00:38, 17.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6232/6893 [04:40<00:37, 17.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6234/6893 [04:40<00:37, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  90%|█████████ | 6236/6893 [04:40<00:38, 17.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6239/6893 [04:40<00:34, 18.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6241/6893 [04:41<00:35, 18.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6243/6893 [04:41<00:35, 18.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6245/6893 [04:41<00:34, 18.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6247/6893 [04:41<00:35, 18.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6249/6893 [04:41<00:37, 17.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6251/6893 [04:41<00:37, 17.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6254/6893 [04:41<00:34, 18.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6256/6893 [04:41<00:34, 18.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6259/6893 [04:41<00:31, 20.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6262/6893 [04:42<00:33, 19.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6265/6893 [04:42<00:32, 19.34it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6267/6893 [04:42<00:33, 18.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6269/6893 [04:42<00:33, 18.67it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6271/6893 [04:42<00:36, 16.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6274/6893 [04:42<00:32, 19.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6276/6893 [04:42<00:32, 19.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6278/6893 [04:42<00:32, 19.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6281/6893 [04:43<00:31, 19.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6283/6893 [04:43<00:31, 19.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6286/6893 [04:43<00:31, 19.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████ | 6288/6893 [04:43<00:31, 19.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6290/6893 [04:43<00:33, 17.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6292/6893 [04:43<00:32, 18.32it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6294/6893 [04:43<00:34, 17.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6297/6893 [04:44<00:32, 18.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6299/6893 [04:44<00:31, 18.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6301/6893 [04:44<00:31, 18.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6303/6893 [04:44<00:31, 18.89it/s]\u001b[A\n",
      "Extracting HuBERT features:  91%|█████████▏| 6306/6893 [04:44<00:29, 19.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6308/6893 [04:44<00:30, 18.92it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6310/6893 [04:44<00:30, 18.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6313/6893 [04:44<00:29, 19.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6315/6893 [04:44<00:32, 17.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6317/6893 [04:45<00:33, 17.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6319/6893 [04:45<00:32, 17.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6321/6893 [04:45<00:31, 17.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6323/6893 [04:45<00:31, 17.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6326/6893 [04:45<00:32, 17.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6329/6893 [04:45<00:28, 19.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6332/6893 [04:45<00:27, 20.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6335/6893 [04:46<00:30, 18.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6337/6893 [04:46<00:30, 18.02it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6340/6893 [04:46<00:28, 19.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6342/6893 [04:46<00:29, 18.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6345/6893 [04:46<00:28, 19.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6347/6893 [04:46<00:29, 18.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6349/6893 [04:46<00:29, 18.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6352/6893 [04:46<00:27, 19.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6355/6893 [04:47<00:27, 19.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6358/6893 [04:47<00:26, 19.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6360/6893 [04:47<00:26, 19.87it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6362/6893 [04:47<00:28, 18.58it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6364/6893 [04:47<00:28, 18.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6366/6893 [04:47<00:28, 18.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6368/6893 [04:47<00:28, 18.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6371/6893 [04:47<00:27, 19.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6373/6893 [04:48<00:29, 17.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  92%|█████████▏| 6375/6893 [04:48<00:29, 17.45it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6377/6893 [04:48<00:30, 16.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6379/6893 [04:48<00:29, 17.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6381/6893 [04:48<00:30, 16.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6383/6893 [04:48<00:29, 17.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6385/6893 [04:48<00:30, 16.44it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6387/6893 [04:48<00:31, 16.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6389/6893 [04:49<00:30, 16.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6391/6893 [04:49<00:29, 17.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6393/6893 [04:49<00:30, 16.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6395/6893 [04:49<00:28, 17.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6398/6893 [04:49<00:28, 17.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6400/6893 [04:49<00:28, 17.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6402/6893 [04:49<00:27, 17.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6404/6893 [04:49<00:29, 16.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6406/6893 [04:50<00:29, 16.78it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6408/6893 [04:50<00:28, 16.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6410/6893 [04:50<00:29, 16.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6412/6893 [04:50<00:28, 16.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6415/6893 [04:50<00:25, 18.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6418/6893 [04:50<00:25, 18.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6420/6893 [04:50<00:25, 18.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6422/6893 [04:50<00:26, 17.68it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6425/6893 [04:51<00:25, 18.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6428/6893 [04:51<00:23, 19.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6431/6893 [04:51<00:23, 19.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6434/6893 [04:51<00:23, 19.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6436/6893 [04:51<00:24, 18.57it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6438/6893 [04:51<00:26, 17.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6440/6893 [04:51<00:25, 17.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  93%|█████████▎| 6443/6893 [04:52<00:24, 18.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6445/6893 [04:52<00:25, 17.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6447/6893 [04:52<00:25, 17.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6450/6893 [04:52<00:25, 17.16it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6452/6893 [04:52<00:26, 16.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6454/6893 [04:52<00:26, 16.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6456/6893 [04:52<00:26, 16.74it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6459/6893 [04:52<00:24, 18.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▎| 6462/6893 [04:53<00:23, 18.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6464/6893 [04:53<00:24, 17.72it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6466/6893 [04:53<00:24, 17.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6468/6893 [04:53<00:24, 17.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6470/6893 [04:53<00:24, 17.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6473/6893 [04:53<00:22, 18.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6475/6893 [04:53<00:23, 18.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6478/6893 [04:54<00:21, 19.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6480/6893 [04:54<00:21, 19.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6482/6893 [04:54<00:21, 18.76it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6484/6893 [04:54<00:22, 18.36it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6486/6893 [04:54<00:24, 16.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6489/6893 [04:54<00:23, 17.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6492/6893 [04:54<00:21, 18.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6494/6893 [04:54<00:21, 18.51it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6496/6893 [04:55<00:21, 18.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6499/6893 [04:55<00:20, 19.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6502/6893 [04:55<00:20, 19.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6504/6893 [04:55<00:21, 18.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6506/6893 [04:55<00:22, 17.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6508/6893 [04:55<00:21, 17.73it/s]\u001b[A\n",
      "Extracting HuBERT features:  94%|█████████▍| 6511/6893 [04:55<00:19, 19.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6514/6893 [04:55<00:19, 19.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6516/6893 [04:56<00:21, 17.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6518/6893 [04:56<00:21, 17.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6520/6893 [04:56<00:21, 17.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6522/6893 [04:56<00:22, 16.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6524/6893 [04:56<00:21, 16.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6527/6893 [04:56<00:20, 18.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6529/6893 [04:56<00:22, 16.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6531/6893 [04:56<00:21, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6534/6893 [04:57<00:20, 17.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6536/6893 [04:57<00:21, 16.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6538/6893 [04:57<00:21, 16.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6540/6893 [04:57<00:22, 15.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6543/6893 [04:57<00:20, 17.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6545/6893 [04:57<00:19, 17.47it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▍| 6547/6893 [04:57<00:19, 17.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6549/6893 [04:58<00:21, 16.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6551/6893 [04:58<00:20, 16.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6553/6893 [04:58<00:19, 17.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6555/6893 [04:58<00:19, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6557/6893 [04:58<00:19, 17.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6560/6893 [04:58<00:17, 19.15it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6563/6893 [04:58<00:17, 18.82it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6565/6893 [04:58<00:18, 17.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6567/6893 [04:59<00:17, 18.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6569/6893 [04:59<00:17, 18.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6571/6893 [04:59<00:17, 18.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6573/6893 [04:59<00:17, 17.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6575/6893 [04:59<00:17, 18.03it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6577/6893 [04:59<00:17, 18.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6580/6893 [04:59<00:16, 19.23it/s]\u001b[A\n",
      "Extracting HuBERT features:  95%|█████████▌| 6582/6893 [04:59<00:16, 18.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6584/6893 [04:59<00:17, 17.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6587/6893 [05:00<00:17, 17.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6589/6893 [05:00<00:16, 18.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6591/6893 [05:00<00:16, 18.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6593/6893 [05:00<00:16, 18.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6596/6893 [05:00<00:15, 19.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6598/6893 [05:00<00:15, 18.97it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6601/6893 [05:00<00:14, 20.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6604/6893 [05:01<00:15, 18.30it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6606/6893 [05:01<00:16, 17.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6608/6893 [05:01<00:16, 16.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6610/6893 [05:01<00:16, 16.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6612/6893 [05:01<00:16, 16.66it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6614/6893 [05:01<00:16, 16.84it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6616/6893 [05:01<00:16, 16.86it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6618/6893 [05:01<00:15, 17.52it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6620/6893 [05:02<00:15, 17.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6623/6893 [05:02<00:15, 17.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6625/6893 [05:02<00:15, 17.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6628/6893 [05:02<00:14, 17.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6630/6893 [05:02<00:15, 17.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▌| 6633/6893 [05:02<00:14, 18.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6635/6893 [05:02<00:14, 18.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6637/6893 [05:02<00:13, 18.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6639/6893 [05:03<00:14, 18.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6642/6893 [05:03<00:12, 20.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6644/6893 [05:03<00:12, 19.18it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6647/6893 [05:03<00:12, 19.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6649/6893 [05:03<00:12, 19.21it/s]\u001b[A\n",
      "Extracting HuBERT features:  96%|█████████▋| 6651/6893 [05:03<00:12, 18.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6653/6893 [05:03<00:12, 18.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6655/6893 [05:03<00:12, 18.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6657/6893 [05:04<00:13, 17.49it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6659/6893 [05:04<00:12, 18.10it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6661/6893 [05:04<00:13, 16.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6663/6893 [05:04<00:14, 16.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6666/6893 [05:04<00:12, 17.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6668/6893 [05:04<00:12, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6670/6893 [05:04<00:12, 17.98it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6672/6893 [05:04<00:13, 16.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6674/6893 [05:05<00:13, 16.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6677/6893 [05:05<00:12, 17.79it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6679/6893 [05:05<00:11, 18.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6681/6893 [05:05<00:11, 18.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6683/6893 [05:05<00:11, 18.28it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6685/6893 [05:05<00:11, 17.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6687/6893 [05:05<00:11, 18.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6689/6893 [05:05<00:11, 18.12it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6691/6893 [05:05<00:11, 18.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6693/6893 [05:06<00:11, 17.48it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6696/6893 [05:06<00:10, 18.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6699/6893 [05:06<00:09, 20.55it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6702/6893 [05:06<00:09, 20.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6705/6893 [05:06<00:09, 19.61it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6707/6893 [05:06<00:09, 19.27it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6710/6893 [05:06<00:09, 19.91it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6712/6893 [05:07<00:09, 18.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6714/6893 [05:07<00:10, 17.65it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6717/6893 [05:07<00:09, 19.09it/s]\u001b[A\n",
      "Extracting HuBERT features:  97%|█████████▋| 6719/6893 [05:07<00:09, 19.06it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6722/6893 [05:07<00:08, 19.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6724/6893 [05:07<00:09, 17.70it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6727/6893 [05:07<00:08, 19.24it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6730/6893 [05:07<00:08, 20.33it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6733/6893 [05:08<00:08, 18.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6735/6893 [05:08<00:08, 17.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6737/6893 [05:08<00:09, 17.05it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6740/6893 [05:08<00:08, 18.50it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6742/6893 [05:08<00:08, 18.07it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6744/6893 [05:08<00:08, 18.01it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6746/6893 [05:08<00:08, 17.99it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6748/6893 [05:08<00:07, 18.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6750/6893 [05:09<00:08, 17.39it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6752/6893 [05:09<00:08, 17.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6754/6893 [05:09<00:08, 16.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6756/6893 [05:09<00:08, 16.80it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6758/6893 [05:09<00:08, 16.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6760/6893 [05:09<00:07, 17.35it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6762/6893 [05:09<00:07, 17.20it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6765/6893 [05:09<00:07, 17.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6767/6893 [05:10<00:07, 17.62it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6769/6893 [05:10<00:06, 17.95it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6771/6893 [05:10<00:07, 17.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6773/6893 [05:10<00:06, 17.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6775/6893 [05:10<00:06, 18.22it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6778/6893 [05:10<00:06, 18.41it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6781/6893 [05:10<00:05, 19.69it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6783/6893 [05:10<00:05, 18.96it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6785/6893 [05:11<00:05, 18.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6787/6893 [05:11<00:05, 17.93it/s]\u001b[A\n",
      "Extracting HuBERT features:  98%|█████████▊| 6789/6893 [05:11<00:05, 18.19it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6792/6893 [05:11<00:05, 18.29it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6794/6893 [05:11<00:05, 17.40it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6796/6893 [05:11<00:05, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6798/6893 [05:11<00:05, 17.46it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6800/6893 [05:11<00:05, 17.81it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6802/6893 [05:12<00:05, 17.08it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▊| 6805/6893 [05:12<00:04, 19.31it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6807/6893 [05:12<00:04, 18.26it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6809/6893 [05:12<00:04, 18.00it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6811/6893 [05:12<00:04, 18.38it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6813/6893 [05:12<00:04, 18.11it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6815/6893 [05:12<00:04, 16.85it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6817/6893 [05:12<00:04, 17.63it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6820/6893 [05:12<00:03, 19.60it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6822/6893 [05:13<00:03, 18.14it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6825/6893 [05:13<00:03, 19.17it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6828/6893 [05:13<00:03, 21.54it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6831/6893 [05:13<00:02, 21.04it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6834/6893 [05:13<00:03, 19.53it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6837/6893 [05:13<00:02, 19.88it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6840/6893 [05:14<00:03, 17.42it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6842/6893 [05:14<00:02, 17.75it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6844/6893 [05:14<00:02, 17.56it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6846/6893 [05:14<00:02, 17.59it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6848/6893 [05:14<00:02, 17.83it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6850/6893 [05:14<00:02, 16.13it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6852/6893 [05:14<00:02, 16.43it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6854/6893 [05:14<00:02, 16.90it/s]\u001b[A\n",
      "Extracting HuBERT features:  99%|█████████▉| 6857/6893 [05:15<00:01, 18.56it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6859/6893 [05:15<00:01, 17.36it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6861/6893 [05:15<00:01, 17.76it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6863/6893 [05:15<00:01, 17.39it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6865/6893 [05:15<00:01, 17.64it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6867/6893 [05:15<00:01, 17.14it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6870/6893 [05:15<00:01, 18.73it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6872/6893 [05:15<00:01, 17.35it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6874/6893 [05:16<00:01, 16.71it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6877/6893 [05:16<00:00, 17.69it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6879/6893 [05:16<00:00, 17.16it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6882/6893 [05:16<00:00, 18.12it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6884/6893 [05:16<00:00, 16.34it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6886/6893 [05:16<00:00, 15.20it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|█████████▉| 6889/6893 [05:16<00:00, 16.85it/s]\u001b[A\n",
      "Extracting HuBERT features: 100%|██████████| 6893/6893 [05:17<00:00, 21.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → hubert_features.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import HubertModel, Wav2Vec2FeatureExtractor\n",
    "\n",
    "manifest_path = \"emovdb_manifest.csv\"\n",
    "df = pd.read_csv(manifest_path)\n",
    "\n",
    "# HuBERT does NOT use a tokenizer. Only feature extractor.\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "    \"facebook/hubert-base-ls960\"\n",
    ")\n",
    "\n",
    "model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\").to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "all_features = []\n",
    "all_paths = []\n",
    "all_lengths = []\n",
    "\n",
    "def load_audio(filepath, target_sr=16000):\n",
    "    wav, sr = sf.read(filepath)\n",
    "    wav = torch.tensor(wav).float()\n",
    "    if wav.ndim > 1:\n",
    "        wav = wav.mean(dim=1)\n",
    "    if sr != target_sr:\n",
    "        wav = torchaudio.functional.resample(wav, sr, target_sr)\n",
    "    return wav\n",
    "\n",
    "for fp in tqdm(df[\"filepath\"], desc=\"Extracting HuBERT features\"):\n",
    "    wav = load_audio(fp).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inp = feature_extractor(\n",
    "            wav, sampling_rate=16000, return_tensors=\"pt\", padding=True\n",
    "        )\n",
    "        inp = {k: v.to(\"cuda\") for k, v in inp.items()}\n",
    "\n",
    "        out = model(**inp, output_hidden_states=True)\n",
    "        feats = out.hidden_states[9].squeeze(0).cpu()\n",
    "\n",
    "    all_features.append(feats)\n",
    "    all_paths.append(fp)\n",
    "    all_lengths.append(feats.shape[0])\n",
    "\n",
    "output = {\n",
    "    \"paths\": all_paths,\n",
    "    \"features\": all_features,\n",
    "    \"lengths\": all_lengths,\n",
    "    \"sample_rate\": 16000,\n",
    "}\n",
    "\n",
    "torch.save(output, \"hubert_features.pt\")\n",
    "print(\"Saved → hubert_features.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:10:01.345385Z",
     "iopub.status.busy": "2025-12-02T11:10:01.345141Z",
     "iopub.status.idle": "2025-12-02T11:10:18.219461Z",
     "shell.execute_reply": "2025-12-02T11:10:18.218565Z",
     "shell.execute_reply.started": "2025-12-02T11:10:01.345367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n",
      "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T11:10:18.221750Z",
     "iopub.status.busy": "2025-12-02T11:10:18.220845Z",
     "iopub.status.idle": "2025-12-02T11:10:42.808487Z",
     "shell.execute_reply": "2025-12-02T11:10:42.807568Z",
     "shell.execute_reply.started": "2025-12-02T11:10:18.221696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking all features...\n",
      "Total frames: torch.Size([1703083, 768])\n",
      "Training K-Means (K=200)...\n",
      "Sampling a subset of 51200 / 1703083 for training\n",
      "Clustering 51200 points in 768D to 200 clusters, redo 1 times, 30 iterations\n",
      "  Preprocessing in 1.09 s\n",
      "Quantizing sequences... search 3.04 s): objective=1.85115e+06 imbalance=1.115 nsplit=0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to discrete units: 100%|██████████| 6893/6893 [00:05<00:00, 1236.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → discrete_units.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load continuous HuBERT features\n",
    "data = torch.load(\"hubert_features.pt\")\n",
    "all_feats = data[\"features\"]     # list of tensors (L_i, 768)\n",
    "all_paths = data[\"paths\"]\n",
    "\n",
    "# ====== 1. Stack features into one big matrix ======\n",
    "print(\"Stacking all features...\")\n",
    "feat_list = [f for f in all_feats]\n",
    "X = torch.cat(feat_list, dim=0).float()      # shape: (N_frames, 768)\n",
    "print(\"Total frames:\", X.shape)\n",
    "\n",
    "# convert to numpy for faiss\n",
    "X_np = X.numpy().astype('float32')\n",
    "\n",
    "# ====== 2. Train KMeans with K=200 ======\n",
    "K = 200\n",
    "print(\"Training K-Means (K=200)...\")\n",
    "\n",
    "kmeans = faiss.Kmeans(\n",
    "    d=768,       # feature dimension\n",
    "    k=K,\n",
    "    niter=30,\n",
    "    verbose=True,\n",
    "    gpu=False\n",
    ")\n",
    "\n",
    "kmeans.train(X_np)\n",
    "\n",
    "centroids = kmeans.centroids\n",
    "\n",
    "# ====== 3. Quantize each utterance ======\n",
    "print(\"Quantizing sequences...\")\n",
    "\n",
    "def quantize_seq(tensor, kmeans):\n",
    "    \"\"\"\n",
    "    Input: (L, 768) tensor\n",
    "    Output: unit_ids (L,)\n",
    "    \"\"\"\n",
    "    x = tensor.numpy().astype('float32')\n",
    "    _, ids = kmeans.index.search(x, 1)  # nearest centroid\n",
    "    return ids.squeeze(1).tolist()\n",
    "\n",
    "# ====== 4. Dedup ======\n",
    "def dedupe(seq):\n",
    "    \"\"\"Remove consecutive repeated units.\"\"\"\n",
    "    if len(seq) == 0:\n",
    "        return seq\n",
    "    new = [seq[0]]\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i] != seq[i-1]:\n",
    "            new.append(seq[i])\n",
    "    return new\n",
    "\n",
    "all_units = []\n",
    "all_units_dedup = []\n",
    "\n",
    "for feats in tqdm(all_feats, desc=\"Converting to discrete units\"):\n",
    "    unit_ids = quantize_seq(feats, kmeans)\n",
    "    dedup_ids = dedupe(unit_ids)\n",
    "    all_units.append(unit_ids)\n",
    "    all_units_dedup.append(dedup_ids)\n",
    "\n",
    "# ====== 5. Save everything ======\n",
    "save_dict = {\n",
    "    \"paths\": all_paths,\n",
    "    \"units\": all_units,\n",
    "    \"units_dedup\": all_units_dedup,\n",
    "    \"kmeans_centroids\": centroids,\n",
    "    \"K\": K\n",
    "}\n",
    "\n",
    "torch.save(save_dict, \"discrete_units.pt\")\n",
    "print(\"Saved → discrete_units.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step: Speaker lookup table + emotion one-hot + dataset helper\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "DISCRETE_PT = \"discrete_units.pt\"       # from step 3\n",
    "MANIFEST_CSV = \"emovdb_manifest.csv\"    # from earlier\n",
    "SPEAKER_TABLE_FN = \"speaker_table.pt\"\n",
    "LABEL_MAPPINGS_FN = \"label_mappings.pt\"\n",
    "SPK_DIM = 128                           # embedding size for speaker lookup table\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------------------\n",
    "# Load data artifacts\n",
    "# ----------------------------\n",
    "discrete = torch.load(DISCRETE_PT, weights_only=False)\n",
    "\n",
    "paths = discrete[\"paths\"]               # list of filepaths in same order as units\n",
    "units_dedup = discrete[\"units_dedup\"]   # list of lists\n",
    "# manifest for metadata (speaker/emotion inference)\n",
    "df = pd.read_csv(MANIFEST_CSV)\n",
    "\n",
    "# ensure paths are same ordering/containment: build a mapping from filepath -> (speaker,emotion)\n",
    "meta_map = {}\n",
    "for _, row in df.iterrows():\n",
    "    path = os.path.abspath(row[\"filepath\"])\n",
    "    meta_map[path] = {\"speaker\": row[\"speaker\"], \"emotion\": row[\"emotion\"]}\n",
    "\n",
    "# normalize the paths stored in discrete to absolute for matching\n",
    "abs_paths = [os.path.abspath(p) for p in paths]\n",
    "\n",
    "# ----------------------------\n",
    "# Create speaker -> id mapping\n",
    "# ----------------------------\n",
    "# Collect speakers present in the manifest for the set of files we have\n",
    "speakers = []\n",
    "for p in abs_paths:\n",
    "    if p in meta_map:\n",
    "        spk = meta_map[p][\"speaker\"]\n",
    "        speakers.append(spk)\n",
    "    else:\n",
    "        # fallback: infer speaker from path parts (last-2 folder)\n",
    "        parts = p.split(os.sep)\n",
    "        spk = parts[-3] if len(parts) >= 3 else \"unknown\"\n",
    "        speakers.append(spk)\n",
    "\n",
    "unique_speakers = sorted(list(set(speakers)))\n",
    "speaker2id = {s: i for i, s in enumerate(unique_speakers)}\n",
    "id2speaker = {i: s for s, i in speaker2id.items()}\n",
    "num_speakers = len(unique_speakers)\n",
    "print(f\"Found {num_speakers} speakers: {unique_speakers}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Create emotion -> id mapping\n",
    "# ----------------------------\n",
    "# Collect emotions from manifest\n",
    "emotions = []\n",
    "for p in abs_paths:\n",
    "    if p in meta_map:\n",
    "        emo = meta_map[p][\"emotion\"]\n",
    "    else:\n",
    "        parts = p.split(os.sep)\n",
    "        emo = parts[-2] if len(parts) >= 2 else \"unknown\"\n",
    "    emotions.append(emo)\n",
    "\n",
    "unique_emotions = sorted(list(set(emotions)))\n",
    "emotion2id = {e: i for i, e in enumerate(unique_emotions)}\n",
    "id2emotion = {i: e for e, i in emotion2id.items()}\n",
    "num_emotions = len(unique_emotions)\n",
    "print(f\"Found {num_emotions} emotions: {unique_emotions}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Speaker lookup module (trainable embedding table)\n",
    "# ----------------------------\n",
    "class SpeakerLookup(nn.Module):\n",
    "    def __init__(self, num_speakers: int, spk_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_speakers, embedding_dim=spk_dim)\n",
    "        # initialize embeddings (standard normal small init)\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, speaker_ids: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        speaker_ids: (B,) long tensor\n",
    "        returns: (B, spk_dim) float tensor\n",
    "        \"\"\"\n",
    "        return self.embedding(speaker_ids)\n",
    "\n",
    "# instantiate\n",
    "spk_module = SpeakerLookup(num_speakers=num_speakers, spk_dim=SPK_DIM).to(DEVICE)\n",
    "\n",
    "# Save initial speaker table and mappings (weights will be updated during later training)\n",
    "torch.save({\n",
    "    \"state_dict\": spk_module.state_dict(),\n",
    "    \"speaker2id\": speaker2id,\n",
    "    \"id2speaker\": id2speaker,\n",
    "    \"spk_dim\": SPK_DIM\n",
    "}, SPEAKER_TABLE_FN)\n",
    "print(f\"Saved speaker table to {SPEAKER_TABLE_FN}\")\n",
    "\n",
    "# Save label mappings\n",
    "torch.save({\n",
    "    \"emotion2id\": emotion2id,\n",
    "    \"id2emotion\": id2emotion,\n",
    "    \"num_emotions\": num_emotions\n",
    "}, LABEL_MAPPINGS_FN)\n",
    "print(f\"Saved label mappings to {LABEL_MAPPINGS_FN}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Utility functions\n",
    "# ----------------------------\n",
    "def get_speaker_id_from_path(path: str):\n",
    "    p = os.path.abspath(path)\n",
    "    if p in meta_map:\n",
    "        spk = meta_map[p][\"speaker\"]\n",
    "    else:\n",
    "        parts = p.split(os.sep)\n",
    "        spk = parts[-3] if len(parts) >= 3 else \"unknown\"\n",
    "    return speaker2id.get(spk, -1)\n",
    "\n",
    "def get_emotion_id_from_path(path: str):\n",
    "    p = os.path.abspath(path)\n",
    "    if p in meta_map:\n",
    "        emo = meta_map[p][\"emotion\"]\n",
    "    else:\n",
    "        parts = p.split(os.sep)\n",
    "        emo = parts[-2] if len(parts) >= 2 else \"unknown\"\n",
    "    return emotion2id.get(emo, -1)\n",
    "\n",
    "# one-hot helper\n",
    "def emotion_one_hot(emo_id: int, num_classes: int):\n",
    "    v = torch.zeros(num_classes, dtype=torch.float32)\n",
    "    if emo_id >= 0:\n",
    "        v[emo_id] = 1.0\n",
    "    return v\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset class that yields units + speaker + emotion conditioning\n",
    "# ----------------------------\n",
    "class UnitsDataset(Dataset):\n",
    "    def __init__(self, paths: List[str], units_dedup: List[List[int]],\n",
    "                 speaker2id: dict, emotion2id: dict, device: str = \"cpu\"):\n",
    "        assert len(paths) == len(units_dedup)\n",
    "        self.paths = [os.path.abspath(p) for p in paths]\n",
    "        self.units = units_dedup\n",
    "        self.speaker2id = speaker2id\n",
    "        self.emotion2id = emotion2id\n",
    "        self.device = device\n",
    "        self.num_emotions = len(emotion2id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        unit_seq = torch.tensor(self.units[idx], dtype=torch.long)           # shape (L,)\n",
    "        spk_id = get_speaker_id_from_path(p)\n",
    "        emo_id = get_emotion_id_from_path(p)\n",
    "        spk_id_t = torch.tensor(spk_id, dtype=torch.long)\n",
    "        emo_onehot = emotion_one_hot(emo_id, self.num_emotions)\n",
    "        return {\n",
    "            \"path\": p,\n",
    "            \"units\": unit_seq.to(self.device),\n",
    "            \"speaker_id\": spk_id_t.to(self.device),\n",
    "            \"emotion_onehot\": emo_onehot.to(self.device),\n",
    "            \"emotion_id\": torch.tensor(emo_id, dtype=torch.long).to(self.device)\n",
    "        }\n",
    "\n",
    "# quick sanity: build dataset and sample\n",
    "dataset = UnitsDataset(abs_paths, units_dedup, speaker2id, emotion2id, device=DEVICE)\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "sample = dataset[0]\n",
    "print(\"Sample keys:\", sample.keys())\n",
    "print(\"Sample units length:\", sample[\"units\"].shape)\n",
    "print(\"Sample speaker_id:\", sample[\"speaker_id\"].item())\n",
    "print(\"Sample emotion_onehot sum (should be 1):\", sample[\"emotion_onehot\"].sum().item())\n",
    "\n",
    "# optional: DataLoader example\n",
    "dl = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=lambda batch: batch) \n",
    "batch = next(iter(dl))\n",
    "print(\"Loaded batch of\", len(batch), \"items\")\n",
    "\n",
    "# ----------------------------\n",
    "# Example: load speaker embedding module and get speaker vectors\n",
    "# ----------------------------\n",
    "loaded = torch.load(SPEAKER_TABLE_FN, map_location=DEVICE)\n",
    "spk_mod = SpeakerLookup(num_speakers=len(loaded[\"speaker2id\"]), spk_dim=loaded[\"spk_dim\"]).to(DEVICE)\n",
    "spk_mod.load_state_dict(loaded[\"state_dict\"])\n",
    "spk_mod.eval()\n",
    "\n",
    "# get vector for a sample\n",
    "sample_spk_id = dataset[0][\"speaker_id\"].unsqueeze(0)  # shape (1,)\n",
    "with torch.no_grad():\n",
    "    spk_vec = spk_mod(sample_spk_id.to(DEVICE))         # (1, SPK_DIM)\n",
    "print(\"Speaker vector shape:\", spk_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/data/b22_shruti_chaudhary/.cache/kagglehub/datasets/phantasm34/emovdb-sorted/versions/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_1-28_0014.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_169-196_0173.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_169-196_0174.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_29-56_0045.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_141-168_0152.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_309-336_0336.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_225-252_0236.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_197-224_0224.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_253-280_0254.wav\n",
      "/kaggle/input/emovdb-sorted/bea/Disgusted/disgust_253-280_0266.wav\n"
     ]
    }
   ],
   "source": [
    "for p in paths[:10]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parallel pairs: 21730\n",
      "Example pair: ([187, 186, 32, 50, 32, 193, 50, 31, 83, 193, 179, 42, 192, 129, 104, 44, 104, 87, 180, 29, 152, 91, 162, 148, 166, 57, 156, 2, 107, 109, 158, 35, 98, 33, 76, 22, 182, 139, 199, 146, 0, 121, 144, 63, 118, 68, 24, 9, 134, 2, 107, 63, 24, 123, 21, 165, 139, 25, 134, 45, 106, 71, 73, 153, 77, 4, 124, 156, 45, 6, 115, 153, 77, 133, 199, 193, 25, 102, 69, 134, 14, 93, 160, 170, 55, 163, 168, 34, 163, 140, 12, 184, 188, 189, 106, 182, 146, 174, 15, 77, 125, 146, 48, 142, 59, 175, 63, 66, 24, 9, 139, 78, 164, 49, 108, 13, 100, 195, 129, 154, 172], 2, [187, 186, 32, 193, 32, 88, 193, 31, 88, 50, 88, 152, 193, 152, 193, 152, 193, 148, 193, 148, 57, 8, 156, 2, 107, 130, 109, 92, 35, 98, 76, 22, 182, 139, 146, 48, 0, 10, 121, 144, 63, 185, 118, 68, 124, 24, 9, 78, 134, 2, 107, 63, 124, 9, 139, 78, 21, 165, 199, 25, 134, 45, 106, 71, 73, 153, 77, 133, 124, 156, 123, 45, 71, 73, 153, 77, 102, 69, 134, 14, 93, 160, 173, 188, 189, 106, 182, 146, 115, 153, 96, 77, 125, 139, 146, 142, 59, 175, 63, 24, 9, 78, 90, 164, 49, 108, 193, 168, 100, 168, 162, 29, 162, 154, 117, 12, 172], 1, 'bea/Disgusted/disgust_1-28_0014.wav')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "discrete = torch.load(\"discrete_units.pt\", weights_only=False)\n",
    "units = discrete[\"units_dedup\"]\n",
    "paths = discrete[\"paths\"]\n",
    "\n",
    "df = pd.read_csv(\"emovdb_manifest.csv\")\n",
    "label_map = torch.load(\"label_mappings.pt\")\n",
    "emotion2id = label_map[\"emotion2id\"]\n",
    "\n",
    "def to_rel(p):\n",
    "    return \"/\".join(p.split(\"/\")[-3:])\n",
    "\n",
    "df[\"relpath\"] = df[\"filepath\"].apply(to_rel)\n",
    "rel_paths = [to_rel(p) for p in paths]\n",
    "\n",
    "def extract_sentence_id(rel_path):\n",
    "    fname = os.path.basename(rel_path)\n",
    "    base = fname.split(\".\")[0]\n",
    "    parts = base.split(\"_\")\n",
    "    return parts[-1]  # \"0007\"\n",
    "\n",
    "grouped = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for rel_path, unit_seq in zip(rel_paths, units):\n",
    "    meta = df[df[\"relpath\"] == rel_path]\n",
    "    if meta.empty:\n",
    "        continue\n",
    "    speaker = meta.iloc[0][\"speaker\"]\n",
    "    emotion = meta.iloc[0][\"emotion\"]\n",
    "    sent_id = extract_sentence_id(rel_path)\n",
    "    grouped[speaker][sent_id][emotion] = (rel_path, unit_seq)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for speaker, sent_dict in grouped.items():\n",
    "    for sent_id, emo_dict in sent_dict.items():\n",
    "        emotions = list(emo_dict.keys())\n",
    "        if len(emotions) < 2:\n",
    "            continue\n",
    "        for emo_src in emotions:\n",
    "            for emo_tgt in emotions:\n",
    "                if emo_src == emo_tgt:\n",
    "                    continue\n",
    "                src_path, src_seq = emo_dict[emo_src]\n",
    "                tgt_path, tgt_seq = emo_dict[emo_tgt]\n",
    "                pairs.append((\n",
    "                    src_seq,\n",
    "                    emotion2id[emo_src],\n",
    "                    tgt_seq,\n",
    "                    emotion2id[emo_tgt],\n",
    "                    src_path\n",
    "                ))\n",
    "\n",
    "print(\"Total parallel pairs:\", len(pairs))\n",
    "print(\"Example pair:\", pairs[0] if pairs else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T13:41:23.919077Z",
     "iopub.status.busy": "2025-12-02T13:41:23.918642Z",
     "iopub.status.idle": "2025-12-02T13:41:31.675638Z",
     "shell.execute_reply": "2025-12-02T13:41:31.674850Z",
     "shell.execute_reply.started": "2025-12-02T13:41:23.919049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# from torch.serialization import add_safe_globals\n",
    "\n",
    "# add_safe_globals([np.core.multiarray._reconstruct])\n",
    "\n",
    "# discrete = torch.load(\"discrete_units.pt\", weights_only=False)\n",
    "# units = discrete[\"units_dedup\"]\n",
    "# paths = [os.path.abspath(p) for p in discrete[\"paths\"]]\n",
    "\n",
    "# df = pd.read_csv(\"emovdb_manifest.csv\")\n",
    "# label_map = torch.load(\"label_mappings.pt\")\n",
    "# emotion2id = label_map[\"emotion2id\"]\n",
    "\n",
    "\n",
    "# def extract_sentence_id(path):\n",
    "#     fname = os.path.basename(path)\n",
    "#     base = fname.split(\".\")[0]\n",
    "#     parts = base.split(\"_\")\n",
    "#     return parts[-1]  # \"0007\"\n",
    "\n",
    "# # Group: speaker -> sentence_id -> emotion -> unit_seq\n",
    "# grouped = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "# for path, unit_seq in zip(paths, units):\n",
    "#     meta = df[df[\"filepath\"] == path]\n",
    "#     if meta.empty:\n",
    "#         continue\n",
    "#     speaker = meta.iloc[0][\"speaker\"]\n",
    "#     emotion = meta.iloc[0][\"emotion\"]\n",
    "#     sent_id = extract_sentence_id(path)\n",
    "#     grouped[speaker][sent_id][emotion] = (path, unit_seq)\n",
    "\n",
    "# pairs = []\n",
    "\n",
    "# # Build pairs only where >=2 emotions exist\n",
    "# for speaker, sent_dict in grouped.items():\n",
    "#     for sent_id, emo_dict in sent_dict.items():\n",
    "#         emotions = list(emo_dict.keys())\n",
    "#         if len(emotions) < 2:\n",
    "#             continue\n",
    "#         for emo_src in emotions:\n",
    "#             for emo_tgt in emotions:\n",
    "#                 if emo_src == emo_tgt:\n",
    "#                     continue\n",
    "#                 src_path, src_seq = emo_dict[emo_src]\n",
    "#                 tgt_path, tgt_seq = emo_dict[emo_tgt]\n",
    "#                 pairs.append((\n",
    "#                     src_seq,\n",
    "#                     emotion2id[emo_src],\n",
    "#                     tgt_seq,\n",
    "#                     emotion2id[emo_tgt],\n",
    "#                     src_path\n",
    "#                 ))\n",
    "\n",
    "# print(\"Total parallel pairs:\", len(pairs))\n",
    "# print(\"Example pair:\", pairs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T13:31:26.094947Z",
     "iopub.status.busy": "2025-12-02T13:31:26.094177Z",
     "iopub.status.idle": "2025-12-02T13:31:26.098375Z",
     "shell.execute_reply": "2025-12-02T13:31:26.097781Z",
     "shell.execute_reply.started": "2025-12-02T13:31:26.094910Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T13:41:41.108893Z",
     "iopub.status.busy": "2025-12-02T13:41:41.108582Z",
     "iopub.status.idle": "2025-12-02T13:50:11.959103Z",
     "shell.execute_reply": "2025-12-02T13:50:11.958388Z",
     "shell.execute_reply.started": "2025-12-02T13:41:41.108873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pretrain Epoch 1/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 1 loss: 2.4944\n",
      "\n",
      "--- Pretrain Epoch 2/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 2 loss: 1.9746\n",
      "\n",
      "--- Pretrain Epoch 3/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 3 loss: 1.7478\n",
      "\n",
      "--- Pretrain Epoch 4/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 4 loss: 1.6110\n",
      "\n",
      "--- Pretrain Epoch 5/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 5 loss: 1.5209\n",
      "\n",
      "--- Pretrain Epoch 6/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 6 loss: 1.4499\n",
      "\n",
      "--- Pretrain Epoch 7/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 7 loss: 1.3898\n",
      "\n",
      "--- Pretrain Epoch 8/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 8 loss: 1.3350\n",
      "\n",
      "--- Pretrain Epoch 9/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 9 loss: 1.2847\n",
      "\n",
      "--- Pretrain Epoch 10/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 10 loss: 1.2367\n",
      "\n",
      "--- Pretrain Epoch 11/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 11 loss: 1.1939\n",
      "\n",
      "--- Pretrain Epoch 12/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 12 loss: 1.1487\n",
      "\n",
      "--- Pretrain Epoch 13/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 13 loss: 1.1068\n",
      "\n",
      "--- Pretrain Epoch 14/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 14 loss: 1.0665\n",
      "\n",
      "--- Pretrain Epoch 15/15 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain epoch 15 loss: 1.0271\n",
      "\n",
      "--- Finetune Epoch 1/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 1 loss: 2.6920\n",
      "\n",
      "--- Finetune Epoch 2/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 2 loss: 2.2135\n",
      "\n",
      "--- Finetune Epoch 3/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 3 loss: 2.0968\n",
      "\n",
      "--- Finetune Epoch 4/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 4 loss: 2.0061\n",
      "\n",
      "--- Finetune Epoch 5/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 5 loss: 1.9253\n",
      "\n",
      "--- Finetune Epoch 6/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 6 loss: 1.8504\n",
      "\n",
      "--- Finetune Epoch 7/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 7 loss: 1.7806\n",
      "\n",
      "--- Finetune Epoch 8/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 8 loss: 1.7087\n",
      "\n",
      "--- Finetune Epoch 9/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 9 loss: 1.6370\n",
      "\n",
      "--- Finetune Epoch 10/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 10 loss: 1.5615\n",
      "\n",
      "--- Finetune Epoch 11/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 11 loss: 1.4904\n",
      "\n",
      "--- Finetune Epoch 12/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 12 loss: 1.4161\n",
      "\n",
      "--- Finetune Epoch 13/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 13 loss: 1.3439\n",
      "\n",
      "--- Finetune Epoch 14/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 14 loss: 1.2753\n",
      "\n",
      "--- Finetune Epoch 15/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 15 loss: 1.2079\n",
      "\n",
      "--- Finetune Epoch 16/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 16 loss: 1.1381\n",
      "\n",
      "--- Finetune Epoch 17/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 17 loss: 1.0680\n",
      "\n",
      "--- Finetune Epoch 18/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 18 loss: 1.0070\n",
      "\n",
      "--- Finetune Epoch 19/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 19 loss: 0.9449\n",
      "\n",
      "--- Finetune Epoch 20/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 20 loss: 0.8853\n",
      "\n",
      "--- Finetune Epoch 21/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 21 loss: 0.8328\n",
      "\n",
      "--- Finetune Epoch 22/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 22 loss: 0.7858\n",
      "\n",
      "--- Finetune Epoch 23/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 23 loss: 0.7415\n",
      "\n",
      "--- Finetune Epoch 24/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 24 loss: 0.6975\n",
      "\n",
      "--- Finetune Epoch 25/25 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune epoch 25 loss: 0.6574\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "K = 200\n",
    "PAD = 0\n",
    "SHIFT = 1\n",
    "BOS = K + SHIFT      # 201\n",
    "EOS = K + SHIFT + 1  # 202\n",
    "VOCAB_SIZE = K + SHIFT + 2  # 203\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)].to(x.device)\n",
    "\n",
    "class EmotionTransformer(nn.Module):\n",
    "    def __init__(self, num_emotions, vocab_size=VOCAB_SIZE, d_model=512, nhead=8, num_layers=6, dim_feedforward=2048, dropout=0.1, max_len=4096):\n",
    "        super().__init__()\n",
    "        self.num_emotions = num_emotions\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=PAD)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len=max_len)\n",
    "        self.encoders = nn.ModuleDict()\n",
    "        self.decoders = nn.ModuleDict()\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        for e in range(num_emotions):\n",
    "            self.encoders[str(e)] = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "            self.decoders[str(e)] = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "        self.d_model = d_model\n",
    "    def encode(self, src_tokens, src_mask, emotion_id):\n",
    "        e = str(int(emotion_id))\n",
    "        x = self.token_emb(src_tokens) * math.sqrt(self.d_model)\n",
    "        x = x + self.pos_enc(x)\n",
    "        x = x.transpose(0,1)\n",
    "        memory = self.encoders[e](x, src_key_padding_mask=src_mask)\n",
    "        return memory\n",
    "    def decode(self, tgt_tokens, memory, memory_mask, emotion_id, tgt_mask):\n",
    "        e = str(int(emotion_id))\n",
    "        y = self.token_emb(tgt_tokens) * math.sqrt(self.d_model)\n",
    "        y = y + self.pos_enc(y)\n",
    "        y = y.transpose(0,1)\n",
    "        out = self.decoders[e](y, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask)\n",
    "        out = out.transpose(0,1)\n",
    "        logits = self.output_proj(out)\n",
    "        return logits\n",
    "    def forward(self, src_tokens, src_mask, tgt_tokens, tgt_mask, src_em, tgt_em):\n",
    "        memory = self.encode(src_tokens, src_mask, src_em)\n",
    "        if tgt_mask is None:\n",
    "            tgt_mask = self.generate_square_subsequent_mask(tgt_tokens.size(1)).to(tgt_tokens.device)\n",
    "        logits = self.decode(tgt_tokens, memory, src_mask, tgt_em, tgt_mask)\n",
    "        return logits\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n",
    "\n",
    "class PairedUnitsDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        a, a_emo, b, b_emo, path_a = self.pairs[idx]\n",
    "        return {\n",
    "            \"src_units\": torch.tensor([x+SHIFT for x in a], dtype=torch.long),\n",
    "            \"src_emotion\": a_emo,\n",
    "            \"tgt_units\": torch.tensor([x+SHIFT for x in b], dtype=torch.long),\n",
    "            \"tgt_emotion\": b_emo,\n",
    "            \"path\": path_a\n",
    "        }\n",
    "\n",
    "def collate_pairs(batch):\n",
    "    srcs = [b[\"src_units\"].tolist() for b in batch]\n",
    "    tgts = [b[\"tgt_units\"].tolist() for b in batch]\n",
    "    src_em = torch.tensor(batch[0][\"src_emotion\"], dtype=torch.long)\n",
    "    tgt_em = torch.tensor(batch[0][\"tgt_emotion\"], dtype=torch.long)\n",
    "    max_src = max(len(s) for s in srcs)\n",
    "    max_tgt = max(len(t) for t in tgts) + 1\n",
    "    src_padded, src_mask, tgt_in, tgt_out = [], [], [], []\n",
    "    for s, t in zip(srcs, tgts):\n",
    "        sseq = s + [PAD]*(max_src-len(s))\n",
    "        smask = [False]*len(s) + [True]*(max_src-len(s))\n",
    "        tgt_seq = [BOS] + t + [EOS]\n",
    "        tgt_in_seq = tgt_seq[:-1] + [PAD]*(max_tgt-(len(tgt_seq)-1))\n",
    "        tgt_out_seq = tgt_seq[1:] + [PAD]*(max_tgt-(len(tgt_seq)-1))\n",
    "        src_padded.append(sseq)\n",
    "        src_mask.append(smask)\n",
    "        tgt_in.append(tgt_in_seq)\n",
    "        tgt_out.append(tgt_out_seq)\n",
    "    return {\n",
    "        \"src\": torch.tensor(src_padded, dtype=torch.long).to(device),\n",
    "        \"src_mask\": torch.tensor(src_mask, dtype=torch.bool).to(device),\n",
    "        \"tgt_in\": torch.tensor(tgt_in, dtype=torch.long).to(device),\n",
    "        \"tgt_out\": torch.tensor(tgt_out, dtype=torch.long).to(device),\n",
    "        \"src_em\": src_em.to(device),\n",
    "        \"tgt_em\": tgt_em.to(device),\n",
    "    }\n",
    "\n",
    "def make_denoising_input(units, p_mask=0.15, span_len=3):\n",
    "    seq = units.copy()\n",
    "    L = len(seq)\n",
    "    i = 0\n",
    "    while i < L:\n",
    "        if random.random() < p_mask:\n",
    "            span = random.randint(1, span_len)\n",
    "            end = min(i+span, L)\n",
    "            for j in range(i, end):\n",
    "                seq[j] = K - 1  # use max raw unit as noise\n",
    "            i = end\n",
    "        else:\n",
    "            i += 1\n",
    "    return seq\n",
    "\n",
    "def pretrain_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        items = []\n",
    "        for i in range(len(batch)):\n",
    "            units = batch[i][\"units\"].tolist()      # raw 0..K-1\n",
    "            emo = batch[i][\"emotion_id\"]\n",
    "            corrupted = make_denoising_input(units)\n",
    "            items.append((corrupted, emo, units, emo, \"\"))\n",
    "        paired = PairedUnitsDataset(items)\n",
    "        pl = DataLoader(paired, batch_size=len(items), shuffle=False, collate_fn=collate_pairs)\n",
    "        for pb in pl:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(pb[\"src\"], pb[\"src_mask\"], pb[\"tgt_in\"], None, pb[\"src_em\"], pb[\"tgt_em\"])\n",
    "            loss = criterion(logits.view(-1, model.vocab_size), pb[\"tgt_out\"].view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def finetune_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch[\"src\"], batch[\"src_mask\"], batch[\"tgt_in\"], None, batch[\"src_em\"], batch[\"tgt_em\"])\n",
    "        loss = criterion(logits.view(-1, model.vocab_size), batch[\"tgt_out\"].view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def greedy_decode(model, src, src_mask, src_em, tgt_em, max_len=300):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        memory = model.encode(src, src_mask, src_em)\n",
    "        ys = torch.tensor([[BOS]], dtype=torch.long).to(device)\n",
    "        for _ in range(max_len):\n",
    "            tgt_mask = model.generate_square_subsequent_mask(ys.size(1)).to(device)\n",
    "            out = model.decode(ys, memory, src_mask, tgt_em, tgt_mask)\n",
    "            nxt = out[:, -1, :].argmax(-1, keepdim=True)\n",
    "            ys = torch.cat([ys, nxt], dim=1)\n",
    "            if nxt.item() == EOS:\n",
    "                break\n",
    "    return ys.squeeze(0).tolist()\n",
    "\n",
    "discrete = torch.load(\"discrete_units.pt\", weights_only=False)\n",
    "paths = discrete[\"paths\"]\n",
    "units_dedup = discrete[\"units_dedup\"]\n",
    "\n",
    "df = pd.read_csv(\"emovdb_manifest.csv\")\n",
    "manifest = {os.path.abspath(r[\"filepath\"]): {\"speaker\": r[\"speaker\"], \"emotion\": r[\"emotion\"]} for _, r in df.iterrows()}\n",
    "emotion2id = torch.load(\"label_mappings.pt\")[\"emotion2id\"]\n",
    "\n",
    "num_emotions = len(emotion2id)\n",
    "model = EmotionTransformer(num_emotions=num_emotions).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "emo_ids = []\n",
    "abs_paths = [os.path.abspath(p) for p in paths]\n",
    "for p in abs_paths:\n",
    "    emo = manifest.get(p, {}).get(\"emotion\", None)\n",
    "    emo_ids.append(emotion2id.get(emo, 0))\n",
    "\n",
    "class SimpleUnitsListDataset(Dataset):\n",
    "    def __init__(self, paths, units, emo_ids):\n",
    "        self.paths = paths\n",
    "        self.units = units\n",
    "        self.emo_ids = emo_ids\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"path\": self.paths[idx], \"units\": torch.tensor(self.units[idx], dtype=torch.long), \"emotion_id\": self.emo_ids[idx]}\n",
    "\n",
    "pretrain_ds = SimpleUnitsListDataset(abs_paths, units_dedup, emo_ids)\n",
    "pretrain_loader = DataLoader(pretrain_ds, batch_size=8, shuffle=True, collate_fn=lambda b: b)\n",
    "\n",
    "\n",
    "num_pretrain_epochs = 15\n",
    "\n",
    "for epoch in range(1, num_pretrain_epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    # display epoch header\n",
    "    print(f\"\\n--- Pretrain Epoch {epoch}/{num_pretrain_epochs} ---\")\n",
    "\n",
    "    # tqdm batch loop\n",
    "    for batch in tqdm(pretrain_loader, desc=f\"Pretrain {epoch}\", leave=False):\n",
    "        loss = pretrain_epoch(model, [batch], optimizer, criterion)  # wrap batch to mimic loader\n",
    "        running_loss += loss\n",
    "        batches += 1\n",
    "\n",
    "    avg_loss = running_loss / batches\n",
    "    print(f\"pretrain epoch {epoch} loss: {avg_loss:.4f}\")\n",
    "\n",
    "# for epoch in range(15):\n",
    "#     loss = pretrain_epoch(model, pretrain_loader, optimizer, criterion)\n",
    "#     print(\"pretrain loss\", loss)\n",
    "\n",
    "# 'pairs' must be defined before this (built from your parallel pairing step)\n",
    "paired_ds = PairedUnitsDataset(pairs)\n",
    "paired_loader = DataLoader(paired_ds, batch_size=16, shuffle=False, collate_fn=collate_pairs)\n",
    "\n",
    "num_finetune_epochs = 25\n",
    "\n",
    "for epoch in range(1, num_finetune_epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    print(f\"\\n--- Finetune Epoch {epoch}/{num_finetune_epochs} ---\")\n",
    "\n",
    "    for batch in tqdm(paired_loader, desc=f\"Finetune {epoch}\", leave=False):\n",
    "        loss = finetune_epoch(model, [batch], optimizer, criterion)\n",
    "        running_loss += loss\n",
    "        batches += 1\n",
    "\n",
    "    avg_loss = running_loss / batches\n",
    "    print(f\"finetune epoch {epoch} loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "# for epoch in range(25):\n",
    "#     loss = finetune_epoch(model, paired_loader, optimizer, criterion)\n",
    "#     print(\"finetune loss\", loss)\n",
    "\n",
    "torch.save(model.state_dict(), \"es2s_transformer.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyworld\n",
      "  Downloading pyworld-0.3.5.tar.gz (261 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: soundfile in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from pyworld) (2.2.6)\n",
      "Requirement already satisfied: cffi>=1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: pycparser in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: packaging in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Building wheels for collected packages: pyworld\n",
      "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyworld: filename=pyworld-0.3.5-cp310-cp310-linux_x86_64.whl size=887034 sha256=288804abed0d4ceb9ab53eab83d2dee8a16c90cb5033c016495c88f89b257647\n",
      "  Stored in directory: /data/b22_shruti_chaudhary/.cache/pip/wheels/8e/a0/94/52e99161f9460670f11129bff5224ddf1a17915007d8cfa196\n",
      "Successfully built pyworld\n",
      "Installing collected packages: pyworld\n",
      "Successfully installed pyworld-0.3.5\n"
     ]
    }
   ],
   "source": [
    "! pip install pyworld soundfile librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/data/b22_shruti_chaudhary/.cache/kagglehub/datasets/phantasm34/emovdb-sorted/versions/1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prosody_data.pt with 6893 utterances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pyworld as pw\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA_ROOT = \"/data/b22_shruti_chaudhary/.cache/kagglehub/datasets/phantasm34/emovdb-sorted/versions/1\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "discrete = torch.load(\"discrete_units.pt\", weights_only=False)\n",
    "paths_kaggle = discrete[\"paths\"]\n",
    "units_full = discrete[\"units\"]           # frame-level units (with repeats)\n",
    "units_dedup = discrete[\"units_dedup\"]    # dedup units\n",
    "\n",
    "df = pd.read_csv(\"emovdb_manifest.csv\")\n",
    "label_map = torch.load(\"label_mappings.pt\")\n",
    "emotion2id = label_map[\"emotion2id\"]\n",
    "\n",
    "def to_rel(p):\n",
    "    return \"/\".join(p.split(\"/\")[-3:])\n",
    "\n",
    "df[\"relpath\"] = df[\"filepath\"].apply(to_rel)\n",
    "rel_from_kaggle = [to_rel(p) for p in paths_kaggle]\n",
    "\n",
    "def get_local_path(rel):\n",
    "    return os.path.join(DATA_ROOT, rel)\n",
    "\n",
    "def extract_f0(x, sr=16000, frame_period_ms=20.0):\n",
    "    f0, t = pw.harvest(x.astype(np.float64), sr, frame_period=frame_period_ms)\n",
    "    f0 = pw.stonemask(x.astype(np.float64), f0, t, sr)\n",
    "    return f0\n",
    "\n",
    "def resample_f0_to_units(f0, target_len):\n",
    "    src_idx = np.linspace(0, len(f0)-1, num=len(f0))\n",
    "    tgt_idx = np.linspace(0, len(f0)-1, num=target_len)\n",
    "    f0_interp = np.interp(tgt_idx, src_idx, f0)\n",
    "    return f0_interp\n",
    "\n",
    "def run_length_encode(seq):\n",
    "    if len(seq) == 0:\n",
    "        return [], []\n",
    "    ids = []\n",
    "    lens = []\n",
    "    prev = seq[0]\n",
    "    cnt = 1\n",
    "    for x in seq[1:]:\n",
    "        if x == prev:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ids.append(prev)\n",
    "            lens.append(cnt)\n",
    "            prev = x\n",
    "            cnt = 1\n",
    "    ids.append(prev)\n",
    "    lens.append(cnt)\n",
    "    return ids, lens\n",
    "\n",
    "prosody_entries = []\n",
    "\n",
    "for rel, u_full, u_dedup in zip(rel_from_kaggle, units_full, units_dedup):\n",
    "    meta = df[df[\"relpath\"] == rel]\n",
    "    if meta.empty:\n",
    "        continue\n",
    "    emo = meta.iloc[0][\"emotion\"]\n",
    "    emo_id = emotion2id[emo]\n",
    "    local_path = get_local_path(rel)\n",
    "    if not os.path.exists(local_path):\n",
    "        continue\n",
    "    try:\n",
    "        wav, sr = sf.read(local_path)\n",
    "    except:\n",
    "        continue\n",
    "    if wav.ndim > 1:\n",
    "        wav = wav.mean(axis=1)\n",
    "    if sr != 16000:\n",
    "        import librosa\n",
    "        wav = librosa.resample(wav, orig_sr=sr, target_sr=16000)\n",
    "        sr = 16000\n",
    "    f0 = extract_f0(wav, sr=sr, frame_period_ms=20.0)\n",
    "    u_full_np = np.array(u_full, dtype=np.int64)\n",
    "    if len(f0) != len(u_full_np):\n",
    "        f0 = resample_f0_to_units(f0, len(u_full_np))\n",
    "    ids, lens = run_length_encode(u_full_np)\n",
    "    if len(ids) != len(u_dedup):\n",
    "        continue\n",
    "    f0_per_unit = []\n",
    "    idx = 0\n",
    "    f0 = np.asarray(f0)\n",
    "    for L in lens:\n",
    "        seg = f0[idx:idx+L]\n",
    "        if len(seg) == 0:\n",
    "            f0_per_unit.append(0.0)\n",
    "        else:\n",
    "            f0_per_unit.append(float(seg.mean()))\n",
    "        idx += L\n",
    "    prosody_entries.append({\n",
    "        \"relpath\": rel,\n",
    "        \"units_dedup\": torch.tensor(u_dedup, dtype=torch.long),\n",
    "        \"f0\": torch.tensor(f0_per_unit, dtype=torch.float32),\n",
    "        \"dur\": torch.tensor(lens, dtype=torch.float32),\n",
    "        \"emotion_id\": emo_id\n",
    "    })\n",
    "\n",
    "torch.save({\"entries\": prosody_entries}, \"prosody_data.pt\")\n",
    "print(\"Saved prosody_data.pt with\", len(prosody_entries), \"utterances\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6893\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "prosody_data = torch.load(\"prosody_data.pt\")\n",
    "entries = prosody_data[\"entries\"]\n",
    "\n",
    "df = pd.read_csv(\"emovdb_manifest.csv\")\n",
    "df[\"relpath\"] = df[\"filepath\"].apply(lambda p: \"/\".join(p.split(\"/\")[-3:]))\n",
    "\n",
    "spk_table = torch.load(\"speaker_table.pt\")\n",
    "speaker2id = spk_table[\"speaker2id\"]\n",
    "spk_dim = spk_table[\"spk_dim\"]\n",
    "\n",
    "def get_speaker_id(relpath):\n",
    "    row = df[df[\"relpath\"] == relpath]\n",
    "    if row.empty:\n",
    "        return 0\n",
    "    spk = row.iloc[0][\"speaker\"]\n",
    "    return speaker2id.get(spk, 0)\n",
    "\n",
    "class ProsodyDataset(Dataset):\n",
    "    def __init__(self, entries):\n",
    "        self.entries = entries\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.entries[idx]\n",
    "        units = e[\"units_dedup\"]\n",
    "        f0 = e[\"f0\"]\n",
    "        dur = e[\"dur\"]\n",
    "        emo = e[\"emotion_id\"]\n",
    "        spk_id = get_speaker_id(e[\"relpath\"])\n",
    "        return {\n",
    "            \"units\": units,\n",
    "            \"f0\": f0,\n",
    "            \"dur\": dur,\n",
    "            \"emo_id\": torch.tensor(emo, dtype=torch.long),\n",
    "            \"spk_id\": torch.tensor(spk_id, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def collate_prosody(batch):\n",
    "    max_len = max(len(b[\"units\"]) for b in batch)\n",
    "    units, f0, dur, emo, spk, mask = [], [], [], [], [], []\n",
    "    for b in batch:\n",
    "        L = len(b[\"units\"])\n",
    "        pad_len = max_len - L\n",
    "        units.append(torch.cat([b[\"units\"], torch.zeros(pad_len, dtype=torch.long)]))\n",
    "        f0.append(torch.cat([b[\"f0\"], torch.zeros(pad_len)]))\n",
    "        dur.append(torch.cat([b[\"dur\"], torch.zeros(pad_len)]))\n",
    "        emo.append(b[\"emo_id\"])\n",
    "        spk.append(b[\"spk_id\"])\n",
    "        mask.append(torch.cat([torch.zeros(L, dtype=torch.bool), torch.ones(pad_len, dtype=torch.bool)]))\n",
    "    return {\n",
    "        \"units\": torch.stack(units),\n",
    "        \"f0\": torch.stack(f0),\n",
    "        \"dur\": torch.stack(dur),\n",
    "        \"emo_id\": torch.stack(emo),\n",
    "        \"spk_id\": torch.stack(spk),\n",
    "        \"mask\": torch.stack(mask)\n",
    "    }\n",
    "\n",
    "prosody_ds = ProsodyDataset(entries)\n",
    "prosody_loader = DataLoader(prosody_ds, batch_size=16, shuffle=True, collate_fn=collate_prosody)\n",
    "print(len(prosody_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:   2%|▏         | 1/50 [00:14<12:12, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Loss: 10603012.7324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:   4%|▍         | 2/50 [00:29<11:57, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  Loss: 9339382.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:   6%|▌         | 3/50 [00:44<11:43, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  Loss: 8136672.5088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:   8%|▊         | 4/50 [00:59<11:28, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  Loss: 7144809.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  10%|█         | 5/50 [01:14<11:15, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4  Loss: 6429068.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  12%|█▏        | 6/50 [01:29<10:53, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5  Loss: 5501968.2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  14%|█▍        | 7/50 [01:43<10:29, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6  Loss: 4778045.2808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  16%|█▌        | 8/50 [01:57<10:09, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7  Loss: 3963553.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  18%|█▊        | 9/50 [02:12<09:51, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8  Loss: 3237787.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  20%|██        | 10/50 [02:26<09:35, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9  Loss: 2870501.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  22%|██▏       | 11/50 [02:40<09:18, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10  Loss: 2470746.8672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  24%|██▍       | 12/50 [02:54<09:00, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11  Loss: 2273587.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  26%|██▌       | 13/50 [03:09<08:55, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12  Loss: 2128902.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  28%|██▊       | 14/50 [03:24<08:45, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13  Loss: 2020608.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  30%|███       | 15/50 [03:39<08:34, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14  Loss: 1936749.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  32%|███▏      | 16/50 [03:54<08:23, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15  Loss: 1873532.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  34%|███▍      | 17/50 [04:09<08:09, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16  Loss: 1834520.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  36%|███▌      | 18/50 [04:24<07:55, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17  Loss: 1800096.4949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  38%|███▊      | 19/50 [04:39<07:41, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18  Loss: 1771571.1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  40%|████      | 20/50 [04:54<07:27, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19  Loss: 1753760.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  42%|████▏     | 21/50 [05:09<07:12, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20  Loss: 1737734.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  44%|████▍     | 22/50 [05:24<06:58, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21  Loss: 1725827.7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  46%|████▌     | 23/50 [05:39<06:43, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22  Loss: 1718736.2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  48%|████▊     | 24/50 [05:54<06:28, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23  Loss: 1708164.1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  50%|█████     | 25/50 [06:08<06:08, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24  Loss: 1698655.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  52%|█████▏    | 26/50 [06:22<05:50, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25  Loss: 1694014.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  54%|█████▍    | 27/50 [06:36<05:33, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26  Loss: 1685717.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  56%|█████▌    | 28/50 [06:51<05:17, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27  Loss: 1682623.8632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  58%|█████▊    | 29/50 [07:05<05:02, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28  Loss: 1676039.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  60%|██████    | 30/50 [07:19<04:44, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29  Loss: 1672030.7334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  62%|██████▏   | 31/50 [07:34<04:34, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30  Loss: 1668076.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  64%|██████▍   | 32/50 [07:49<04:23, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31  Loss: 1662683.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  66%|██████▌   | 33/50 [08:04<04:10, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32  Loss: 1657334.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  68%|██████▊   | 34/50 [08:19<03:56, 14.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33  Loss: 1651520.2869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  70%|███████   | 35/50 [08:34<03:42, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34  Loss: 1647705.8171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  72%|███████▏  | 36/50 [08:49<03:28, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35  Loss: 1643870.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  74%|███████▍  | 37/50 [09:04<03:13, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36  Loss: 1635632.7253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  76%|███████▌  | 38/50 [09:19<02:59, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37  Loss: 1630506.3716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  78%|███████▊  | 39/50 [09:34<02:44, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38  Loss: 1628383.5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  80%|████████  | 40/50 [09:49<02:29, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39  Loss: 1621080.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  82%|████████▏ | 41/50 [10:04<02:14, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40  Loss: 1617559.7153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  84%|████████▍ | 42/50 [10:19<01:59, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41  Loss: 1608702.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  86%|████████▌ | 43/50 [10:33<01:43, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42  Loss: 1604808.6028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  88%|████████▊ | 44/50 [10:47<01:27, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43  Loss: 1598776.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  90%|█████████ | 45/50 [11:02<01:12, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44  Loss: 1594647.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  92%|█████████▏| 46/50 [11:16<00:57, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45  Loss: 1589405.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  94%|█████████▍| 47/50 [11:30<00:42, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46  Loss: 1582323.9482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  96%|█████████▌| 48/50 [11:43<00:27, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47  Loss: 1579350.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training:  98%|█████████▊| 49/50 [11:58<00:14, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48  Loss: 1570430.1652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prosody Training: 100%|██████████| 50/50 [12:13<00:00, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49  Loss: 1565814.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "K = 200\n",
    "PAD = 0\n",
    "SHIFT = 1\n",
    "VOCAB_SIZE = K + SHIFT + 2\n",
    "\n",
    "class SpeakerLookup(nn.Module):\n",
    "    def __init__(self, num_speakers, spk_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_speakers, spk_dim)\n",
    "    def forward(self, spk_ids):\n",
    "        return self.embedding(spk_ids)\n",
    "\n",
    "num_speakers = len(speaker2id)\n",
    "spk_lookup = SpeakerLookup(num_speakers, spk_dim).to(device)\n",
    "spk_lookup.load_state_dict(spk_table[\"state_dict\"])\n",
    "\n",
    "emotion2id = torch.load(\"label_mappings.pt\")[\"emotion2id\"]\n",
    "num_emotions = len(emotion2id)\n",
    "\n",
    "class ProsodyPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, num_emotions, spk_dim, d_model=256, nhead=4, num_layers=3, ff=512):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=PAD)\n",
    "        self.emo_emb = nn.Embedding(num_emotions, d_model)\n",
    "        self.proj_spk = nn.Linear(spk_dim, d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=ff, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.f0_head = nn.Linear(d_model, 1)\n",
    "        self.dur_head = nn.Linear(d_model, 1)\n",
    "    def forward(self, units, emo_ids, spk_vecs, src_key_padding_mask):\n",
    "        x_tok = self.token_emb(units)\n",
    "        x_emo = self.emo_emb(emo_ids).unsqueeze(1)\n",
    "        x_spk = self.proj_spk(spk_vecs).unsqueeze(1)\n",
    "        x = x_tok + x_emo + x_spk\n",
    "        h = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        f0 = self.f0_head(h).squeeze(-1)\n",
    "        dur = self.dur_head(h).squeeze(-1)\n",
    "        return f0, dur\n",
    "\n",
    "prosody_model = ProsodyPredictor(VOCAB_SIZE, num_emotions, spk_dim).to(device)\n",
    "optim_p = torch.optim.Adam(prosody_model.parameters(), lr=1e-4)\n",
    "mse = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "def train_prosody_epoch(model, loader, spk_lookup, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        units = batch[\"units\"].to(device)\n",
    "        f0 = batch[\"f0\"].to(device)\n",
    "        dur = batch[\"dur\"].to(device)\n",
    "        emo = batch[\"emo_id\"].to(device)\n",
    "        spk_id = batch[\"spk_id\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            spk_vecs = spk_lookup(spk_id)\n",
    "        optimizer.zero_grad()\n",
    "        f0_pred, dur_pred = model(units, emo, spk_vecs, src_key_padding_mask=mask)\n",
    "        f0_loss = mse(f0_pred, f0)\n",
    "        dur_loss = mse(dur_pred, dur)\n",
    "        f0_loss = (f0_loss * (~mask)).sum() / (~mask).sum().clamp(min=1)\n",
    "        dur_loss = (dur_loss * (~mask)).sum() / (~mask).sum().clamp(min=1)\n",
    "        loss = f0_loss + dur_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(50), desc=\"Prosody Training\"):\n",
    "    loss = train_prosody_epoch(prosody_model, prosody_loader, spk_lookup, optim_p)\n",
    "    tqdm.write(f\"Epoch {epoch}  Loss: {loss:.4f}\")\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": prosody_model.state_dict()\n",
    "}, \"prosody_predictor.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/b22_shruti_chaudhary/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "Epoch 1/50:  89%|▉| 3062/3447 [20:51<02:37,  2.44it/s, D_loss=3.2088, G_loss=10.3493, D_epoch=10600.84, G_epoch=25093.76"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_ROOT = \"/data/b22_shruti_chaudhary/.cache/kagglehub/datasets/phantasm34/emovdb-sorted/versions/1\"\n",
    "sample_rate = 16000\n",
    "hop_length = 256\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "discrete = torch.load(\"discrete_units.pt\", weights_only=False)\n",
    "paths_kaggle = discrete[\"paths\"]\n",
    "units_full = discrete[\"units\"]\n",
    "units_dedup = discrete[\"units_dedup\"]\n",
    "\n",
    "def to_rel(p):\n",
    "    return \"/\".join(p.split(\"/\")[-3:])\n",
    "\n",
    "rel_from_kaggle = [to_rel(p) for p in paths_kaggle]\n",
    "\n",
    "df = pd.read_csv(\"emovdb_manifest.csv\")\n",
    "df[\"relpath\"] = df[\"filepath\"].apply(to_rel)\n",
    "\n",
    "label_map = torch.load(\"label_mappings.pt\")\n",
    "emotion2id = label_map[\"emotion2id\"]\n",
    "id2emotion = {v:k for k,v in emotion2id.items()}\n",
    "num_emotions = len(emotion2id)\n",
    "\n",
    "spk_table = torch.load(\"speaker_table.pt\")\n",
    "speaker2id = spk_table[\"speaker2id\"]\n",
    "id2speaker = {v:k for k,v in speaker2id.items()}\n",
    "spk_dim = spk_table[\"spk_dim\"]\n",
    "num_speakers = len(speaker2id)\n",
    "\n",
    "prosody_data = torch.load(\"prosody_data.pt\")\n",
    "prosody_entries = prosody_data[\"entries\"]\n",
    "\n",
    "rel2prosody = {e[\"relpath\"]: e for e in prosody_entries}\n",
    "\n",
    "rel2units_dedup = {to_rel(p): u for p,u in zip(paths_kaggle, units_dedup)}\n",
    "\n",
    "K = 200\n",
    "PAD = 0\n",
    "SHIFT = 1\n",
    "VOCAB_SIZE = K + SHIFT + 2\n",
    "\n",
    "def get_local_path(rel):\n",
    "    return os.path.join(DATA_ROOT, rel)\n",
    "\n",
    "def get_speaker_id(relpath):\n",
    "    row = df[df[\"relpath\"] == relpath]\n",
    "    if row.empty:\n",
    "        return 0\n",
    "    spk = row.iloc[0][\"speaker\"]\n",
    "    return speaker2id.get(spk, 0)\n",
    "\n",
    "def get_emotion_id(relpath):\n",
    "    row = df[df[\"relpath\"] == relpath]\n",
    "    if row.empty:\n",
    "        return 0\n",
    "    emo = row.iloc[0][\"emotion\"]\n",
    "    return emotion2id.get(emo, 0)\n",
    "\n",
    "class VocoderDataset(Dataset):\n",
    "    def __init__(self, entries, max_frames=256):\n",
    "        self.entries = entries\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.entries[idx]\n",
    "        rel = e[\"relpath\"]\n",
    "        units_d = e[\"units_dedup\"]\n",
    "        f0_u = e[\"f0\"]\n",
    "        dur = e[\"dur\"]\n",
    "        spk_id = get_speaker_id(rel)\n",
    "        emo_id = get_emotion_id(rel)\n",
    "\n",
    "        local_path = get_local_path(rel)\n",
    "        wav, sr = sf.read(local_path)\n",
    "        if wav.ndim > 1:\n",
    "            wav = wav.mean(axis=1)\n",
    "        if sr != sample_rate:\n",
    "            wav_t = torch.from_numpy(wav).float().unsqueeze(0)\n",
    "            wav_t = torchaudio.functional.resample(wav_t, sr, sample_rate)\n",
    "            wav = wav_t.squeeze(0).numpy()\n",
    "            sr = sample_rate\n",
    "\n",
    "        u = units_d.long()\n",
    "        f0u = f0_u.float()\n",
    "        d = dur.long()\n",
    "\n",
    "        unit_frames = []\n",
    "        f0_frames = []\n",
    "        for uid, f0v, L in zip(u.tolist(), f0u.tolist(), d.tolist()):\n",
    "            if L <= 0:\n",
    "                continue\n",
    "            unit_frames.extend([uid] * L)\n",
    "            f0_frames.extend([f0v] * L)\n",
    "\n",
    "        unit_frames = torch.tensor(unit_frames, dtype=torch.long)\n",
    "        f0_frames = torch.tensor(f0_frames, dtype=torch.float32)\n",
    "\n",
    "        if len(unit_frames) == 0:\n",
    "            unit_frames = torch.zeros(1, dtype=torch.long)\n",
    "            f0_frames = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "        T = len(unit_frames)\n",
    "        max_T = self.max_frames\n",
    "\n",
    "        if T > max_T:\n",
    "            start = np.random.randint(0, T - max_T + 1)\n",
    "            end = start + max_T\n",
    "            unit_frames = unit_frames[start:end]\n",
    "            f0_frames = f0_frames[start:end]\n",
    "            T = max_T\n",
    "        else:\n",
    "            pad_T = max_T - T\n",
    "            unit_frames = torch.cat(\n",
    "                [unit_frames, torch.full((pad_T,), PAD, dtype=torch.long)]\n",
    "            )\n",
    "            f0_frames = torch.cat(\n",
    "                [f0_frames, torch.zeros(pad_T, dtype=torch.float32)]\n",
    "            )\n",
    "            T = max_T\n",
    "\n",
    "        audio_len = T * hop_length\n",
    "\n",
    "        if len(wav) < audio_len:\n",
    "            pad = audio_len - len(wav)\n",
    "            wav = np.pad(wav, (0, pad))\n",
    "        else:\n",
    "            start = np.random.randint(0, len(wav) - audio_len + 1)\n",
    "            wav = wav[start:start + audio_len]\n",
    "\n",
    "        wav = torch.tensor(wav, dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"units\": unit_frames,\n",
    "            \"f0\": f0_frames,\n",
    "            \"audio\": wav,\n",
    "            \"spk_id\": torch.tensor(spk_id, dtype=torch.long),\n",
    "            \"emo_id\": torch.tensor(emo_id, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_vocoder(batch):\n",
    "    units = torch.stack([b[\"units\"] for b in batch])\n",
    "    f0 = torch.stack([b[\"f0\"] for b in batch])\n",
    "    audio = torch.stack([b[\"audio\"] for b in batch])\n",
    "    spk = torch.stack([b[\"spk_id\"] for b in batch])\n",
    "    emo = torch.stack([b[\"emo_id\"] for b in batch])\n",
    "    return {\n",
    "        \"units\": units,\n",
    "        \"f0\": f0,\n",
    "        \"audio\": audio,\n",
    "        \"spk_id\": spk,\n",
    "        \"emo_id\": emo,\n",
    "    }\n",
    "\n",
    "\n",
    "# class VocoderDataset(Dataset):\n",
    "#     def __init__(self, entries, max_frames=800):\n",
    "#         self.entries = entries\n",
    "#         self.max_frames = max_frames\n",
    "#     def __len__(self):\n",
    "#         return len(self.entries)\n",
    "#     def __getitem__(self, idx):\n",
    "#         e = self.entries[idx]\n",
    "#         rel = e[\"relpath\"]\n",
    "#         units_d = e[\"units_dedup\"]\n",
    "#         f0_u = e[\"f0\"]\n",
    "#         dur = e[\"dur\"]\n",
    "#         spk_id = get_speaker_id(rel)\n",
    "#         emo_id = get_emotion_id(rel)\n",
    "#         local_path = get_local_path(rel)\n",
    "#         wav, sr = sf.read(local_path)\n",
    "#         if wav.ndim > 1:\n",
    "#             wav = wav.mean(axis=1)\n",
    "#         if sr != sample_rate:\n",
    "#             wav_t = torch.from_numpy(wav).float().unsqueeze(0)\n",
    "#             wav_t = torchaudio.functional.resample(wav_t, sr, sample_rate)\n",
    "#             wav = wav_t.squeeze(0).numpy()\n",
    "#             sr = sample_rate\n",
    "#         u = units_d.long()\n",
    "#         f0u = f0_u.float()\n",
    "#         d = dur.long()\n",
    "#         unit_frames = []\n",
    "#         f0_frames = []\n",
    "#         for uid, f0v, L in zip(u.tolist(), f0u.tolist(), d.tolist()):\n",
    "#             if L <= 0:\n",
    "#                 continue\n",
    "#             unit_frames.extend([uid] * L)\n",
    "#             f0_frames.extend([f0v] * L)\n",
    "#         unit_frames = torch.tensor(unit_frames, dtype=torch.long)\n",
    "#         f0_frames = torch.tensor(f0_frames, dtype=torch.float32)\n",
    "#         if len(unit_frames) == 0:\n",
    "#             unit_frames = torch.zeros(1, dtype=torch.long)\n",
    "#             f0_frames = torch.zeros(1, dtype=torch.float32)\n",
    "#         T = len(unit_frames)\n",
    "#         max_T = min(T, self.max_frames)\n",
    "#         if T > max_T:\n",
    "#             start = np.random.randint(0, T - max_T + 1)\n",
    "#             end = start + max_T\n",
    "#             unit_frames = unit_frames[start:end]\n",
    "#             f0_frames = f0_frames[start:end]\n",
    "#             T = max_T\n",
    "#         max_audio_len = T * hop_length\n",
    "#         if len(wav) < max_audio_len:\n",
    "#             pad = max_audio_len - len(wav)\n",
    "#             wav = np.pad(wav, (0, pad))\n",
    "#         else:\n",
    "#             start = np.random.randint(0, len(wav) - max_audio_len + 1)\n",
    "#             wav = wav[start:start + max_audio_len]\n",
    "#         wav = torch.tensor(wav, dtype=torch.float32)\n",
    "#         return {\n",
    "#             \"units\": unit_frames,\n",
    "#             \"f0\": f0_frames,\n",
    "#             \"audio\": wav,\n",
    "#             \"spk_id\": torch.tensor(spk_id, dtype=torch.long),\n",
    "#             \"emo_id\": torch.tensor(emo_id, dtype=torch.long),\n",
    "#         }\n",
    "\n",
    "# def collate_vocoder(batch):\n",
    "#     max_T = max(len(b[\"units\"]) for b in batch)\n",
    "#     units = []\n",
    "#     f0 = []\n",
    "#     audio = []\n",
    "#     spk = []\n",
    "#     emo = []\n",
    "#     for b in batch:\n",
    "#         L = len(b[\"units\"])\n",
    "#         pad_T = max_T - L\n",
    "#         units.append(torch.cat([b[\"units\"], torch.full((pad_T,), PAD, dtype=torch.long)]))\n",
    "#         f0.append(torch.cat([b[\"f0\"], torch.zeros(pad_T)]))\n",
    "#         audio.append(b[\"audio\"])\n",
    "#         spk.append(b[\"spk_id\"])\n",
    "#         emo.append(b[\"emo_id\"])\n",
    "#     units = torch.stack(units)\n",
    "#     f0 = torch.stack(f0)\n",
    "#     audio = torch.stack(audio)\n",
    "#     spk = torch.stack(spk)\n",
    "#     emo = torch.stack(emo)\n",
    "#     return {\n",
    "#         \"units\": units,\n",
    "#         \"f0\": f0,\n",
    "#         \"audio\": audio,\n",
    "#         \"spk_id\": spk,\n",
    "#         \"emo_id\": emo,\n",
    "#     }\n",
    "\n",
    "vocoder_ds = VocoderDataset(prosody_entries)\n",
    "vocoder_loader = DataLoader(vocoder_ds, batch_size=2, shuffle=True, collate_fn=collate_vocoder)\n",
    "\n",
    "class SpeakerLookup(nn.Module):\n",
    "    def __init__(self, num_speakers, spk_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_speakers, spk_dim)\n",
    "    def forward(self, spk_ids):\n",
    "        return self.embedding(spk_ids)\n",
    "\n",
    "spk_lookup = SpeakerLookup(num_speakers, spk_dim)\n",
    "spk_lookup.load_state_dict(spk_table[\"state_dict\"])\n",
    "spk_lookup = spk_lookup.to(device)\n",
    "spk_lookup.eval()\n",
    "\n",
    "emo_dim = 32\n",
    "unit_emb_dim = 256\n",
    "\n",
    "class VocoderConditioner(nn.Module):\n",
    "    def __init__(self, vocab_size, num_emotions, spk_dim, unit_emb_dim=256, emo_dim=32):\n",
    "        super().__init__()\n",
    "        self.unit_emb = nn.Embedding(vocab_size, unit_emb_dim, padding_idx=PAD)\n",
    "        self.emo_emb = nn.Embedding(num_emotions, emo_dim)\n",
    "        self.proj_spk = nn.Linear(spk_dim, emo_dim)\n",
    "    def forward(self, units, f0, spk_vecs, emo_ids):\n",
    "        u = self.unit_emb(units + SHIFT)\n",
    "        f0 = f0.unsqueeze(-1)\n",
    "        emo = self.emo_emb(emo_ids).unsqueeze(1)\n",
    "        spk_p = self.proj_spk(spk_vecs).unsqueeze(1)\n",
    "        emo_exp = emo.expand(-1, u.size(1), -1)\n",
    "        spk_exp = spk_p.expand(-1, u.size(1), -1)\n",
    "        cond = torch.cat([u, f0, emo_exp, spk_exp], dim=-1)\n",
    "        cond = cond.transpose(1,2)\n",
    "        return cond\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3, dilation=(1,3,5)):\n",
    "        super().__init__()\n",
    "        self.convs1 = nn.ModuleList([\n",
    "            nn.utils.weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, padding=d*(kernel_size-1)//2, dilation=d))\n",
    "            for d in dilation\n",
    "        ])\n",
    "        self.convs2 = nn.ModuleList([\n",
    "            nn.utils.weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, padding=(kernel_size-1)//2))\n",
    "            for _ in dilation\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for c1, c2 in zip(self.convs1, self.convs2):\n",
    "            y = F.leaky_relu(x, 0.1)\n",
    "            y = c1(y)\n",
    "            y = F.leaky_relu(y,0.1)\n",
    "            y = c2(y)\n",
    "            x = x + y\n",
    "        return x\n",
    "\n",
    "class HiFiGAN_Generator(nn.Module):\n",
    "    def __init__(self, cond_dim, channels=512, upsample_rates=(8,8,2,2), upsample_kernel_sizes=(16,16,4,4)):\n",
    "        super().__init__()\n",
    "        self.conv_pre = nn.utils.weight_norm(nn.Conv1d(cond_dim, channels,7,1,padding=3))\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        in_ch = channels\n",
    "        for u,k in zip(upsample_rates, upsample_kernel_sizes):\n",
    "            self.ups.append(\n",
    "                nn.utils.weight_norm(\n",
    "                    nn.ConvTranspose1d(in_ch,in_ch//2,k,u,padding=(k-u)//2)\n",
    "                )\n",
    "            )\n",
    "            in_ch = in_ch//2\n",
    "            self.resblocks.append(nn.ModuleList([ResBlock(in_ch) for _ in range(3)]))\n",
    "        self.conv_post = nn.utils.weight_norm(nn.Conv1d(in_ch,1,7,1,padding=3))\n",
    "    def forward(self,x):\n",
    "        x = self.conv_pre(x)\n",
    "        for up,rbs in zip(self.ups,self.resblocks):\n",
    "            x = F.leaky_relu(x,0.1)\n",
    "            x = up(x)\n",
    "            out = 0\n",
    "            for rb in rbs:\n",
    "                out += rb(x)\n",
    "            x = out/len(rbs)\n",
    "        x = F.leaky_relu(x,0.1)\n",
    "        x = self.conv_post(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "class MPD_Block(nn.Module):\n",
    "    def __init__(self, period):\n",
    "        super().__init__()\n",
    "        self.period = period\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.utils.weight_norm(nn.Conv2d(1,32,(5,1),(3,1),padding=(2,0))),\n",
    "            nn.utils.weight_norm(nn.Conv2d(32,128,(5,1),(3,1),padding=(2,0))),\n",
    "            nn.utils.weight_norm(nn.Conv2d(128,512,(5,1),(3,1),padding=(2,0))),\n",
    "            nn.utils.weight_norm(nn.Conv2d(512,1024,(5,1),(3,1),padding=(2,0))),\n",
    "            nn.utils.weight_norm(nn.Conv2d(1024,1024,(5,1),1,padding=(2,0)))\n",
    "        ])\n",
    "        self.conv_post = nn.utils.weight_norm(nn.Conv2d(1024,1,(3,1),1,padding=(1,0)))\n",
    "    def forward(self,x):\n",
    "        b,c,t = x.shape\n",
    "        # if t % self.period != 0:\n",
    "        #     pad = self.period - (t%self.period)\n",
    "        #     x = F.pad(x,(0,pad),\"reflect\")\n",
    "        pad = (self.period - (t % self.period)) % self.period\n",
    "        x = F.pad(x,(0,pad),mode=\"reflect\")\n",
    "        t = x.shape[-1]\n",
    "        x = x.view(b,1,t//self.period,self.period)\n",
    "        feats = []\n",
    "        for l in self.convs:\n",
    "            x = l(x)\n",
    "            x = F.leaky_relu(x,0.1)\n",
    "            feats.append(x)\n",
    "        x = self.conv_post(x)\n",
    "        feats.append(x)\n",
    "        x = x.reshape(b,-1)\n",
    "        return x,feats\n",
    "\n",
    "class MultiPeriodDiscriminator(nn.Module):\n",
    "    def __init__(self, periods=[2,3,5,7,11]):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([MPD_Block(p) for p in periods])\n",
    "    def forward(self,x):\n",
    "        ret=[]\n",
    "        for b in self.blocks:\n",
    "            score,feat = b(x)\n",
    "            ret.append((score,feat))\n",
    "        return ret\n",
    "\n",
    "class MSD_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.utils.weight_norm(nn.Conv1d(1,128,15,1,padding=7)),\n",
    "            nn.utils.weight_norm(nn.Conv1d(128,128,41,2,padding=20,groups=4)),\n",
    "            nn.utils.weight_norm(nn.Conv1d(128,256,41,2,padding=20,groups=16)),\n",
    "            nn.utils.weight_norm(nn.Conv1d(256,512,41,2,padding=20,groups=16)),\n",
    "            nn.utils.weight_norm(nn.Conv1d(512,512,41,2,padding=20,groups=16)),\n",
    "            nn.utils.weight_norm(nn.Conv1d(512,512,5,1,padding=2)),\n",
    "        ])\n",
    "        self.conv_post = nn.utils.weight_norm(nn.Conv1d(512,1,3,1,padding=1))\n",
    "    def forward(self,x):\n",
    "        feats=[]\n",
    "        for l in self.convs:\n",
    "            x=l(x)\n",
    "            x=F.leaky_relu(x,0.1)\n",
    "            feats.append(x)\n",
    "        x=self.conv_post(x)\n",
    "        feats.append(x)\n",
    "        return x,feats\n",
    "\n",
    "class MultiScaleDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b0 = MSD_Block()\n",
    "        self.b1 = MSD_Block()\n",
    "        self.b2 = MSD_Block()\n",
    "        self.avg = nn.AvgPool1d(4,2,padding=2)\n",
    "    def forward(self,x):\n",
    "        outs=[]\n",
    "        x1=x\n",
    "        outs.append(self.b0(x1))\n",
    "        x2=self.avg(x1)\n",
    "        outs.append(self.b1(x2))\n",
    "        x3=self.avg(x2)\n",
    "        outs.append(self.b2(x3))\n",
    "        return outs\n",
    "\n",
    "def loss_adv_g(scores):\n",
    "    loss=0\n",
    "    for s in scores:\n",
    "        loss+=torch.mean((1-s)**2)\n",
    "    return loss\n",
    "\n",
    "def loss_adv_d(real_scores,fake_scores):\n",
    "    loss=0\n",
    "    for r,f in zip(real_scores,fake_scores):\n",
    "        loss+=torch.mean((r-1)**2)+torch.mean(f**2)\n",
    "    return loss\n",
    "\n",
    "def feature_matching(real_feats,fake_feats):\n",
    "    loss=0\n",
    "    for r,f in zip(real_feats,fake_feats):\n",
    "        for rr,ff in zip(r,f):\n",
    "            loss+=torch.mean(torch.abs(rr-ff))\n",
    "    return loss\n",
    "\n",
    "def log_norm_f0(f0):\n",
    "    f0 = f0.clone()\n",
    "    f0[f0 <= 0] = 1.0\n",
    "    f0 = torch.log(f0)\n",
    "    m = f0.mean()\n",
    "    s = f0.std().clamp(min=1e-6)\n",
    "    return (f0 - m) / s\n",
    "\n",
    "cond_dim = unit_emb_dim + 1 + emo_dim + emo_dim\n",
    "\n",
    "generator = HiFiGAN_Generator(cond_dim=cond_dim).to(device)\n",
    "mpd = MultiPeriodDiscriminator().to(device)\n",
    "msd = MultiScaleDiscriminator().to(device)\n",
    "cond_net = VocoderConditioner(VOCAB_SIZE, num_emotions, spk_dim, unit_emb_dim=unit_emb_dim, emo_dim=emo_dim).to(device)\n",
    "\n",
    "optim_g = torch.optim.Adam(generator.parameters(), lr=2e-4, betas=(0.8,0.99))\n",
    "optim_d = torch.optim.Adam(list(mpd.parameters())+list(msd.parameters()), lr=2e-4, betas=(0.8,0.99))\n",
    "\n",
    "def discriminator_step(batch):\n",
    "    units = batch[\"units\"].to(device)\n",
    "    f0 = batch[\"f0\"].to(device)\n",
    "    audio = batch[\"audio\"].to(device)\n",
    "    spk_id = batch[\"spk_id\"].to(device)\n",
    "    emo_id = batch[\"emo_id\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        spk_vecs = spk_lookup(spk_id)\n",
    "        f0n = log_norm_f0(f0)\n",
    "        cond = cond_net(units, f0n, spk_vecs, emo_id)\n",
    "        fake_audio = generator(cond).squeeze(1)\n",
    "        fake_audio = fake_audio[:, :audio.size(1)]\n",
    "    real = audio.unsqueeze(1)\n",
    "    fake = fake_audio.unsqueeze(1)\n",
    "    r_mpd = mpd(real)\n",
    "    f_mpd = mpd(fake)\n",
    "    r_msd = msd(real)\n",
    "    f_msd = msd(fake)\n",
    "    real_scores = [x[0] for x in r_mpd] + [x[0] for x in r_msd]\n",
    "    fake_scores = [x[0] for x in f_mpd] + [x[0] for x in f_msd]\n",
    "    loss_d = loss_adv_d(real_scores, fake_scores)\n",
    "    return loss_d\n",
    "\n",
    "def generator_step(batch):\n",
    "    units = batch[\"units\"].to(device)\n",
    "    f0 = batch[\"f0\"].to(device)\n",
    "    audio = batch[\"audio\"].to(device)\n",
    "    spk_id = batch[\"spk_id\"].to(device)\n",
    "    emo_id = batch[\"emo_id\"].to(device)\n",
    "    spk_vecs = spk_lookup(spk_id)\n",
    "    f0n = log_norm_f0(f0)\n",
    "    cond = cond_net(units, f0n, spk_vecs, emo_id)\n",
    "    fake_audio = generator(cond).squeeze(1)\n",
    "    fake_audio = fake_audio[:, :audio.size(1)]\n",
    "    real = audio.unsqueeze(1)\n",
    "    fake = fake_audio.unsqueeze(1)\n",
    "    r_mpd = mpd(real)\n",
    "    f_mpd = mpd(fake)\n",
    "    r_msd = msd(real)\n",
    "    f_msd = msd(fake)\n",
    "    adv = loss_adv_g([x[0] for x in f_mpd] + [x[0] for x in f_msd])\n",
    "    fm = feature_matching([x[1] for x in r_mpd]+[x[1] for x in r_msd],[x[1] for x in f_mpd]+[x[1] for x in f_msd])\n",
    "    l1 = F.l1_loss(fake_audio,audio)\n",
    "    loss_g = adv + 10*l1 + 2*fm\n",
    "    return loss_g\n",
    "\n",
    "num_epochs = 50  # set >0 when you want to train\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    generator.train()\n",
    "    mpd.train()\n",
    "    msd.train()\n",
    "\n",
    "    total_g = 0.0\n",
    "    total_d = 0.0\n",
    "\n",
    "    # progress bar over batches\n",
    "    pbar = tqdm(vocoder_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=120)\n",
    "\n",
    "    for batch in pbar:\n",
    "\n",
    "        # ---- discriminator ----\n",
    "        optim_d.zero_grad()\n",
    "        ld = discriminator_step(batch)\n",
    "        ld.backward()\n",
    "        optim_d.step()\n",
    "\n",
    "        # ---- generator ----\n",
    "        optim_g.zero_grad()\n",
    "        lg = generator_step(batch)\n",
    "        lg.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        total_d += ld.item()\n",
    "        total_g += lg.item()\n",
    "\n",
    "        # update display\n",
    "        pbar.set_postfix({\n",
    "            \"D_loss\": f\"{ld.item():.4f}\",\n",
    "            \"G_loss\": f\"{lg.item():.4f}\",\n",
    "            \"D_epoch\": f\"{total_d:.2f}\",\n",
    "            \"G_epoch\": f\"{total_g:.2f}\",\n",
    "        })\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs} DONE | D={total_d:.2f} | G={total_g:.2f}\\n\")\n",
    "\n",
    "    # save every 50 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        ckpt_path = f\"hifigan_vocoder_epoch{epoch+1}.pt\"\n",
    "        torch.save({\n",
    "            \"generator\": generator.state_dict(),\n",
    "            \"mpd\": mpd.state_dict(),\n",
    "            \"msd\": msd.state_dict(),\n",
    "            \"cond_net\": cond_net.state_dict()\n",
    "        }, ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)].to(x.device)\n",
    "\n",
    "class EmotionTransformer(nn.Module):\n",
    "    def __init__(self, num_emotions, vocab_size=VOCAB_SIZE, d_model=512, nhead=8, num_layers=6, dim_feedforward=2048, dropout=0.1, max_len=4096):\n",
    "        super().__init__()\n",
    "        self.num_emotions = num_emotions\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=PAD)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len=max_len)\n",
    "        self.encoders = nn.ModuleDict()\n",
    "        self.decoders = nn.ModuleDict()\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        for e in range(num_emotions):\n",
    "            self.encoders[str(e)] = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "            self.decoders[str(e)] = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "        self.d_model = d_model\n",
    "    def encode(self, src_tokens, src_mask, emotion_id):\n",
    "        e = str(int(emotion_id))\n",
    "        x = self.token_emb(src_tokens) * np.sqrt(self.d_model)\n",
    "        x = x + self.pos_enc(x)\n",
    "        x = x.transpose(0,1)\n",
    "        memory = self.encoders[e](x, src_key_padding_mask=src_mask)\n",
    "        return memory\n",
    "    def decode(self, tgt_tokens, memory, memory_mask, emotion_id, tgt_mask):\n",
    "        e = str(int(emotion_id))\n",
    "        y = self.token_emb(tgt_tokens) * np.sqrt(self.d_model)\n",
    "        y = y + self.pos_enc(y)\n",
    "        y = y.transpose(0,1)\n",
    "        out = self.decoders[e](y, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask)\n",
    "        out = out.transpose(0,1)\n",
    "        logits = self.output_proj(out)\n",
    "        return logits\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n",
    "\n",
    "def greedy_decode_es2s(model, src, src_mask, src_em, tgt_em, max_len=400):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        memory = model.encode(src, src_mask, src_em)\n",
    "        ys = torch.tensor([[VOCAB_SIZE-2]], dtype=torch.long).to(device)\n",
    "        for _ in range(max_len):\n",
    "            tgt_mask = model.generate_square_subsequent_mask(ys.size(1)).to(device)\n",
    "            out = model.decode(ys, memory, src_mask, tgt_em, tgt_mask)\n",
    "            next_token = out[:, -1, :].argmax(-1, keepdim=True)\n",
    "            ys = torch.cat([ys, next_token], dim=1)\n",
    "            if next_token.item() == VOCAB_SIZE-1:\n",
    "                break\n",
    "    return ys.squeeze(0).tolist()\n",
    "\n",
    "class ProsodyPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, num_emotions, spk_dim, d_model=256, nhead=4, num_layers=3, ff=512):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=PAD)\n",
    "        self.emo_emb = nn.Embedding(num_emotions, d_model)\n",
    "        self.proj_spk = nn.Linear(spk_dim, d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=ff, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.f0_head = nn.Linear(d_model, 1)\n",
    "        self.dur_head = nn.Linear(d_model, 1)\n",
    "    def forward(self, units, emo_ids, spk_vecs, src_key_padding_mask):\n",
    "        x_tok = self.token_emb(units)\n",
    "        x_emo = self.emo_emb(emo_ids).unsqueeze(1)\n",
    "        x_spk = self.proj_spk(spk_vecs).unsqueeze(1)\n",
    "        x = x_tok + x_emo + x_spk\n",
    "        h = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        f0 = self.f0_head(h).squeeze(-1)\n",
    "        dur = self.dur_head(h).squeeze(-1)\n",
    "        return f0, dur\n",
    "\n",
    "es2s = EmotionTransformer(num_emotions=num_emotions).to(device)\n",
    "es2s.load_state_dict(torch.load(\"es2s_transformer.pt\", map_location=device))\n",
    "es2s.eval()\n",
    "\n",
    "prosody_model = ProsodyPredictor(VOCAB_SIZE, num_emotions, spk_dim).to(device)\n",
    "prosody_model.load_state_dict(torch.load(\"prosody_predictor.pt\", map_location=device)[\"state_dict\"])\n",
    "prosody_model.eval()\n",
    "\n",
    "def expand_units_with_dur(units, dur):\n",
    "    units = units.tolist()\n",
    "    dur = torch.clamp(dur, min=1.0).round().long().tolist()\n",
    "    u_frames = []\n",
    "    for u,d in zip(units,dur):\n",
    "        u_frames.extend([u]*d)\n",
    "    return torch.tensor(u_frames, dtype=torch.long)\n",
    "\n",
    "def convert_emotion_from_relpath(relpath, tgt_emotion_name, vocoder_ckpt, max_len_units=400):\n",
    "    tgt_emo_id = emotion2id[tgt_emotion_name]\n",
    "    src_emo_id = get_emotion_id(relpath)\n",
    "    spk_id = get_speaker_id(relpath)\n",
    "    spk_vec = spk_lookup(torch.tensor([spk_id],dtype=torch.long).to(device))\n",
    "    units_src = rel2units_dedup[relpath]\n",
    "    src = torch.tensor([[u+SHIFT for u in units_src]], dtype=torch.long).to(device)\n",
    "    src_mask = torch.zeros_like(src, dtype=torch.bool).to(device)\n",
    "    src_em = torch.tensor(src_emo_id, dtype=torch.long).to(device)\n",
    "    tgt_em = torch.tensor(tgt_emo_id, dtype=torch.long).to(device)\n",
    "    out_units = greedy_decode_es2s(es2s, src, src_mask, src_em, tgt_em, max_len=max_len_units)\n",
    "    out_units = [u for u in out_units if u > SHIFT and u < VOCAB_SIZE-1]\n",
    "    units_tgt = torch.tensor(out_units, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    mask = torch.zeros_like(units_tgt, dtype=torch.bool).to(device)\n",
    "    emo_ids = torch.tensor([tgt_emo_id], dtype=torch.long).to(device)\n",
    "    f0_pred, dur_pred = prosody_model(units_tgt, emo_ids, spk_vec, mask)\n",
    "    units_frames = expand_units_with_dur(units_tgt[0].cpu(), dur_pred[0].cpu())\n",
    "    f0_frames = torch.zeros_like(units_frames, dtype=torch.float32)\n",
    "    cond_len = len(units_frames)\n",
    "    ckpt = torch.load(vocoder_ckpt, map_location=device)\n",
    "    generator.load_state_dict(ckpt[\"generator\"])\n",
    "    cond_net.load_state_dict(ckpt[\"cond_net\"])\n",
    "    generator.eval()\n",
    "    cond_units = units_frames.unsqueeze(0).to(device)\n",
    "    cond_f0 = f0_frames.unsqueeze(0).to(device)\n",
    "    emo_ids_b = emo_ids\n",
    "    spk_vecs_b = spk_vec\n",
    "    f0n = log_norm_f0(cond_f0)\n",
    "    cond = cond_net(cond_units, f0n, spk_vecs_b, emo_ids_b)\n",
    "    with torch.no_grad():\n",
    "        audio_hat = generator(cond).squeeze(1)[0].cpu().numpy()\n",
    "    return audio_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 3\n",
      "  GPU 0 : NVIDIA RTX A6000\n",
      "  GPU 1 : NVIDIA RTX A5000\n",
      "  GPU 2 : NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"  GPU\", i, \":\", torch.cuda.get_device_name(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6893/6893 [5:31:55<00:00,  2.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0 extraction complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torchcrepe\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load prosody entries (fix NameError)\n",
    "prosody_data = torch.load(\"prosody_data.pt\", map_location=\"cpu\")\n",
    "prosody_entries = prosody_data[\"entries\"]\n",
    "\n",
    "DATA_ROOT = \"/data/b22_shruti_chaudhary/.cache/kagglehub/datasets/phantasm34/emovdb-sorted/versions/1\"\n",
    "SAVE_DIR = \"f0_cache/\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "HOP = 256\n",
    "\n",
    "def get_f0(wav, sr, hop=HOP):\n",
    "    # Resample to 16k if needed\n",
    "    if sr != SAMPLE_RATE:\n",
    "        wav = torchaudio.functional.resample(\n",
    "            torch.tensor(wav).unsqueeze(0),\n",
    "            sr, SAMPLE_RATE\n",
    "        ).squeeze(0).numpy()\n",
    "        sr = SAMPLE_RATE\n",
    "\n",
    "    # Convert to GPU\n",
    "    audio = torch.tensor(wav, dtype=torch.float32).unsqueeze(0).cuda()\n",
    "   # print(audio.device)\n",
    "\n",
    "\n",
    "    # Run torchcrepe\n",
    "    with torch.no_grad():\n",
    "        f0 = torchcrepe.predict(audio, sr, hop, 50.0, 500.0)\n",
    "        f0 = f0.squeeze(0).cpu().numpy()\n",
    "\n",
    "    return f0\n",
    "\n",
    "for entry in tqdm(prosody_entries):\n",
    "    rel = entry[\"relpath\"]\n",
    "    wav_path = os.path.join(DATA_ROOT, rel)\n",
    "\n",
    "    wav, sr = sf.read(wav_path)\n",
    "    \n",
    "    # Convert to mono\n",
    "    if wav.ndim > 1:\n",
    "        wav = wav.mean(axis=1)\n",
    "\n",
    "    f0 = get_f0(wav, sr)\n",
    "\n",
    "    save_name = rel.replace(\"/\", \"_\") + \".pt\"\n",
    "    save_path = os.path.join(SAVE_DIR, save_name)\n",
    "\n",
    "    torch.save(torch.tensor(f0), save_path)\n",
    "\n",
    "print(\"F0 extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1788303,
     "isSourceIdPinned": false,
     "sourceId": 2917436,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
